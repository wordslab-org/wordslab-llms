{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc9ecc80-06bf-4459-920c-c901d42809f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T13:25:33.511453Z",
     "iopub.status.busy": "2024-02-17T13:25:33.509421Z",
     "iopub.status.idle": "2024-02-17T13:25:33.541385Z",
     "shell.execute_reply": "2024-02-17T13:25:33.540867Z",
     "shell.execute_reply.started": "2024-02-17T13:25:33.511400Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib.metadata\n",
    "importlib.metadata.version(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae1024-9758-4eff-bfe7-a8726d51e488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3217b137-498d-4c9d-b9c0-2c19abf26492",
   "metadata": {},
   "source": [
    "**Profiler Implementation**\n",
    "\n",
    "https://github.com/pytorch/pytorch/blob/487ebcac3bc10b4b4b0631dafe2a12ddb0852f2a/torch/csrc/profiler/python/init.cpp\n",
    "\n",
    "https://github.com/pytorch/kineto/tree/main/libkineto/src\n",
    "\n",
    "**Profiler log level**\n",
    "\n",
    "  VERBOSE = 0,\n",
    "  INFO = 1,\n",
    "  WARNING = 2,\n",
    "  ERROR = 3,\n",
    "  STAGE = 4,\n",
    "  ENUM_COUNT = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f1db81e-e4ad-4168-b5fa-15e84b838d8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T13:26:05.388584Z",
     "iopub.status.busy": "2024-02-17T13:26:05.387258Z",
     "iopub.status.idle": "2024-02-17T13:26:05.394580Z",
     "shell.execute_reply": "2024-02-17T13:26:05.393577Z",
     "shell.execute_reply.started": "2024-02-17T13:26:05.388519Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KINETO_LOG_LEVEL\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d880f534-aabb-4d06-8de8-0a8c9e02d750",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T13:26:08.188111Z",
     "iopub.status.busy": "2024-02-17T13:26:08.187480Z",
     "iopub.status.idle": "2024-02-17T13:26:09.465648Z",
     "shell.execute_reply": "2024-02-17T13:26:09.465097Z",
     "shell.execute_reply.started": "2024-02-17T13:26:08.188075Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0+cu121'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "248dfee8-5446-43eb-80fd-9b627afe7962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T13:34:18.615943Z",
     "iopub.status.busy": "2024-02-17T13:34:18.615370Z",
     "iopub.status.idle": "2024-02-17T13:38:26.454652Z",
     "shell.execute_reply": "2024-02-17T13:38:26.454191Z",
     "shell.execute_reply.started": "2024-02-17T13:34:18.615917Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46cbb482ca0c4f8dba2edf4aa1b66a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f51ebc7ce64ca58a701bcf60aeaa64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e19950e3f941d7927fb8dbabc0a435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/397M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6984d046a02d48e5bd68430bb6d6b498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"croissantllm/CroissantLLMBase\", use_safetensors=True, torch_dtype=\"auto\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f1fb7-b75d-421d-bc95-6bb9f0537828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "input_ids = torch.randint(low=0, high=32000, size=(50,1024), dtype=torch.int64).to(model.device)\n",
    "attention_mask = torch.ones(50,1024).to(model.device)\n",
    "model.eval()\n",
    "\n",
    "with profile(\n",
    "  activities=[ProfilerActivity.CPU,ProfilerActivity.CUDA],\n",
    "  with_stack=True,\n",
    "  experimental_config=torch._C._profiler._ExperimentalConfig(verbose=True)\n",
    ") as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, use_cache=False, output_attentions=False, output_hidden_states=False) \n",
    "\n",
    "print(prof.key_averages().table())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e655b176-3bd9-4309-b5fa-4902fa1ac57e",
   "metadata": {},
   "source": [
    "```\n",
    "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
    "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
    "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
    "                                        model_inference         0.18%      14.742ms         9.70%     799.770ms     799.770ms       0.000us         0.00%        8.176s        8.176s             1  \n",
    "                                           aten::arange         0.00%     106.000us         0.10%       8.467ms       4.234ms       1.000us         0.00%       6.000us       3.000us             2  \n",
    "                                            aten::empty         0.03%       2.493ms         0.03%       2.493ms      25.439us       0.000us         0.00%       0.000us       0.000us            98  \n",
    "                                          aten::resize_         0.00%      56.000us         0.01%       1.044ms     522.000us       0.000us         0.00%       0.000us       0.000us             2  \n",
    "                                       cudaLaunchKernel         8.78%     723.549ms         8.78%     723.549ms     826.913us     328.621ms         4.29%     328.621ms     375.567us           875  \n",
    "void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us       1.000us         0.00%       1.000us       1.000us             1  \n",
    "                                        aten::unsqueeze         0.00%     148.000us         0.00%     166.000us       3.388us       0.000us         0.00%       0.000us       0.000us            49  \n",
    "                                       aten::as_strided         0.00%     113.000us         0.00%     113.000us       0.187us       0.000us         0.00%       0.000us       0.000us           603  \n",
    "                                        aten::embedding         0.00%      87.000us         5.76%     474.649ms     474.649ms       0.000us         0.00%       1.314ms       1.314ms             1  \n",
    "                                          aten::reshape         0.00%     256.000us         0.01%     431.000us       1.781us       0.000us         0.00%       0.000us       0.000us           242  \n",
    "                                             aten::view         0.00%     225.000us         0.00%     225.000us       0.714us       0.000us         0.00%       0.000us       0.000us           315  \n",
    "                                     aten::index_select         0.00%     117.000us         5.76%     474.543ms     474.543ms       1.314ms         0.02%       1.314ms       1.314ms             1  \n",
    "                                  cudaStreamIsCapturing         0.00%      44.000us         0.00%      44.000us       1.128us       3.053ms         0.04%       3.053ms      78.282us            39  \n",
    "                                             cudaMalloc         0.18%      14.599ms         0.18%      14.599ms     811.056us      60.387ms         0.79%      60.387ms       3.355ms            18  \n",
    "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us       1.314ms         0.02%       1.314ms       1.314ms             1  \n",
    "                                               aten::eq         0.00%     101.000us         0.08%       6.894ms       6.894ms       2.000us         0.00%       2.000us       2.000us             1  \n",
    "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.000us         0.00%       2.000us       2.000us             1  \n",
    "                                              aten::all         0.00%      78.000us         0.06%       5.293ms       5.293ms       7.000us         0.00%       7.000us       7.000us             1  \n",
    "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       7.000us         0.00%       7.000us       7.000us             1  \n",
    "                                       aten::is_nonzero         0.00%       8.000us         0.00%      65.000us      65.000us       0.000us         0.00%       2.000us       2.000us             1  \n",
    "                                             aten::item         0.00%       5.000us         0.00%      57.000us      57.000us       0.000us         0.00%       2.000us       2.000us             1  \n",
    "                              aten::_local_scalar_dense         0.00%      13.000us         0.00%      52.000us      52.000us       2.000us         0.00%       2.000us       2.000us             1  \n",
    "                                        cudaMemcpyAsync         0.00%      34.000us         0.00%      34.000us      34.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
    "                       Memcpy DtoH (Device -> Pageable)         0.00%       0.000us         0.00%       0.000us       0.000us       2.000us         0.00%       2.000us       2.000us             1  \n",
    "                                  cudaStreamSynchronize         0.00%       5.000us         0.00%       5.000us       5.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
    "                                               aten::to         0.00%       3.000us         0.00%       3.000us       0.015us       0.000us         0.00%       0.000us       0.000us           196  \n",
    "                                              aten::pow         0.01%     743.000us         0.32%      26.170ms     534.082us      60.137ms         0.79%     100.702ms       2.055ms            49  \n",
    "                                      aten::result_type         0.00%       1.000us         0.00%       1.000us       0.020us       0.000us         0.00%       0.000us       0.000us            49  \n",
    "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      60.137ms         0.79%      60.137ms       1.227ms            49  \n",
    "                                             aten::mean         0.01%     796.000us         0.06%       5.092ms     103.918us      29.301ms         0.38%      30.752ms     627.592us            49  \n",
    "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      29.301ms         0.38%      29.301ms     597.980us            49  \n",
    "                                              aten::add         0.02%       1.602ms         0.14%      11.149ms      76.890us     175.393ms         2.29%     205.720ms       1.419ms           145  \n",
    "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      97.000us         0.00%      97.000us       1.980us            49  \n",
    "                                            aten::rsqrt         0.01%     512.000us         0.24%      19.560ms     399.184us      74.000us         0.00%      19.662ms     401.265us            49  \n",
    "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      74.000us         0.00%      74.000us       1.510us            49  \n",
    "                                              aten::mul         0.03%       2.408ms         0.15%      11.959ms      54.858us     356.785ms         4.66%     394.627ms       1.810ms           218  \n",
    "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     238.789ms         3.12%     238.789ms       1.231ms           194  \n",
    "                                           aten::linear         0.01%       1.139ms         0.38%      31.700ms     187.574us       0.000us         0.00%        6.567s      38.856ms           169  \n",
    "                                                aten::t         0.00%     392.000us         0.01%     735.000us       4.349us       0.000us         0.00%       0.000us       0.000us           169  \n",
    "                                        aten::transpose         0.01%     616.000us         0.01%     686.000us       1.900us       0.000us         0.00%       0.000us       0.000us           361  \n",
    "                                           aten::matmul         0.01%     948.000us         0.37%      30.510ms     180.533us       0.000us         0.00%        6.746s      39.918ms           169  \n",
    "                                               aten::mm         0.07%       5.818ms         0.35%      29.144ms     172.450us        6.465s        84.47%        6.746s      39.918ms           169  \n",
    "                                               cudaFree         0.15%      12.242ms         0.15%      12.242ms       6.121ms       1.446ms         0.02%       1.446ms     723.000us             2  \n",
    "                                 cudaDeviceGetAttribute         0.00%       0.000us         0.00%       0.000us       0.000us      18.023ms         0.24%      18.023ms       1.202ms            15  \n",
    "                                   cudaGetSymbolAddress         0.00%     154.000us         0.00%     154.000us     154.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
    "          cudaOccupancyMaxActiveBlocksPerMultiprocessor         0.03%       2.499ms         0.03%       2.499ms      24.990us      86.611ms         1.13%      86.611ms     866.110us           100  \n",
    "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us        2.033s        26.56%        2.033s      21.181ms            96  \n",
    "                                     aten::_unsafe_view         0.00%     101.000us         0.00%     101.000us       0.598us       0.000us         0.00%       0.000us       0.000us           169  \n",
    "                                            aten::slice         0.01%     421.000us         0.01%     433.000us       3.007us       0.000us         0.00%       0.000us       0.000us           144  \n",
    "                                            aten::index         0.01%     908.000us         0.75%      61.806ms       1.288ms     289.000us         0.00%      57.657ms       1.201ms            48  \n",
    "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     289.000us         0.00%     289.000us       6.021us            48  \n",
    "                                              aten::neg         0.01%     543.000us         0.12%      10.080ms     210.000us      30.007ms         0.39%      56.006ms       1.167ms            48  \n",
    "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      30.007ms         0.39%      30.007ms     625.146us            48  \n",
    "                                              aten::cat         0.01%     718.000us         0.10%       8.464ms     176.333us      69.500ms         0.91%      71.949ms       1.499ms            48  \n",
    "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us      69.500ms         0.91%      69.500ms       1.448ms            48  \n",
    "                     aten::scaled_dot_product_attention         0.00%     237.000us         0.13%      10.731ms     447.125us       0.000us         0.00%     411.735ms      17.156ms            24  \n",
    "          aten::_scaled_dot_product_efficient_attention         0.00%     261.000us         0.13%      10.494ms     437.250us       0.000us         0.00%     411.735ms      17.156ms            24  \n",
    "                     aten::_efficient_attention_forward         0.00%     397.000us         0.12%      10.095ms     420.625us     387.076ms         5.06%     411.735ms      17.156ms            24  \n",
    "                                   cudaFuncSetAttribute         0.11%       9.238ms         0.11%       9.238ms     384.917us      23.438ms         0.31%      23.438ms     976.583us            24  \n",
    "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      87.549ms         1.14%      87.549ms       1.824ms            48  \n",
    "fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemE...         0.00%       0.000us         0.00%       0.000us       0.000us     387.076ms         5.06%     387.076ms      16.128ms            24  \n",
    "                                             aten::silu         0.00%     294.000us         1.15%      94.475ms       3.936ms      79.196ms         1.03%      79.794ms       3.325ms            24  \n",
    "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      87.747ms         1.15%      87.747ms       1.828ms            48  \n",
    "                                ampere_sgemm_128x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us        4.432s        57.90%        4.432s      60.712ms            73  \n",
    "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      79.196ms         1.03%      79.196ms       3.300ms            24  \n",
    "                                  cudaDeviceSynchronize        90.30%        7.443s        90.30%        7.443s        7.443s       0.000us         0.00%       0.000us       0.000us             1  \n",
    "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     117.996ms         1.54%     117.996ms       4.917ms            24  \n",
    "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
    "Self CPU time total: 8.243s\n",
    "Self CUDA time total: 7.654s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9434e7d-1b53-4546-8c86-8ba4af5a4a3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T10:25:17.631472Z",
     "iopub.status.busy": "2023-12-17T10:25:17.631159Z",
     "iopub.status.idle": "2023-12-17T10:25:21.469653Z",
     "shell.execute_reply": "2023-12-17T10:25:21.469006Z",
     "shell.execute_reply.started": "2023-12-17T10:25:17.631460Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask, use_cache=False, output_attentions=False, output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e7c5f63-d709-4c24-8311-3154ae7fc404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T11:23:14.213245Z",
     "iopub.status.busy": "2023-12-17T11:23:14.212624Z",
     "iopub.status.idle": "2023-12-17T11:23:14.216156Z",
     "shell.execute_reply": "2023-12-17T11:23:14.215683Z",
     "shell.execute_reply.started": "2023-12-17T11:23:14.213229Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def profile_model_inference(model, batch_size, seq_length):\n",
    "    input_ids = torch.randint(low=0, high=32000, size=(batch_size,seq_length), dtype=torch.int64).to(model.device)\n",
    "    attention_mask = torch.ones(batch_size,seq_length).to(model.device)\n",
    "    model.eval()\n",
    "    with torch.profiler.profile(record_shapes=True, profile_memory=True, with_stack=True, with_flops=True, with_modules=True, experimental_config=torch._C._profiler._ExperimentalConfig(verbose=True, enable_cuda_sync_events=True)) as prof:\n",
    "    #with torch.profiler.profile() as prof:\n",
    "        with torch.profiler.record_function(\"MODEL INFERENCE\"):\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, use_cache=False, output_attentions=False, output_hidden_states=False)        \n",
    "\n",
    "    return prof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc87e203-b681-473a-87ca-a917df9a97ef",
   "metadata": {},
   "source": [
    "**Initial Error Message**\n",
    "\n",
    "WARNING:2023-12-17 08:02:36 4992:4992 init.cpp:146] function cbapi->getCuptiStatus() failed with error CUPTI_ERROR_NOT_INITIALIZED (15)\n",
    "WARNING:2023-12-17 08:02:36 4992:4992 init.cpp:147] CUPTI initialization failed - CUDA profiler activities will be missing\n",
    "INFO:2023-12-17 08:02:36 4992:4992 init.cpp:149] If you see CUPTI_ERROR_INSUFFICIENT_PRIVILEGES, refer to https://developer.nvidia.com/nvidia-development-tools-solutions-err-nvgpuctrperm-cupti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "143e140a-7f48-4214-9c06-e51d6119b649",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T11:23:20.808010Z",
     "iopub.status.busy": "2023-12-17T11:23:20.807661Z",
     "iopub.status.idle": "2023-12-17T11:23:25.989768Z",
     "shell.execute_reply": "2023-12-17T11:23:25.989263Z",
     "shell.execute_reply.started": "2023-12-17T11:23:20.807998Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Log file: /tmp/libkineto_activities_2304.json\n",
      "  Trace start time: 2023-12-17 11:23:27  Trace duration: 500ms\n",
      "  Warmup duration: 5s\n",
      "  Max GPU buffer size: 128MB\n",
      "  Enabled activities: cpu_op,user_annotation,gpu_user_annotation,gpu_memcpy,gpu_memset,kernel,external_correlation,cuda_runtime,cuda_driver,cpu_instant_event,python_function,cuda_sync,xpu_runtime\n",
      "INFO:2023-12-17 11:23:20 2304:2304 CuptiActivityProfiler.cpp:834] Enabling GPU tracing\n",
      "INFO:2023-12-17 11:23:20 2304:2304 CuptiActivityProfiler.cpp:873] Tracing starting in 6s\n",
      "INFO:2023-12-17 11:23:20 2304:2304 CuptiActivityProfiler.cpp:878] Tracing will end in 7s\n",
      "STAGE:2023-12-17 11:23:20 2304:2304 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2023-12-17 11:23:25 2304:2304 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "INFO:2023-12-17 11:23:25 2304:2304 CuptiActivityProfiler.cpp:232] Processing 1 CPU buffers\n",
      "INFO:2023-12-17 11:23:25 2304:2304 CuptiActivityProfiler.cpp:262] Processed 47046 GPU records (1596120 bytes)\n",
      "INFO:2023-12-17 11:23:25 2304:2304 CuptiActivityProfiler.cpp:294] Error info: Out-of-range = 1223, Blocklisted runtime = 11100, Invalid ext correlations = 0, CPU GPU out-of-order = 0, Unexpected CUDA events = 0, CUPTI stopped early? = 0\n",
      "INFO:2023-12-17 11:23:25 2304:2304 CuptiActivityProfiler.cpp:1060] Traces Recorded:\n",
      "INFO:2023-12-17 11:23:25 2304:2304 CuptiActivityProfiler.cpp:1063] PyTorch Profiler: 1 iterations\n",
      "STAGE:2023-12-17 11:23:25 2304:2304 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "prof = profile_model_inference(model, 50, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfae7fc7-4527-4990-90d7-4babd1276610",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T11:23:33.893719Z",
     "iopub.status.busy": "2023-12-17T11:23:33.893364Z",
     "iopub.status.idle": "2023-12-17T11:23:33.895878Z",
     "shell.execute_reply": "2023-12-17T11:23:33.895342Z",
     "shell.execute_reply.started": "2023-12-17T11:23:33.893706Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "events = prof.events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f850f989-4f2e-4c87-9826-c356bea63195",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T10:26:29.449482Z",
     "iopub.status.busy": "2023-12-17T10:26:29.449197Z",
     "iopub.status.idle": "2023-12-17T10:26:29.465567Z",
     "shell.execute_reply": "2023-12-17T10:26:29.465059Z",
     "shell.execute_reply.started": "2023-12-17T10:26:29.449470Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<ProfilerActivity.CPU: 0>, <ProfilerActivity.CUDA: 2>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof.activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2539ca60-e154-477b-b513-8175b496e917",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T10:26:31.150198Z",
     "iopub.status.busy": "2023-12-17T10:26:31.149954Z",
     "iopub.status.idle": "2023-12-17T10:26:31.159463Z",
     "shell.execute_reply": "2023-12-17T10:26:31.159017Z",
     "shell.execute_reply.started": "2023-12-17T10:26:31.150183Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3716415.0, 3716415.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = 0\n",
    "for event in events:\n",
    "    if event.cpu_parent is not None and event.cpu_parent.id == events[0].id:\n",
    "        total_time += event.cpu_time\n",
    "events[0].cpu_time ,total_time + events[0].self_cpu_time_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2e58728-c5c9-4088-b9b2-6f523961ca0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T11:23:39.877039Z",
     "iopub.status.busy": "2023-12-17T11:23:39.876602Z",
     "iopub.status.idle": "2023-12-17T11:23:39.879902Z",
     "shell.execute_reply": "2023-12-17T11:23:39.879242Z",
     "shell.execute_reply.started": "2023-12-17T11:23:39.877016Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = events[0].cpu_time/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9541e1e8-540d-43c3-8f0e-41b4f7ac98e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T11:23:43.388879Z",
     "iopub.status.busy": "2023-12-17T11:23:43.388466Z",
     "iopub.status.idle": "2023-12-17T11:23:43.395345Z",
     "shell.execute_reply": "2023-12-17T11:23:43.394942Z",
     "shell.execute_reply.started": "2023-12-17T11:23:43.388861Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 1.2154696132596685, 98.16356248190462)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = 0\n",
    "count_events = 0\n",
    "count_threshold = 0\n",
    "for event in events:\n",
    "    if event.cpu_parent is not None and event.cpu_parent.id == events[0].id:\n",
    "        count_events += 1\n",
    "        if event.cpu_time>=threshold:\n",
    "            count_threshold += 1\n",
    "            total_time += event.cpu_time\n",
    "count_threshold, count_threshold/count_events*100, total_time/events[0].cpu_time*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b22dc2-1225-4c88-83f7-56f0431e71cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for event in events:\n",
    "    if event.cpu_parent is not None and event.cpu_parent.id == events[0].id:\n",
    "        if event.cpu_time>=threshold:\n",
    "            print(event.name, int(event.cpu_time), f\"{(event.cpu_time/events[0].cpu_time*100):.2f} %\")\n",
    "            if event.cpu_children is not None:\n",
    "                for child_event in event.cpu_children:\n",
    "                    if child_event.cpu_time>=threshold:\n",
    "                        print(\"-\", child_event.name, int(child_event.cpu_time), f\"{(child_event.cpu_time/event.cpu_time*100):.2f} %\")\n",
    "                        if child_event.cpu_children is not None:\n",
    "                            for grandchild_event in child_event.cpu_children:\n",
    "                                if grandchild_event.cpu_time>=threshold:\n",
    "                                    print(\" \",\"-\", grandchild_event.name, int(grandchild_event.cpu_time), f\"{(grandchild_event.cpu_time/event.cpu_time*100):.2f} %\")\n",
    "                                    if grandchild_event.cpu_children is not None:\n",
    "                                        for Grandchild_event in grandchild_event.cpu_children:\n",
    "                                            if Grandchild_event.cpu_time>=threshold:\n",
    "                                                print(\" \",\" \",\"-\", Grandchild_event.name, int(Grandchild_event.cpu_time), f\"{(Grandchild_event.cpu_time/event.cpu_time*100):.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b772509-35f9-4b4a-8435-57da2e53e8c9",
   "metadata": {},
   "source": [
    "```\n",
    "aten::arange 2361 3.12 %\n",
    "- aten::empty 2170 91.91 %\n",
    "- aten::arange 133 5.63 %\n",
    "aten::embedding 142 0.19 %\n",
    "- aten::index_select 109 76.76 %\n",
    "aten::eq 81 0.11 %\n",
    "aten::is_nonzero 1092 1.44 %\n",
    "- aten::item 1086 99.45 %\n",
    "  - aten::_local_scalar_dense 1082 99.08 %\n",
    "    - cudaMemcpyAsync 1061 97.16 %\n",
    "aten::pow 77 0.10 %\n",
    "aten::rsqrt 696 0.92 %\n",
    "- cudaMalloc 615 88.36 %\n",
    "aten::linear 211 0.28 %\n",
    "- aten::matmul 169 80.09 %\n",
    "  - aten::mm 127 60.19 %\n",
    "aten::linear 132 0.17 %\n",
    "- aten::matmul 109 82.58 %\n",
    "  - aten::mm 77 58.33 %\n",
    "aten::linear 122 0.16 %\n",
    "- aten::matmul 100 81.97 %\n",
    "aten::index 104 0.14 %\n",
    "aten::scaled_dot_product_attention 203 0.27 %\n",
    "- aten::_scaled_dot_product_efficient_attention 166 81.77 %\n",
    "  - aten::_efficient_attention_forward 102 50.25 %\n",
    "aten::linear 134 0.18 %\n",
    "- aten::matmul 113 84.33 %\n",
    "  - aten::mm 82 61.19 %\n",
    "aten::linear 111 0.15 %\n",
    "- aten::matmul 89 80.18 %\n",
    "aten::linear 104 0.14 %\n",
    "- aten::matmul 78 75.00 %\n",
    "aten::linear 94 0.12 %\n",
    "aten::linear 123 0.16 %\n",
    "- aten::matmul 101 82.11 %\n",
    "aten::linear 102 0.13 %\n",
    "- aten::matmul 85 83.33 %\n",
    "aten::linear 103 0.14 %\n",
    "- aten::matmul 85 82.52 %\n",
    "aten::scaled_dot_product_attention 158 0.21 %\n",
    "- aten::_scaled_dot_product_efficient_attention 134 84.81 %\n",
    "  - aten::_efficient_attention_forward 86 54.43 %\n",
    "aten::linear 118 0.16 %\n",
    "- aten::matmul 101 85.59 %\n",
    "aten::linear 111 0.15 %\n",
    "- aten::matmul 87 78.38 %\n",
    "aten::linear 95 0.13 %\n",
    "- aten::matmul 76 80.00 %\n",
    "aten::linear 91 0.12 %\n",
    "aten::linear 120 0.16 %\n",
    "- aten::matmul 98 81.67 %\n",
    "aten::linear 106 0.14 %\n",
    "- aten::matmul 86 81.13 %\n",
    "aten::linear 101 0.13 %\n",
    "- aten::matmul 83 82.18 %\n",
    "aten::scaled_dot_product_attention 155 0.21 %\n",
    "- aten::_scaled_dot_product_efficient_attention 135 87.10 %\n",
    "  - aten::_efficient_attention_forward 86 55.48 %\n",
    "aten::linear 122 0.16 %\n",
    "- aten::matmul 104 85.25 %\n",
    "aten::linear 108 0.14 %\n",
    "- aten::matmul 85 78.70 %\n",
    "aten::linear 94 0.12 %\n",
    "aten::linear 93 0.12 %\n",
    "aten::linear 123 0.16 %\n",
    "- aten::matmul 99 80.49 %\n",
    "aten::linear 98 0.13 %\n",
    "- aten::matmul 82 83.67 %\n",
    "aten::linear 99 0.13 %\n",
    "- aten::matmul 82 82.83 %\n",
    "aten::scaled_dot_product_attention 152 0.20 %\n",
    "- aten::_scaled_dot_product_efficient_attention 132 86.84 %\n",
    "  - aten::_efficient_attention_forward 84 55.26 %\n",
    "aten::linear 131 0.17 %\n",
    "- aten::matmul 102 77.86 %\n",
    "aten::linear 122 0.16 %\n",
    "- aten::matmul 88 72.13 %\n",
    "aten::linear 94 0.12 %\n",
    "aten::linear 96 0.13 %\n",
    "aten::linear 120 0.16 %\n",
    "- aten::matmul 98 81.67 %\n",
    "aten::linear 99 0.13 %\n",
    "- aten::matmul 83 83.84 %\n",
    "aten::linear 105 0.14 %\n",
    "- aten::matmul 85 80.95 %\n",
    "aten::scaled_dot_product_attention 181 0.24 %\n",
    "- aten::_scaled_dot_product_efficient_attention 161 88.95 %\n",
    "  - aten::_efficient_attention_forward 102 56.35 %\n",
    "aten::linear 119 0.16 %\n",
    "- aten::matmul 102 85.71 %\n",
    "aten::linear 108 0.14 %\n",
    "- aten::matmul 85 78.70 %\n",
    "aten::linear 102 0.13 %\n",
    "- aten::matmul 78 76.47 %\n",
    "aten::linear 112 0.15 %\n",
    "- aten::matmul 92 82.14 %\n",
    "aten::linear 124 0.16 %\n",
    "- aten::matmul 99 79.84 %\n",
    "aten::linear 103 0.14 %\n",
    "- aten::matmul 84 81.55 %\n",
    "aten::linear 102 0.13 %\n",
    "- aten::matmul 84 82.35 %\n",
    "aten::scaled_dot_product_attention 164 0.22 %\n",
    "- aten::_scaled_dot_product_efficient_attention 144 87.80 %\n",
    "  - aten::_efficient_attention_forward 86 52.44 %\n",
    "aten::linear 117 0.15 %\n",
    "- aten::matmul 100 85.47 %\n",
    "aten::linear 110 0.15 %\n",
    "- aten::matmul 86 78.18 %\n",
    "aten::linear 94 0.12 %\n",
    "- aten::matmul 76 80.85 %\n",
    "aten::linear 92 0.12 %\n",
    "aten::linear 121 0.16 %\n",
    "- aten::matmul 97 80.17 %\n",
    "aten::linear 98 0.13 %\n",
    "- aten::matmul 81 82.65 %\n",
    "aten::linear 97 0.13 %\n",
    "- aten::matmul 80 82.47 %\n",
    "aten::scaled_dot_product_attention 151 0.20 %\n",
    "- aten::_scaled_dot_product_efficient_attention 131 86.75 %\n",
    "  - aten::_efficient_attention_forward 84 55.63 %\n",
    "aten::transpose 79 0.10 %\n",
    "aten::linear 118 0.16 %\n",
    "- aten::matmul 102 86.44 %\n",
    "aten::linear 106 0.14 %\n",
    "- aten::matmul 84 79.25 %\n",
    "aten::linear 92 0.12 %\n",
    "aten::linear 91 0.12 %\n",
    "aten::linear 123 0.16 %\n",
    "- aten::matmul 99 80.49 %\n",
    "aten::linear 100 0.13 %\n",
    "- aten::matmul 83 83.00 %\n",
    "aten::linear 104 0.14 %\n",
    "- aten::matmul 85 81.73 %\n",
    "aten::scaled_dot_product_attention 151 0.20 %\n",
    "- aten::_scaled_dot_product_efficient_attention 131 86.75 %\n",
    "  - aten::_efficient_attention_forward 85 56.29 %\n",
    "aten::linear 117 0.15 %\n",
    "- aten::matmul 100 85.47 %\n",
    "aten::linear 106 0.14 %\n",
    "- aten::matmul 82 77.36 %\n",
    "aten::linear 91 0.12 %\n",
    "aten::linear 92 0.12 %\n",
    "aten::linear 123 0.16 %\n",
    "- aten::matmul 99 80.49 %\n",
    "aten::linear 98 0.13 %\n",
    "- aten::matmul 81 82.65 %\n",
    "aten::linear 99 0.13 %\n",
    "- aten::matmul 82 82.83 %\n",
    "aten::scaled_dot_product_attention 154 0.20 %\n",
    "- aten::_scaled_dot_product_efficient_attention 132 85.71 %\n",
    "  - aten::_efficient_attention_forward 85 55.19 %\n",
    "aten::linear 118 0.16 %\n",
    "- aten::matmul 102 86.44 %\n",
    "aten::linear 108 0.14 %\n",
    "- aten::matmul 86 79.63 %\n",
    "aten::linear 97 0.13 %\n",
    "- aten::matmul 78 80.41 %\n",
    "aten::linear 97 0.13 %\n",
    "- aten::matmul 76 78.35 %\n",
    "aten::linear 153 0.20 %\n",
    "- aten::matmul 128 83.66 %\n",
    "  - aten::mm 91 59.48 %\n",
    "aten::linear 111 0.15 %\n",
    "- aten::matmul 91 81.98 %\n",
    "aten::linear 109 0.14 %\n",
    "- aten::matmul 90 82.57 %\n",
    "aten::index 79 0.10 %\n",
    "aten::scaled_dot_product_attention 169 0.22 %\n",
    "- aten::_scaled_dot_product_efficient_attention 147 86.98 %\n",
    "  - aten::_efficient_attention_forward 96 56.80 %\n",
    "aten::linear 131 0.17 %\n",
    "- aten::matmul 112 85.50 %\n",
    "  - aten::mm 81 61.83 %\n",
    "aten::linear 121 0.16 %\n",
    "- aten::matmul 98 80.99 %\n",
    "aten::linear 96 0.13 %\n",
    "- aten::matmul 77 80.21 %\n",
    "aten::linear 95 0.13 %\n",
    "aten::linear 110 0.15 %\n",
    "- aten::matmul 91 82.73 %\n",
    "aten::linear 80 0.11 %\n",
    "aten::linear 78 0.10 %\n",
    "aten::scaled_dot_product_attention 116 0.15 %\n",
    "- aten::_scaled_dot_product_efficient_attention 100 86.21 %\n",
    "aten::linear 91 0.12 %\n",
    "- aten::matmul 79 86.81 %\n",
    "aten::linear 82 0.11 %\n",
    "aten::linear 95 0.13 %\n",
    "- aten::matmul 78 82.11 %\n",
    "aten::linear 79 0.10 %\n",
    "aten::linear 84 0.11 %\n",
    "aten::scaled_dot_product_attention 116 0.15 %\n",
    "- aten::_scaled_dot_product_efficient_attention 101 87.07 %\n",
    "aten::linear 91 0.12 %\n",
    "- aten::matmul 78 85.71 %\n",
    "aten::linear 84 0.11 %\n",
    "aten::linear 78 0.10 %\n",
    "aten::linear 94 0.12 %\n",
    "- aten::matmul 76 80.85 %\n",
    "aten::linear 88 0.12 %\n",
    "aten::linear 79 0.10 %\n",
    "aten::scaled_dot_product_attention 114 0.15 %\n",
    "- aten::_scaled_dot_product_efficient_attention 99 86.84 %\n",
    "aten::linear 90 0.12 %\n",
    "- aten::matmul 76 84.44 %\n",
    "aten::linear 83 0.11 %\n",
    "aten::linear 84 0.11 %\n",
    "aten::linear 104 0.14 %\n",
    "- aten::matmul 78 75.00 %\n",
    "aten::linear 81 0.11 %\n",
    "aten::linear 76 0.10 %\n",
    "aten::scaled_dot_product_attention 115 0.15 %\n",
    "- aten::_scaled_dot_product_efficient_attention 100 86.96 %\n",
    "aten::linear 90 0.12 %\n",
    "- aten::matmul 77 85.56 %\n",
    "aten::linear 81 0.11 %\n",
    "aten::linear 96 0.13 %\n",
    "- aten::matmul 76 79.17 %\n",
    "aten::linear 79 0.10 %\n",
    "aten::linear 77 0.10 %\n",
    "aten::scaled_dot_product_attention 115 0.15 %\n",
    "- aten::_scaled_dot_product_efficient_attention 100 86.96 %\n",
    "aten::linear 91 0.12 %\n",
    "- aten::matmul 78 85.71 %\n",
    "aten::linear 83 0.11 %\n",
    "aten::linear 81 0.11 %\n",
    "aten::linear 97 0.13 %\n",
    "- aten::matmul 77 79.38 %\n",
    "aten::linear 80 0.11 %\n",
    "aten::linear 77 0.10 %\n",
    "aten::scaled_dot_product_attention 115 0.15 %\n",
    "- aten::_scaled_dot_product_efficient_attention 100 86.96 %\n",
    "aten::linear 90 0.12 %\n",
    "- aten::matmul 78 86.67 %\n",
    "aten::linear 82 0.11 %\n",
    "aten::linear 80 0.11 %\n",
    "aten::linear 97 0.13 %\n",
    "- aten::matmul 77 79.38 %\n",
    "aten::linear 77 0.10 %\n",
    "aten::linear 78 0.10 %\n",
    "aten::scaled_dot_product_attention 123 0.16 %\n",
    "- aten::_scaled_dot_product_efficient_attention 108 87.80 %\n",
    "aten::linear 91 0.12 %\n",
    "- aten::matmul 78 85.71 %\n",
    "aten::linear 147 0.19 %\n",
    "aten::linear 93 0.12 %\n",
    "- aten::matmul 76 81.72 %\n",
    "aten::linear 83 0.11 %\n",
    "aten::linear 78 0.10 %\n",
    "aten::scaled_dot_product_attention 124 0.16 %\n",
    "- aten::_scaled_dot_product_efficient_attention 109 87.90 %\n",
    "aten::linear 91 0.12 %\n",
    "- aten::matmul 77 84.62 %\n",
    "aten::linear 84 0.11 %\n",
    "aten::linear 100 0.13 %\n",
    "- aten::matmul 81 81.00 %\n",
    "aten::linear 79 0.10 %\n",
    "aten::linear 79 0.10 %\n",
    "aten::scaled_dot_product_attention 115 0.15 %\n",
    "- aten::_scaled_dot_product_efficient_attention 100 86.96 %\n",
    "aten::linear 93 0.12 %\n",
    "- aten::matmul 78 83.87 %\n",
    "aten::linear 82 0.11 %\n",
    "aten::linear 76 0.10 %\n",
    "aten::linear 106 0.14 %\n",
    "- aten::matmul 88 83.02 %\n",
    "aten::linear 83 0.11 %\n",
    "aten::scaled_dot_product_attention 80 0.11 %\n",
    "aten::linear 93 0.12 %\n",
    "aten::scaled_dot_product_attention 83 0.11 %\n",
    "aten::scaled_dot_product_attention 113 0.15 %\n",
    "- aten::_scaled_dot_product_efficient_attention 103 91.15 %\n",
    "  - aten::_efficient_attention_forward 81 71.68 %\n",
    "aten::linear 4787 6.33 %\n",
    "- aten::matmul 4775 99.75 %\n",
    "  - aten::mm 4755 99.33 %\n",
    "    - cudaMalloc 4710 98.39 %\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b448759-b639-47a5-be2e-1bd1cd81036b",
   "metadata": {},
   "source": [
    "Jarvislabs Pytorch VM config:\n",
    "\n",
    "### Jeremy Howard : How to install Pytorch and cuda with conda\n",
    "\n",
    "https://twitter.com/jeremyphoward/status/1697435241152127369\n",
    "\n",
    "1. Install miniconda\n",
    "\n",
    "https://github.com/fastai/fastsetup/blob/master/setup-conda.sh\n",
    "\n",
    "2. Find out what CUDA version PyTorch expects by going to their website and seeing what the latest \"compute platform\" version is.\n",
    "\n",
    "https://pytorch.org/\n",
    "\n",
    "> conda install pytorch ... pytorch-cuda=12.1 ...\n",
    "\n",
    "3. Install CUDA\n",
    "\n",
    "```\n",
    "conda install cuda -c nvidia/label/cuda-12.1.0\n",
    "```\n",
    "\n",
    "4.Copy the command to install pytorch from their website, but replace `-c nvidia` with a version specific label, as shown below:\n",
    "\n",
    "```\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia/label/cuda-12.1.0`\n",
    "```\n",
    "\n",
    "### ubuntu version\n",
    "\n",
    "```\n",
    "root@ac9978bd266c:~# lsb_release -a\n",
    "No LSB modules are available.\n",
    "Distributor ID: Ubuntu\n",
    "Description:    Ubuntu 22.04.3 LTS\n",
    "Release:        22.04\n",
    "Codename:       jammy\n",
    "\n",
    "root@ac9978bd266c:~# uname -a\n",
    "Linux ac9978bd266c 5.15.0-89-generic #99-Ubuntu SMP Mon Oct 30 20:42:41 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux\n",
    "\n",
    "root@ac9978bd266c:~# cat /etc/os-release\n",
    "PRETTY_NAME=\"Ubuntu 22.04.3 LTS\"\n",
    "NAME=\"Ubuntu\"\n",
    "VERSION_ID=\"22.04\"\n",
    "VERSION=\"22.04.3 LTS (Jammy Jellyfish)\"\n",
    "VERSION_CODENAME=jammy\n",
    "ID=ubuntu\n",
    "ID_LIKE=debian\n",
    "HOME_URL=\"https://www.ubuntu.com/\"\n",
    "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
    "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
    "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
    "UBUNTU_CODENAME=jammy\n",
    "```\n",
    "\n",
    "### container setup\n",
    "\n",
    "Docker container ID\n",
    "\n",
    "```\n",
    "root@ac9978bd266c:~# echo $HOSTNAME\n",
    "ac9978bd266c\n",
    "```\n",
    "\n",
    "Docker container entrypoint\n",
    "\n",
    "```\n",
    "root@ac9978bd266c:~# cat /docker-entrypoint.sh\n",
    "#!/bin/bash\n",
    "source /opt/conda/etc/profile.d/conda.sh\n",
    "conda activate py3.10                   \n",
    "echo \"PasswordAuthentication no\" >> /etc/ssh/sshd_config\n",
    "service ssh start\n",
    "export SHELL=\"/bin/bash\"\n",
    "\n",
    "env HOME=/home code-server --host 0.0.0.0 --port 7007 --auth none&\n",
    "env HOME=/home jupyter lab --ip=0.0.0.0 --NotebookApp.token=$TOKEN  --allow-root --port 8889\n",
    "```\n",
    "\n",
    "```\n",
    "root@ac9978bd266c:~# ps aux\n",
    "USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n",
    "root           1  0.0  0.0   4360  3392 ?        Ss   08:26   0:00 /bin/bash /docker-entrypoint.sh\n",
    "root          18  0.0  0.0  15428  3732 ?        Ss   08:26   0:00 sshd: /usr/sbin/sshd [listener] 0 of 10-100 startups\n",
    "root          19  0.0  0.0 1238088 64232 ?       Sl   08:26   0:00 /usr/lib/code-server/lib/node /usr/lib/code-server --host 0.0.0.0 --port 7007 --auth none\n",
    "root          20  0.2  0.0 888616 94924 ?        Rl   08:26   0:07 /root/miniconda3/envs/py3.10/bin/python /root/miniconda3/envs/py3.10/bin/jupyter-lab --ip=0.0.0.0 --NotebookApp.token=3vAcOEC8d551ymv0ppLqoR69HaQEfJB-1KEiXP1WwS8WlZbWf0_R7tCOxXoV8T8G --allo\n",
    "root          46  0.0  0.0 1172236 64432 ?       Sl   08:26   0:00 /usr/lib/code-server/lib/node /usr/lib/code-server/out/node/entry\n",
    "```\n",
    "\n",
    "Jarvislab Urls\n",
    "\n",
    "- Jupyterlab: https://ac9978bd266c.notebooksh.jarvislabs.net/\n",
    "- VS Code:    https://ac9978bd266c0.notebooksh.jarvislabs.net/\n",
    "- Any service listening on port 6006 inside the container: https://ac9978bd266c1.notebooksh.jarvislabs.net/\n",
    "\n",
    "### miniconda install\n",
    "\n",
    "```\n",
    "root@ac9978bd266c:/root/miniconda3# which conda\n",
    "/root/miniconda3/bin/conda\n",
    "\n",
    "root@ac9978bd266c:/root/miniconda3# conda --version\n",
    "conda 23.11.0\n",
    "\n",
    "root@ac9978bd266c:~# which python\n",
    "/root/miniconda3/envs/py3.10/bin/python\n",
    "\n",
    "root@ac9978bd266c:/root/miniconda3# python --version\n",
    "Python 3.10.13\n",
    "```\n",
    "\n",
    "### miniconda environments\n",
    "\n",
    "```\n",
    "root@ac9978bd266c:/root/miniconda3# conda env list\n",
    "base                     /root/miniconda3\n",
    "py3.10                   /root/miniconda3/envs/py3.10\n",
    "\n",
    "root@ac9978bd266c:/root/miniconda3/envs/py3.10/conda-meta# cat history \n",
    "==> 2024-01-30 10:00:19 <==\n",
    "# cmd: /root/miniconda3/bin/conda create -n py3.10 python=3.10\n",
    "# conda version: 23.11.0\n",
    "```\n",
    "\n",
    "### apt source\n",
    "\n",
    "https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64 \n",
    "\n",
    "### nvidia packages\n",
    "\n",
    "```\n",
    "cuda-cccl-12-3/unknown,now 12.3.101-1 amd64 [installed,automatic]\n",
    "cuda-compat-12-3/unknown,now 545.23.08-1 amd64 [installed]\n",
    "cuda-cudart-12-3/unknown,now 12.3.101-1 amd64 [installed]\n",
    "cuda-cudart-dev-12-3/unknown,now 12.3.101-1 amd64 [installed]\n",
    "cuda-cuobjdump-12-3/unknown,now 12.3.101-1 amd64 [installed,automatic]\n",
    "cuda-cupti-12-3/unknown,now 12.3.101-1 amd64 [installed,automatic]\n",
    "cuda-cupti-dev-12-3/unknown,now 12.3.101-1 amd64 [installed,automatic]\n",
    "cuda-cuxxfilt-12-3/unknown,now 12.3.101-1 amd64 [installed,automatic]\n",
    "cuda-driver-dev-12-3/unknown,now 12.3.101-1 amd64 [installed,automatic]\n",
    "cuda-gdb-12-3/unknown,now 12.3.101-1 amd64 [installed,automatic]\n",
    "cuda-nvdisasm-12-3/unknown,now 12.3.101-1 amd64 [installed,automatic]\n",
    "cuda-nvml-dev-12-3/unknown,now 12.3.101-1 amd64 [installed]\n",
    "cuda-nvprof-12-3/unknown,now 12.3.101-1 amd64 [installed]\n",
    "cuda-nvprune-12-3/unknown,now 12.3.101-1 amd64 [installed,automatic]\n",
    "cuda-nvtx-12-3/unknown,now 12.3.101-1 amd64 [installed]\n",
    "cuda-opencl-12-3/unknown,now 12.3.101-1 amd64 [installed,automatic]\n",
    "cuda-opencl-dev-12-3/unknown,now 12.3.101-1 amd64 [installed,automatic]\n",
    "cuda-profiler-api-12-3/unknown,now 12.3.101-1 amd64 [installed,automatic]\n",
    "cuda-sanitizer-12-3/unknown,now 12.3.101-1 amd64 [installed,automatic]\n",
    "cuda-toolkit-12-3-config-common/unknown,now 12.3.101-1 all [installed,automatic]\n",
    "cuda-toolkit-12-config-common/unknown,now 12.3.101-1 all [installed,automatic]\n",
    "cuda-toolkit-config-common/unknown,now 12.3.101-1 all [installed,automatic]\n",
    "libcublas-12-3/unknown,now 12.3.4.1-1 amd64 [installed]\n",
    "libcublas-dev-12-3/unknown,now 12.3.4.1-1 amd64 [installed]\n",
    "libcufft-12-3/unknown,now 11.0.12.1-1 amd64 [installed,automatic]\n",
    "libcufft-dev-12-3/unknown,now 11.0.12.1-1 amd64 [installed,automatic]\n",
    "libcufile-12-3/unknown,now 1.8.1.2-1 amd64 [installed,automatic]\n",
    "libcufile-dev-12-3/unknown,now 1.8.1.2-1 amd64 [installed,automatic]\n",
    "libcusolver-12-3/unknown,now 11.5.4.101-1 amd64 [installed,automatic]\n",
    "libcusolver-dev-12-3/unknown,now 11.5.4.101-1 amd64 [installed,automatic]\n",
    "libcusparse-12-3/unknown,now 12.2.0.103-1 amd64 [installed]\n",
    "libcusparse-dev-12-3/unknown,now 12.2.0.103-1 amd64 [installed]\n",
    "libnpp-12-3/unknown,now 12.2.3.2-1 amd64 [installed]\n",
    "libnpp-dev-12-3/unknown,now 12.2.3.2-1 amd64 [installed]\n",
    "libnvjitlink-12-3/unknown,now 12.3.101-1 amd64 [installed,automatic]\n",
    "libnvjitlink-dev-12-3/unknown,now 12.3.101-1 amd64 [installed,automatic]\n",
    "libnvjpeg-12-3/unknown,now 12.3.0.81-1 amd64 [installed,automatic]\n",
    "libnvjpeg-dev-12-3/unknown,now 12.3.0.81-1 amd64 [installed,automatic]\n",
    "nsight-compute-2023.3.1/unknown,now 2023.3.1.1-1 amd64 [installed,automatic]\n",
    "```\n",
    "\n",
    "### Environment variables\n",
    "\n",
    "```\n",
    "NV_LIBCUBLAS_VERSION=12.3.4.1-1\n",
    "NVIDIA_VISIBLE_DEVICES=3\n",
    "NV_NVML_DEV_VERSION=12.3.101-1\n",
    "NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.19.3-1+cuda12.3\n",
    "NV_LIBNCCL_DEV_PACKAGE_VERSION=2.19.3-1\n",
    "PYTHON_VERSION=3.10\n",
    "NVIDIA_REQUIRE_CUDA=cuda>=12.3 brand=tesla,driver>=470,driver<471 brand=unknown,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=geforce,driver>=470,driver<471 brand=geforcertx,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=titan,driver>=470,driver<471 brand=titanrtx,driver>=470,driver<471 brand=tesla,driver>=525,driver<526 brand=unknown,driver>=525,driver<526 brand=nvidia,driver>=525,driver<526 brand=nvidiartx,driver>=525,driver<526 brand=geforce,driver>=525,driver<526 brand=geforcertx,driver>=525,driver<526 brand=quadro,driver>=525,driver<526 brand=quadrortx,driver>=525,driver<526 brand=titan,driver>=525,driver<526 brand=titanrtx,driver>=525,driver<526 brand=tesla,driver>=535,driver<536 brand=unknown,driver>=535,driver<536 brand=nvidia,driver>=535,driver<536 brand=nvidiartx,driver>=535,driver<536 brand=geforce,driver>=535,driver<536 brand=geforcertx,driver>=535,driver<536 brand=quadro,driver>=535,driver<536 brand=quadrortx,driver>=535,driver<536 brand=titan,driver>=535,driver<536 brand=titanrtx,driver>=535,driver<536\n",
    "NV_LIBCUBLAS_DEV_PACKAGE=libcublas-dev-12-3=12.3.4.1-1\n",
    "NV_NVTX_VERSION=12.3.101-1\n",
    "NV_CUDA_CUDART_DEV_VERSION=12.3.101-1\n",
    "NV_LIBCUSPARSE_VERSION=12.2.0.103-1\n",
    "NV_LIBNPP_VERSION=12.2.3.2-1\n",
    "NCCL_VERSION=2.19.3-1\n",
    "NVIDIA_DRIVER_CAPABILITIES=compute,utility\n",
    "NV_NVPROF_DEV_PACKAGE=cuda-nvprof-12-3=12.3.101-1\n",
    "NV_LIBNPP_PACKAGE=libnpp-12-3=12.2.3.2-1\n",
    "NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
    "NV_LIBCUBLAS_DEV_VERSION=12.3.4.1-1\n",
    "NVIDIA_PRODUCT_NAME=CUDA\n",
    "NV_LIBCUBLAS_DEV_PACKAGE_NAME=libcublas-dev-12-3\n",
    "NV_CUDA_CUDART_VERSION=12.3.101-1\n",
    "CUDA_VERSION=12.3.1\n",
    "NV_LIBCUBLAS_PACKAGE=libcublas-12-3=12.3.4.1-1\n",
    "NV_CUDA_NSIGHT_COMPUTE_DEV_PACKAGE=cuda-nsight-compute-12-3=12.3.1-1\n",
    "PYDEVD_USE_FRAME_EVAL=NO\n",
    "NV_LIBNPP_DEV_PACKAGE=libnpp-dev-12-3=12.2.3.2-1\n",
    "NV_LIBCUBLAS_PACKAGE_NAME=libcublas-12-3\n",
    "NV_LIBNPP_DEV_VERSION=12.2.3.2-1\n",
    "NV_LIBCUSPARSE_DEV_VERSION=12.2.0.103-1\n",
    "LIBRARY_PATH=/usr/local/cuda/lib64/stubs\n",
    "NV_CUDA_LIB_VERSION=12.3.1-1\n",
    "NVARCH=x86_64\n",
    "NV_CUDA_COMPAT_PACKAGE=cuda-compat-12-3\n",
    "NV_LIBNCCL_PACKAGE=libnccl2=2.19.3-1+cuda12.3\n",
    "LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
    "NV_CUDA_NSIGHT_COMPUTE_VERSION=12.3.1-1\n",
    "NV_NVPROF_VERSION=12.3.101-1\n",
    "PATH=/root/miniconda3/envs/py3.10/bin:/root/miniconda3/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
    "NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
    "NV_LIBNCCL_PACKAGE_VERSION=2.19.3-1\n",
    "```\n",
    "\n",
    "### python packages\n",
    "\n",
    "```\n",
    "libpython3-stdlib/jammy-updates,jammy-security,now 3.10.6-1~22.04 amd64 [installed,automatic]\n",
    "libpython3.10-minimal/jammy-updates,jammy-security,now 3.10.12-1~22.04.3 amd64 [installed,automatic]\n",
    "libpython3.10-stdlib/jammy-updates,jammy-security,now 3.10.12-1~22.04.3 amd64 [installed,automatic]\n",
    "libpython3.10/jammy-updates,jammy-security,now 3.10.12-1~22.04.3 amd64 [installed,automatic]\n",
    "python3-dbus/jammy,now 1.2.18-3build1 amd64 [installed,automatic]\n",
    "python3-distro/jammy,now 1.7.0-1 all [installed,automatic]\n",
    "python3-gi/jammy-updates,now 3.42.1-0ubuntu1 amd64 [installed,automatic]\n",
    "python3-minimal/jammy-updates,jammy-security,now 3.10.6-1~22.04 amd64 [installed,automatic]\n",
    "python3.10-minimal/jammy-updates,jammy-security,now 3.10.12-1~22.04.3 amd64 [installed,automatic]\n",
    "python3.10/jammy-updates,jammy-security,now 3.10.12-1~22.04.3 amd64 [installed,automatic]\n",
    "python3/jammy-updates,jammy-security,now 3.10.6-1~22.04 amd64 [installed,automatic]\n",
    "```\n",
    "\n",
    "```\n",
    "print(sys.path)\n",
    "['/home', \n",
    " '/root/miniconda3/envs/py3.10/lib/python310.zip', \n",
    " '/root/miniconda3/envs/py3.10/lib/python3.10', \n",
    " '/root/miniconda3/envs/py3.10/lib/python3.10/lib-dynload', \n",
    " '', \n",
    " '/root/miniconda3/envs/py3.10/lib/python3.10/site-packages']\n",
    "```\n",
    "\n",
    "### Jupyterlab config\n",
    "\n",
    "/root/miniconda3/envs/py3.10/etc/jupyter/jupyter_notebook_config.d/jupyter-lsp-notebook.json\n",
    "\n",
    "```\n",
    "root@ac9978bd266c:~# cat /root/miniconda3/envs/py3.10/etc/jupyter/jupyter_notebook_config.d/jupyter-lsp-notebook.json\n",
    "{\n",
    "  \"NotebookApp\": {\n",
    "    \"nbserver_extensions\": {\n",
    "      \"jupyter_lsp\": true\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "/root/miniconda3/envs/py3.10/etc/jupyter/jupyter_notebook_config.d/jupyterlab.json\n",
    "\n",
    "```\n",
    "root@ac9978bd266c:~# cat /root/miniconda3/envs/py3.10/etc/jupyter/jupyter_notebook_config.d/jupyterlab.json\n",
    "{\n",
    "  \"NotebookApp\": {\n",
    "    \"nbserver_extensions\": {\n",
    "      \"jupyterlab\": true\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "/root/miniconda3/envs/py3.10/etc/jupyter/jupyter_server_config.d/jupyter-lsp-jupyter-server.json\n",
    "\n",
    "```\n",
    "root@ac9978bd266c:~# cat /root/miniconda3/envs/py3.10/etc/jupyter/jupyter_server_config.d/jupyter-lsp-jupyter-server.json\n",
    "{\n",
    "  \"ServerApp\": {\n",
    "    \"jpserver_extensions\": {\n",
    "      \"jupyter_lsp\": true\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "/root/miniconda3/envs/py3.10/etc/jupyter/jupyter_server_config.d/jupyter_server_terminals.json\n",
    "\n",
    "```\n",
    "root@ac9978bd266c:~# cat /root/miniconda3/envs/py3.10/etc/jupyter/jupyter_server_config.d/jupyter_server_terminals.json\n",
    "{\n",
    "  \"ServerApp\": {\n",
    "    \"jpserver_extensions\": {\n",
    "      \"jupyter_server_terminals\": true\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "/root/miniconda3/envs/py3.10/etc/jupyter/jupyter_server_config.d/jupyterlab.json\n",
    "\n",
    "```\n",
    "root@ac9978bd266c:~# cat /root/miniconda3/envs/py3.10/etc/jupyter/jupyter_server_config.d/jupyterlab.json\n",
    "{\n",
    "  \"ServerApp\": {\n",
    "    \"jpserver_extensions\": {\n",
    "      \"jupyterlab\": true\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "/root/miniconda3/envs/py3.10/etc/jupyter/jupyter_server_config.d/notebook.json\n",
    "\n",
    "\n",
    "```\n",
    "root@ac9978bd266c:~# cat /root/miniconda3/envs/py3.10/etc/jupyter/jupyter_server_config.d/notebook.json\n",
    "{\n",
    "  \"ServerApp\": {\n",
    "    \"jpserver_extensions\": {\n",
    "      \"notebook\": true\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "/root/miniconda3/envs/py3.10/etc/jupyter/jupyter_server_config.d/notebook_shim.json\n",
    "\n",
    "```\n",
    "root@ac9978bd266c:~# cat /root/miniconda3/envs/py3.10/etc/jupyter/jupyter_server_config.d/notebook_shim.json\n",
    "{\n",
    "    \"ServerApp\": {\n",
    "        \"jpserver_extensions\": {\n",
    "            \"notebook_shim\": true\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "/root/miniconda3/envs/py3.10/etc/jupyter/nbconfig/notebook.d/widgetsnbextension.json \n",
    "\n",
    "```\n",
    "root@ac9978bd266c:~# cat /root/miniconda3/envs/py3.10/etc/jupyter/nbconfig/notebook.d/widgetsnbextension.json \n",
    "{\n",
    "  \"load_extensions\": {\n",
    "    \"jupyter-js-widgets/extension\": true\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### code-server config\n",
    "\n",
    "```\n",
    "root@ac9978bd266c:~# cat ~/.config/code-server/config.yaml\n",
    "\n",
    "> nothing\n",
    "\n",
    "root@ac9978bd266c:~# /usr/lib/code-server/bin/code-server --list-extensions\n",
    "\n",
    "> nothing\n",
    "```\n",
    "\n",
    "### pip list\n",
    "\n",
    "```\n",
    "diffusers                 0.26.3\n",
    "jupyterlab                4.0.11\n",
    "numpy                     1.26.3\n",
    "nvidia-cublas-cu12        12.1.3.1\n",
    "nvidia-cuda-cupti-cu12    12.1.105\n",
    "nvidia-cuda-nvrtc-cu12    12.1.105\n",
    "nvidia-cuda-runtime-cu12  12.1.105\n",
    "nvidia-cudnn-cu12         8.9.2.26\n",
    "nvidia-cufft-cu12         11.0.2.54\n",
    "nvidia-curand-cu12        10.3.2.106\n",
    "nvidia-cusolver-cu12      11.4.5.107\n",
    "nvidia-cusparse-cu12      12.1.0.106\n",
    "nvidia-nccl-cu12          2.18.1\n",
    "nvidia-nvjitlink-cu12     12.3.101\n",
    "nvidia-nvtx-cu12          12.1.105\n",
    "pandas                    2.2.0\n",
    "spacy                     3.7.4\n",
    "torch                     2.1.2\n",
    "transformers              4.37.2\n",
    "triton                    2.1.0\n",
    "```\n",
    "\n",
    "```\n",
    "root@ac9978bd266c:~# pip show torch\n",
    "Name: torch\n",
    "Version: 2.1.2\n",
    "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
    "Home-page: https://pytorch.org/\n",
    "Author: PyTorch Team\n",
    "Author-email: packages@pytorch.org\n",
    "License: BSD-3\n",
    "Location: /root/miniconda3/envs/py3.10/lib/python3.10/site-packages\n",
    "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-nccl-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n",
    "Required-by: torchaudio, torchvision\n",
    "```\n",
    "\n",
    "```\n",
    "root@ac9978bd266c:/root/miniconda3# conda list -n py3.10\n",
    "# packages in environment at /root/miniconda3/envs/py3.10:\n",
    "#\n",
    "# Name                    Version                   Build  Channel\n",
    "_libgcc_mutex             0.1                        main  \n",
    "_openmp_mutex             5.1                       1_gnu  \n",
    "annotated-types           0.6.0                    pypi_0    pypi\n",
    "anyio                     4.2.0                    pypi_0    pypi\n",
    "argon2-cffi               23.1.0                   pypi_0    pypi\n",
    "argon2-cffi-bindings      21.2.0                   pypi_0    pypi\n",
    "arrow                     1.3.0                    pypi_0    pypi\n",
    "asttokens                 2.4.1                    pypi_0    pypi\n",
    "async-lru                 2.0.4                    pypi_0    pypi\n",
    "attrs                     23.2.0                   pypi_0    pypi\n",
    "babel                     2.14.0                   pypi_0    pypi\n",
    "beautifulsoup4            4.12.3                   pypi_0    pypi\n",
    "bleach                    6.1.0                    pypi_0    pypi\n",
    "blis                      0.7.11                   pypi_0    pypi\n",
    "bzip2                     1.0.8                h7b6447c_0  \n",
    "ca-certificates           2023.12.12           h06a4308_0  \n",
    "catalogue                 2.0.10                   pypi_0    pypi\n",
    "certifi                   2023.11.17               pypi_0    pypi\n",
    "cffi                      1.16.0                   pypi_0    pypi\n",
    "charset-normalizer        3.3.2                    pypi_0    pypi\n",
    "click                     8.1.7                    pypi_0    pypi\n",
    "cloudpathlib              0.16.0                   pypi_0    pypi\n",
    "comm                      0.2.1                    pypi_0    pypi\n",
    "confection                0.1.4                    pypi_0    pypi\n",
    "cymem                     2.0.8                    pypi_0    pypi\n",
    "debugpy                   1.8.0                    pypi_0    pypi\n",
    "decorator                 5.1.1                    pypi_0    pypi\n",
    "defusedxml                0.7.1                    pypi_0    pypi\n",
    "diffusers                 0.26.3                   pypi_0    pypi\n",
    "exceptiongroup            1.2.0                    pypi_0    pypi\n",
    "executing                 2.0.1                    pypi_0    pypi\n",
    "fastjsonschema            2.19.1                   pypi_0    pypi\n",
    "filelock                  3.13.1                   pypi_0    pypi\n",
    "fqdn                      1.5.1                    pypi_0    pypi\n",
    "fsspec                    2023.12.2                pypi_0    pypi\n",
    "ftfy                      6.1.3                    pypi_0    pypi\n",
    "huggingface-hub           0.20.3                   pypi_0    pypi\n",
    "idna                      3.6                      pypi_0    pypi\n",
    "importlib-metadata        7.0.1                    pypi_0    pypi\n",
    "ipykernel                 6.29.0                   pypi_0    pypi\n",
    "ipython                   8.20.0                   pypi_0    pypi\n",
    "ipywidgets                8.1.1                    pypi_0    pypi\n",
    "isoduration               20.11.0                  pypi_0    pypi\n",
    "jedi                      0.19.1                   pypi_0    pypi\n",
    "jinja2                    3.1.3                    pypi_0    pypi\n",
    "json5                     0.9.14                   pypi_0    pypi\n",
    "jsonpointer               2.4                      pypi_0    pypi\n",
    "jsonschema                4.21.1                   pypi_0    pypi\n",
    "jsonschema-specifications 2023.12.1                pypi_0    pypi\n",
    "jupyter-client            8.6.0                    pypi_0    pypi\n",
    "jupyter-core              5.7.1                    pypi_0    pypi\n",
    "jupyter-events            0.9.0                    pypi_0    pypi\n",
    "jupyter-lsp               2.2.2                    pypi_0    pypi\n",
    "jupyter-server            2.12.5                   pypi_0    pypi\n",
    "jupyter-server-terminals  0.5.2                    pypi_0    pypi\n",
    "jupyterlab                4.0.11                   pypi_0    pypi\n",
    "jupyterlab-pygments       0.3.0                    pypi_0    pypi\n",
    "jupyterlab-server         2.25.2                   pypi_0    pypi\n",
    "jupyterlab-widgets        3.0.9                    pypi_0    pypi\n",
    "langcodes                 3.3.0                    pypi_0    pypi\n",
    "ld_impl_linux-64          2.38                 h1181459_1  \n",
    "libffi                    3.4.4                h6a678d5_0  \n",
    "libgcc-ng                 11.2.0               h1234567_1  \n",
    "libgomp                   11.2.0               h1234567_1  \n",
    "libstdcxx-ng              11.2.0               h1234567_1  \n",
    "libuuid                   1.41.5               h5eee18b_0  \n",
    "markupsafe                2.1.4                    pypi_0    pypi\n",
    "matplotlib-inline         0.1.6                    pypi_0    pypi\n",
    "mistune                   3.0.2                    pypi_0    pypi\n",
    "mpmath                    1.3.0                    pypi_0    pypi\n",
    "murmurhash                1.0.10                   pypi_0    pypi\n",
    "nbclient                  0.9.0                    pypi_0    pypi\n",
    "nbconvert                 7.14.2                   pypi_0    pypi\n",
    "nbformat                  5.9.2                    pypi_0    pypi\n",
    "ncurses                   6.4                  h6a678d5_0  \n",
    "nest-asyncio              1.6.0                    pypi_0    pypi\n",
    "networkx                  3.2.1                    pypi_0    pypi\n",
    "notebook                  7.0.7                    pypi_0    pypi\n",
    "notebook-shim             0.2.3                    pypi_0    pypi\n",
    "numpy                     1.26.3                   pypi_0    pypi\n",
    "nvidia-cublas-cu12        12.1.3.1                 pypi_0    pypi\n",
    "nvidia-cuda-cupti-cu12    12.1.105                 pypi_0    pypi\n",
    "nvidia-cuda-nvrtc-cu12    12.1.105                 pypi_0    pypi\n",
    "nvidia-cuda-runtime-cu12  12.1.105                 pypi_0    pypi\n",
    "nvidia-cudnn-cu12         8.9.2.26                 pypi_0    pypi\n",
    "nvidia-cufft-cu12         11.0.2.54                pypi_0    pypi\n",
    "nvidia-curand-cu12        10.3.2.106               pypi_0    pypi\n",
    "nvidia-cusolver-cu12      11.4.5.107               pypi_0    pypi\n",
    "nvidia-cusparse-cu12      12.1.0.106               pypi_0    pypi\n",
    "nvidia-nccl-cu12          2.18.1                   pypi_0    pypi\n",
    "nvidia-nvjitlink-cu12     12.3.101                 pypi_0    pypi\n",
    "nvidia-nvtx-cu12          12.1.105                 pypi_0    pypi\n",
    "openssl                   3.0.12               h7f8727e_0  \n",
    "overrides                 7.7.0                    pypi_0    pypi\n",
    "packaging                 23.2                     pypi_0    pypi\n",
    "pandas                    2.2.0                    pypi_0    pypi\n",
    "pandocfilters             1.5.1                    pypi_0    pypi\n",
    "parso                     0.8.3                    pypi_0    pypi\n",
    "pexpect                   4.9.0                    pypi_0    pypi\n",
    "pillow                    10.2.0                   pypi_0    pypi\n",
    "pip                       23.3.2                   pypi_0    pypi\n",
    "platformdirs              4.1.0                    pypi_0    pypi\n",
    "preshed                   3.0.9                    pypi_0    pypi\n",
    "prometheus-client         0.19.0                   pypi_0    pypi\n",
    "prompt-toolkit            3.0.43                   pypi_0    pypi\n",
    "psutil                    5.9.8                    pypi_0    pypi\n",
    "ptyprocess                0.7.0                    pypi_0    pypi\n",
    "pure-eval                 0.2.2                    pypi_0    pypi\n",
    "pycparser                 2.21                     pypi_0    pypi\n",
    "pydantic                  2.6.1                    pypi_0    pypi\n",
    "pydantic-core             2.16.2                   pypi_0    pypi\n",
    "pygments                  2.17.2                   pypi_0    pypi\n",
    "python                    3.10.13              h955ad1f_0  \n",
    "python-dateutil           2.8.2                    pypi_0    pypi\n",
    "python-json-logger        2.0.7                    pypi_0    pypi\n",
    "pytz                      2024.1                   pypi_0    pypi\n",
    "pyyaml                    6.0.1                    pypi_0    pypi\n",
    "pyzmq                     25.1.2                   pypi_0    pypi\n",
    "readline                  8.2                  h5eee18b_0  \n",
    "referencing               0.33.0                   pypi_0    pypi\n",
    "regex                     2023.12.25               pypi_0    pypi\n",
    "requests                  2.31.0                   pypi_0    pypi\n",
    "rfc3339-validator         0.1.4                    pypi_0    pypi\n",
    "rfc3986-validator         0.1.1                    pypi_0    pypi\n",
    "rpds-py                   0.17.1                   pypi_0    pypi\n",
    "safetensors               0.4.2                    pypi_0    pypi\n",
    "send2trash                1.8.2                    pypi_0    pypi\n",
    "setuptools                68.2.2          py310h06a4308_0  \n",
    "six                       1.16.0                   pypi_0    pypi\n",
    "smart-open                6.4.0                    pypi_0    pypi\n",
    "sniffio                   1.3.0                    pypi_0    pypi\n",
    "soupsieve                 2.5                      pypi_0    pypi\n",
    "spacy                     3.7.4                    pypi_0    pypi\n",
    "spacy-legacy              3.0.12                   pypi_0    pypi\n",
    "spacy-loggers             1.0.5                    pypi_0    pypi\n",
    "sqlite                    3.41.2               h5eee18b_0  \n",
    "srsly                     2.4.8                    pypi_0    pypi\n",
    "stack-data                0.6.3                    pypi_0    pypi\n",
    "sympy                     1.12                     pypi_0    pypi\n",
    "terminado                 0.18.0                   pypi_0    pypi\n",
    "thinc                     8.2.3                    pypi_0    pypi\n",
    "tinycss2                  1.2.1                    pypi_0    pypi\n",
    "tk                        8.6.12               h1ccaba5_0  \n",
    "tokenizers                0.15.2                   pypi_0    pypi\n",
    "tomli                     2.0.1                    pypi_0    pypi\n",
    "torch                     2.1.2                    pypi_0    pypi\n",
    "torchaudio                2.1.2                    pypi_0    pypi\n",
    "torchvision               0.16.2                   pypi_0    pypi\n",
    "tornado                   6.4                      pypi_0    pypi\n",
    "tqdm                      4.66.2                   pypi_0    pypi\n",
    "traitlets                 5.14.1                   pypi_0    pypi\n",
    "transformers              4.37.2                   pypi_0    pypi\n",
    "triton                    2.1.0                    pypi_0    pypi\n",
    "typer                     0.9.0                    pypi_0    pypi\n",
    "types-python-dateutil     2.8.19.20240106          pypi_0    pypi\n",
    "typing-extensions         4.9.0                    pypi_0    pypi\n",
    "tzdata                    2024.1                   pypi_0    pypi\n",
    "uri-template              1.3.0                    pypi_0    pypi\n",
    "urllib3                   2.1.0                    pypi_0    pypi\n",
    "wasabi                    1.1.2                    pypi_0    pypi\n",
    "wcwidth                   0.2.13                   pypi_0    pypi\n",
    "weasel                    0.3.4                    pypi_0    pypi\n",
    "webcolors                 1.13                     pypi_0    pypi\n",
    "webencodings              0.5.1                    pypi_0    pypi\n",
    "websocket-client          1.7.0                    pypi_0    pypi\n",
    "wheel                     0.41.2          py310h06a4308_0  \n",
    "widgetsnbextension        4.0.9                    pypi_0    pypi\n",
    "xz                        5.4.5                h5eee18b_0  \n",
    "zipp                      3.17.0                   pypi_0    pypi\n",
    "zlib                      1.2.13               h5eee18b_0  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4116a299-ec12-4ab1-95ef-53d696da7314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mixtral-aqlm",
   "language": "python",
   "name": "mixtral-aqlm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
