{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce6463ad-807f-479a-8645-2afbca404c50",
   "metadata": {},
   "source": [
    "### ollama setup \n",
    "\n",
    "https://aider.chat/2024/11/21/quantization.html#setting-ollamas-context-window-size\n",
    "\n",
    "cd /workspace/wordslab-llms/ollama/bin\n",
    "\n",
    "OLLAMA_HOST=0.0.0.0 ./ollama serve\n",
    "\n",
    "./ollama pull qwen2.5-coder:7b \n",
    "\n",
    "./ollama show qwen2.5-coder:7b --modelfile > settings.txt\n",
    "\n",
    "vi settings.txt ## Add PARAMETER num_ctx 8192 at the end of the file\n",
    "\n",
    "./ollama create qwen2.5-coder:7b-8k -f settings.txt\n",
    "\n",
    "### ollama tested models\n",
    "\n",
    "./ollama pull qwen2.5-coder:7b \n",
    "\n",
    "NAME                   ID              SIZE      PROCESSOR             \n",
    "qwen2.5-coder:7b-8k    ac3fb70aa735    8.9 GB    100% GPU\n",
    "\n",
    "./ollama pull qwen2.5-coder:7b-instruct-q8_0\n",
    "\n",
    "NAME                        ID              SIZE     PROCESSOR              \n",
    "qwen2.5-coder:7b-int8-8k    38b50b1d0e8e    12 GB    100% GPU\n",
    "\n",
    "./ollama pull qwen2.5-coder:7b-instruct-fp16\n",
    "\n",
    "NAME                        ID              SIZE     PROCESSOR             \n",
    "qwen2.5-coder:7b-fp16-8k    9e0d8452b05d    18 GB\n",
    "\n",
    "./ollama pull hf.co/bartowski/Qwen2.5.1-Coder-7B-Instruct-GGUF:Q8_0\n",
    "\n",
    "NAME                                  ID              SIZE     PROCESSOR          \n",
    "qwen2.5-coder:7b-bartowski-int8-8k    276ce9838f83    12 GB    100% GPU\n",
    "\n",
    "./ollama pull hf.co/bartowski/Qwen2.5.1-Coder-7B-Instruct-GGUF:Q4_K_L\n",
    "\n",
    "NAME                             ID              SIZE      PROCESSOR         \n",
    "qwen2.5-coder:7b-bartowski-8k    2dc6eb25931d    8.9 GB    100% GPU \n",
    "\n",
    "./ollama pull qwen2.5-coder:14b \n",
    "\n",
    "NAME                    ID              SIZE     PROCESSOR              \n",
    "qwen2.5-coder:14b-8k    e0f25a5f2c0a    ?? GB    100% GPU\n",
    "\n",
    "./ollama pull qwen2.5-coder:14b-instruct-q8_0 \n",
    "\n",
    "NAME                         ID              SIZE     PROCESSOR    UNTIL              \n",
    "qwen2.5-coder:14b-int8-8k    6032005c5055    17 GB    100% GPU\n",
    "\n",
    "### aider benchmark setup\n",
    "\n",
    "https://github.com/Aider-AI/aider/blob/main/benchmark/README.md\n",
    "\n",
    "#### build container\n",
    "\n",
    "create-workspace-project https://github.com/Aider-AI/aider.git\n",
    "\n",
    "cd /workspace/aider\n",
    "mkdir tmp.benchmarks\n",
    "git clone https://github.com/exercism/python.git\n",
    "cp -rp python/exercises/practice tmp.benchmarks/exercism-python\n",
    "\n",
    "service docker start\n",
    "./benchmark/docker_build.sh\n",
    "\n",
    "vi ## Add env variable -e OLLAMA_API_BASE=http://host.docker.internal:11434 instead of OPENAI key\n",
    "\n",
    "#### run benchmark\n",
    "\n",
    "./benchmark/docker.sh\n",
    "\n",
    "./benchmark/benchmark.py --new qwen2.5-coder-7b-8k-whole --model ollama_chat/qwen2.5-coder:7b-8k --edit-format whole\n",
    "\n",
    "### aider reference results\n",
    "\n",
    "https://github.com/Aider-AI/aider/blob/main/aider/website/_data/quant.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3059bbdf-78fe-4234-b300-ecddf4ff85a9",
   "metadata": {},
   "source": [
    "### Results with the recommended 8k ollama context length\n",
    "\n",
    "Note: for 7B / int4, the diff format benchmark freezed two times (entered an endless loop ?).\n",
    "\n",
    "```\n",
    "- dirname: 2024-11-30-15-38-47--qwen2.5-coder-7b-8k-whole\n",
    "  test_cases: 133\n",
    "  model: ollama_chat/qwen2.5-coder:7b-8k\n",
    "  edit_format: whole\n",
    "  commit_hash: 2c7251f-dirty\n",
    "  pass_rate_1: 48.1\n",
    "  pass_rate_2: 52.6\n",
    "  percent_cases_well_formed: 100.0\n",
    "  error_outputs: 0\n",
    "  num_malformed_responses: 0\n",
    "  num_with_malformed_responses: 0\n",
    "  user_asks: 2\n",
    "  lazy_comments: 0\n",
    "  syntax_errors: 0\n",
    "  indentation_errors: 0\n",
    "  exhausted_context_windows: 0\n",
    "  test_timeouts: 2\n",
    "  command: aider --model ollama_chat/qwen2.5-coder:7b-8k\n",
    "  date: 2024-11-30\n",
    "  versions: 0.65.2.dev\n",
    "  seconds_per_case: 7.4\n",
    "  total_cost: 0.0000\n",
    "\n",
    "- dirname: 2024-11-30-17-16-20--qwen2.5-coder-7b-int8-8k-whole\n",
    "  test_cases: 133\n",
    "  model: ollama_chat/qwen2.5-coder:7b-int8-8k\n",
    "  edit_format: whole\n",
    "  commit_hash: 2c7251f-dirty\n",
    "  pass_rate_1: 47.4\n",
    "  pass_rate_2: 56.4\n",
    "  percent_cases_well_formed: 100.0\n",
    "  error_outputs: 0\n",
    "  num_malformed_responses: 0\n",
    "  num_with_malformed_responses: 0\n",
    "  user_asks: 8\n",
    "  lazy_comments: 0\n",
    "  syntax_errors: 0\n",
    "  indentation_errors: 0\n",
    "  exhausted_context_windows: 0\n",
    "  test_timeouts: 3\n",
    "  command: aider --model ollama_chat/qwen2.5-coder:7b-int8-8k\n",
    "  date: 2024-11-30\n",
    "  versions: 0.65.2.dev\n",
    "  seconds_per_case: 11.3\n",
    "  total_cost: 0.0000\n",
    "\n",
    "- dirname: 2024-11-30-17-47-28--qwen2.5-coder-7b-fp16-8k-whole\n",
    "  test_cases: 133\n",
    "  model: ollama_chat/qwen2.5-coder:7b-fp16-8k\n",
    "  edit_format: whole\n",
    "  commit_hash: 2c7251f-dirty\n",
    "  pass_rate_1: 46.6\n",
    "  pass_rate_2: 56.4\n",
    "  percent_cases_well_formed: 100.0\n",
    "  error_outputs: 0\n",
    "  num_malformed_responses: 0\n",
    "  num_with_malformed_responses: 0\n",
    "  user_asks: 10\n",
    "  lazy_comments: 0\n",
    "  syntax_errors: 0\n",
    "  indentation_errors: 0\n",
    "  exhausted_context_windows: 0\n",
    "  test_timeouts: 2\n",
    "  command: aider --model ollama_chat/qwen2.5-coder:7b-fp16-8k\n",
    "  date: 2024-11-30\n",
    "  versions: 0.65.2.dev\n",
    "  seconds_per_case: 16.2\n",
    "  total_cost: 0.0000\n",
    "\n",
    "- dirname: 2024-11-30-21-50-48--qwen2.5-coder:7b-bartowski-8k-whole\n",
    "  test_cases: 133\n",
    "  model: ollama_chat/qwen2.5-coder:7b-bartowski-8k\n",
    "  edit_format: whole\n",
    "  commit_hash: 2c7251f-dirty\n",
    "  pass_rate_1: 53.4\n",
    "  pass_rate_2: 61.7\n",
    "  percent_cases_well_formed: 100.0\n",
    "  error_outputs: 0\n",
    "  num_malformed_responses: 0\n",
    "  num_with_malformed_responses: 0\n",
    "  user_asks: 2\n",
    "  lazy_comments: 0\n",
    "  syntax_errors: 0\n",
    "  indentation_errors: 0\n",
    "  exhausted_context_windows: 0\n",
    "  test_timeouts: 1\n",
    "  command: aider --model ollama_chat/qwen2.5-coder:7b-bartowski-8k\n",
    "  date: 2024-11-30\n",
    "  versions: 0.65.2.dev\n",
    "  seconds_per_case: 7.4\n",
    "  total_cost: 0.0000\n",
    "\n",
    "- dirname: 2024-11-30-20-25-15--qwen2.5-coder-7b-bartowski-int8-8k-whole\n",
    "  test_cases: 133\n",
    "  model: ollama_chat/qwen2.5-coder:7b-bartowski-int8-8k\n",
    "  edit_format: whole\n",
    "  commit_hash: 2c7251f-dirty\n",
    "  pass_rate_1: 54.1\n",
    "  pass_rate_2: 63.9\n",
    "  percent_cases_well_formed: 100.0\n",
    "  error_outputs: 0\n",
    "  num_malformed_responses: 0\n",
    "  num_with_malformed_responses: 0\n",
    "  user_asks: 3\n",
    "  lazy_comments: 0\n",
    "  syntax_errors: 0\n",
    "  indentation_errors: 0\n",
    "  exhausted_context_windows: 0\n",
    "  test_timeouts: 1\n",
    "  command: aider --model ollama_chat/qwen2.5-coder:7b-bartowski-int8-8k\n",
    "  date: 2024-11-30\n",
    "  versions: 0.65.2.dev\n",
    "  seconds_per_case: 10.1\n",
    "  total_cost: 0.0000\n",
    "\n",
    "- dirname: 2024-11-30-21-00-05--qwen2.5-coder-14b-8k-whole\n",
    "  test_cases: 133\n",
    "  model: ollama_chat/qwen2.5-coder:14b-8k\n",
    "  edit_format: whole\n",
    "  commit_hash: 2c7251f-dirty\n",
    "  pass_rate_1: 53.4\n",
    "  pass_rate_2: 68.4\n",
    "  percent_cases_well_formed: 100.0\n",
    "  error_outputs: 0\n",
    "  num_malformed_responses: 0\n",
    "  num_with_malformed_responses: 0\n",
    "  user_asks: 6\n",
    "  lazy_comments: 0\n",
    "  syntax_errors: 0\n",
    "  indentation_errors: 0\n",
    "  exhausted_context_windows: 0\n",
    "  test_timeouts: 2\n",
    "  command: aider --model ollama_chat/qwen2.5-coder:14b-8k\n",
    "  date: 2024-11-30\n",
    "  versions: 0.65.2.dev\n",
    "  seconds_per_case: 14.5\n",
    "  total_cost: 0.0000\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c53faa-a753-4a02-bd39-44f3999f83c5",
   "metadata": {},
   "source": [
    "###  Result with the default 2k ollama context length\n",
    "\n",
    "```\n",
    "- dirname: 2024-11-30-13-13-48--qwen2.5-coder-7b-whole\n",
    "  test_cases: 133\n",
    "  model: ollama_chat/qwen2.5-coder:7b\n",
    "  edit_format: whole\n",
    "  commit_hash: 2c7251f-dirty\n",
    "  pass_rate_1: 44.4\n",
    "  pass_rate_2: 48.9\n",
    "  percent_cases_well_formed: 100.0\n",
    "  error_outputs: 0\n",
    "  num_malformed_responses: 0\n",
    "  num_with_malformed_responses: 0\n",
    "  user_asks: 12\n",
    "  lazy_comments: 3\n",
    "  syntax_errors: 0\n",
    "  indentation_errors: 0\n",
    "  exhausted_context_windows: 0\n",
    "  test_timeouts: 4\n",
    "  command: aider --model ollama_chat/qwen2.5-coder:7b\n",
    "  date: 2024-11-30\n",
    "  versions: 0.65.2.dev\n",
    "  seconds_per_case: 7.1\n",
    "  total_cost: 0.0000\n",
    "\n",
    "- dirname: 2024-11-30-13-42-28--qwen2.5-coder-14b-whole\n",
    "  test_cases: 133\n",
    "  model: ollama_chat/qwen2.5-coder:14b\n",
    "  edit_format: whole\n",
    "  commit_hash: 2c7251f-dirty\n",
    "  pass_rate_1: 52.6\n",
    "  pass_rate_2: 64.7\n",
    "  percent_cases_well_formed: 100.0\n",
    "  error_outputs: 0\n",
    "  num_malformed_responses: 0\n",
    "  num_with_malformed_responses: 0\n",
    "  user_asks: 22\n",
    "  lazy_comments: 0\n",
    "  syntax_errors: 0\n",
    "  indentation_errors: 0\n",
    "  exhausted_context_windows: 0\n",
    "  test_timeouts: 2\n",
    "  command: aider --model ollama_chat/qwen2.5-coder:14b\n",
    "  date: 2024-11-30\n",
    "  versions: 0.65.2.dev\n",
    "  seconds_per_case: 12.7\n",
    "  total_cost: 0.0000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f5c618-4b14-4f79-ab52-31e622ad7a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
