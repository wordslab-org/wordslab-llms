{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac1282ee-ce66-4665-9049-057431d59f0f",
   "metadata": {},
   "source": [
    "# Most popular open weights LLMs - December 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1a15aa-978c-460a-9f6c-0c401910ed74",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1721f2-2876-44e4-871e-8eb8439c68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0565e32d-be17-4a3e-9b06-fcd8f9a0976a",
   "metadata": {},
   "source": [
    "## Models dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e5dbc53-38e1-4483-aef8-25310952f772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T22:34:35.974178Z",
     "iopub.status.busy": "2024-01-02T22:34:35.973925Z",
     "iopub.status.idle": "2024-01-02T22:34:35.981857Z",
     "shell.execute_reply": "2024-01-02T22:34:35.981424Z",
     "shell.execute_reply.started": "2024-01-02T22:34:35.974164Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = { \n",
    "    \"redpajama_3b\" : \"togethercomputer/RedPajama-INCITE-Base-3B-v1\", # 5.30 GB\n",
    "    \"btlm_3b\" : \"cerebras/btlm-3b-8k-base\", #  4.93 GB\n",
    "    \"openllama2_3b\" : \"openlm-research/open_llama_3b_v2\", #  6.38 GB\n",
    "    \"stablelm_3b\" : \"stabilityai/stablelm-3b-4e1t\", # 5.21 GB\n",
    "    \"phi2_3b\" : \"microsoft/phi-2\", # 5.18 GB\n",
    "\n",
    "    \"bloomz_7b\" : \"bigscience/bloomz-7b1-mt\", # 13.18 GB\n",
    "    \"falcon_7b\" : \"tiiuae/falcon-7b\", # 13.45 GB       \n",
    "    \"redpajama_7b\" : \"togethercomputer/RedPajama-INCITE-7B-Base\", # 12.90 GB\n",
    "    \"mpt_7b\" : \"mosaicml/mpt-7b\", # 12.39 GB\n",
    "    \"mpt_7b_8k\" : \"mosaicml/mpt-7b-8k\", # 12.39 GB\n",
    "    \"openllama2_7b\" : \"openlm-research/open_llama_7b_v2\", # 12.55 GB\n",
    "    \"llama2_7b\" : \"meta-llama/Llama-2-7b-hf\", # 12.55 GB\n",
    "    \"llama2_7b_32k\" : \"togethercomputer/LLaMA-2-7B-32K\", # 12.55 GB\n",
    "    \"mistral_7b\" : \"mistralai/Mistral-7B-v0.1\", # 13.49 GB\n",
    "    \"qwen_7b\" : \"Qwen/Qwen-7B\", # 14.38 GB\n",
    "    \"yi_6b\" : \"01-ai/Yi-6B\", # 11.29 GB\n",
    "    \"decilm_7b\" : \"Deci/DeciLM-7B\", # 13.12 GB\n",
    "    \n",
    "    \"openllama1_13b\" : \"openlm-research/open_llama_13b\", # 24.24 GB\n",
    "    \"llama2_13b\" : \"meta-llama/Llama-2-13b-hf\", # 24.25 GB\n",
    "    \"qwen_14b\" : \"Qwen/Qwen-14B\", # 26.39 GB\n",
    "    \"solar_10b\" : \"upstage/SOLAR-10.7B-v1.0\", # 19.99 GB\n",
    "    \n",
    "    \"llama1_33b\" : \"TheBloke/WizardLM-33B-V1.0-Uncensored-GPTQ\", # 15.78 GB https://huggingface.co/alexl83/LLaMA-33B-HF\n",
    "    \"falcon_40b\" : \"TheBloke/falcon-40b-instruct-GPTQ\", # 21.00 GB https://huggingface.co/tiiuae/falcon-40b\n",
    "    \"mpt_30b\" : \"abhinavkulkarni/mosaicml-mpt-30b-instruct-w4-g128-awq\", # 15.00 GB https://huggingface.co/mosaicml/mpt-30b\n",
    "    \"codellama_34b\" : \"TheBloke/CodeLlama-34B-Instruct-GPTQ\", # 17.07 GB https://huggingface.co/codellama/CodeLlama-34b-hf\n",
    "    \"yi_34b\" : \"TheBloke/Yi-34B-GPTQ\", # 17.33 GB https://huggingface.co/01-ai/Yi-34B    \n",
    "    \"mixtral_8x7B\" : \"TheBloke/Mixtral-8x7B-v0.1-GPTQ\" # 22.18 GB https://huggingface.co/mistralai/Mixtral-8x7B-v0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45f6691-1719-4cb7-99ea-f8fb7e67dd51",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ae3299f-b520-4278-919b-2cdc661e6020",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T22:34:36.670260Z",
     "iopub.status.busy": "2024-01-02T22:34:36.669457Z",
     "iopub.status.idle": "2024-01-02T22:34:37.251842Z",
     "shell.execute_reply": "2024-01-02T22:34:37.251451Z",
     "shell.execute_reply.started": "2024-01-02T22:34:36.670217Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7714b7e-ed3d-47e9-b02e-dff03299cf27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T22:34:37.252666Z",
     "iopub.status.busy": "2024-01-02T22:34:37.252428Z",
     "iopub.status.idle": "2024-01-02T22:34:48.593753Z",
     "shell.execute_reply": "2024-01-02T22:34:48.593307Z",
     "shell.execute_reply.started": "2024-01-02T22:34:37.252658Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee06683d9d5149bd888aabd7b700848f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756b6fc635a54e1e95221353703528d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d5e819113247cba1f76b9698866cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6f937ceb084e53a66b643d2ac99829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7d1367b1f1402799b5c02c35e1fb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3c5d0fa69b49df915878ee9dce7efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_name_fr = \"frenchtext/banque-fr-2311\"\n",
    "dataset_fr = load_dataset(dataset_name_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4df161a8-456f-4eaa-b99f-13c3b90d2c8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T22:34:48.594662Z",
     "iopub.status.busy": "2024-01-02T22:34:48.594461Z",
     "iopub.status.idle": "2024-01-02T22:34:48.597468Z",
     "shell.execute_reply": "2024-01-02T22:34:48.597025Z",
     "shell.execute_reply.started": "2024-01-02T22:34:48.594653Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Uri', 'Timestamp', 'Lang', 'Title', 'Text', 'Words', 'AvgWordsLength', 'Chars', 'LetterChars', 'NumberChars', 'OtherChars', 'Website', 'PDF'],\n",
       "        num_rows: 68166\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['Uri', 'Timestamp', 'Lang', 'Title', 'Text', 'Words', 'AvgWordsLength', 'Chars', 'LetterChars', 'NumberChars', 'OtherChars', 'Website', 'PDF'],\n",
       "        num_rows: 8522\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Uri', 'Timestamp', 'Lang', 'Title', 'Text', 'Words', 'AvgWordsLength', 'Chars', 'LetterChars', 'NumberChars', 'OtherChars', 'Website', 'PDF'],\n",
       "        num_rows: 8541\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5b9ed0-02c3-43ea-8647-40db7517ff27",
   "metadata": {},
   "source": [
    "## Batching and tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c1603b5-31cf-4dc9-94ce-27b20091787d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T22:34:48.598194Z",
     "iopub.status.busy": "2024-01-02T22:34:48.597947Z",
     "iopub.status.idle": "2024-01-02T22:34:48.600704Z",
     "shell.execute_reply": "2024-01-02T22:34:48.599971Z",
     "shell.execute_reply.started": "2024-01-02T22:34:48.598183Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = dataset_name_fr\n",
    "split = \"valid\"\n",
    "dataset = dataset_fr[split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef174d1d-8294-485e-91fd-bd9889fbcba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T22:34:48.602087Z",
     "iopub.status.busy": "2024-01-02T22:34:48.601597Z",
     "iopub.status.idle": "2024-01-02T22:34:48.604426Z",
     "shell.execute_reply": "2024-01-02T22:34:48.604011Z",
     "shell.execute_reply.started": "2024-01-02T22:34:48.602078Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset_batches(dataset, batch_size=32):\n",
    "    filtered_dataset = dataset.filter(lambda example: example[\"Words\"]>10)\n",
    "    sorted_dataset = dataset.sort(\"Words\",reverse=True)\n",
    "    \n",
    "    dataset_length = len(sorted_dataset)\n",
    "    for start_idx in range(0, dataset_length, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, dataset_length)\n",
    "        yield sorted_dataset[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e8fd7f9-aeec-451e-80b2-3c40360203a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T22:34:48.605063Z",
     "iopub.status.busy": "2024-01-02T22:34:48.604873Z",
     "iopub.status.idle": "2024-01-02T22:34:48.607435Z",
     "shell.execute_reply": "2024-01-02T22:34:48.606832Z",
     "shell.execute_reply.started": "2024-01-02T22:34:48.605055Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_encoding_offsets(encoding):\n",
    "    start_index = encoding.offsets[0][0]\n",
    "    end_index = encoding.offsets[-1][1]\n",
    "    if end_index==0: end_index = -1\n",
    "    return (start_index, end_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f631c448-19a0-456c-abef-19aeaad60cfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T22:34:48.608250Z",
     "iopub.status.busy": "2024-01-02T22:34:48.608138Z",
     "iopub.status.idle": "2024-01-02T22:34:48.610941Z",
     "shell.execute_reply": "2024-01-02T22:34:48.610548Z",
     "shell.execute_reply.started": "2024-01-02T22:34:48.608242Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_dataset_batch(tokenizer, dataset_batch, stride=256):\n",
    "    encodings = tokenizer(text = dataset_batch[\"Text\"], add_special_tokens=True, \n",
    "                      padding=\"longest\", truncation=True, return_overflowing_tokens=True, stride=stride,\n",
    "                      # 2020: https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html#tensor-core-shape\n",
    "                      # However now in 2023, this is less and less true, newer drivers and cuda versions are smarter about this and will be able to use tensorcores even without this aligned padding\n",
    "                      pad_to_multiple_of=16, return_tensors=\"pt\")\n",
    "\n",
    "    encodings[\"overflow_to_sample_uri\"] = list(map(lambda sample_id: dataset_batch[\"Uri\"][sample_id.item()], encodings[\"overflow_to_sample_mapping\"]))\n",
    "    encodings[\"overflow_to_sample_offset\"] = list(map(get_encoding_offsets, encodings.encodings))\n",
    "    \n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e8b9cf9-24e0-4800-81cd-c010e8b7d68f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T22:34:48.611860Z",
     "iopub.status.busy": "2024-01-02T22:34:48.611617Z",
     "iopub.status.idle": "2024-01-02T22:34:48.614697Z",
     "shell.execute_reply": "2024-01-02T22:34:48.613988Z",
     "shell.execute_reply.started": "2024-01-02T22:34:48.611849Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_encodings_batches(tokenizer, dataset, batch_size=32, stride=256):\n",
    "    for dataset_batch in get_dataset_batches(dataset, batch_size):\n",
    "        encodings = encode_dataset_batch(tokenizer, dataset_batch, stride)\n",
    "        \n",
    "        encodings_length = len(encodings.encodings)\n",
    "        for start_idx in range(0, encodings_length, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, encodings_length)\n",
    "            yield {key: encodings[key][start_idx:end_idx] for key in encodings.data.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c715b1d-5b91-4d7e-99f5-609573d93b19",
   "metadata": {},
   "source": [
    "## Compute perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90b7de50-6539-4ece-bf0d-c8569de15786",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T22:34:52.651698Z",
     "iopub.status.busy": "2024-01-02T22:34:52.650985Z",
     "iopub.status.idle": "2024-01-02T22:34:52.665436Z",
     "shell.execute_reply": "2024-01-02T22:34:52.665020Z",
     "shell.execute_reply.started": "2024-01-02T22:34:52.651669Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"/workspace/hftoken\", 'r') as file:\n",
    "    myhftoken = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "042d937f-b4ed-4699-8279-eabf72836579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T22:34:52.932571Z",
     "iopub.status.busy": "2024-01-02T22:34:52.931870Z",
     "iopub.status.idle": "2024-01-02T22:34:52.938079Z",
     "shell.execute_reply": "2024-01-02T22:34:52.937086Z",
     "shell.execute_reply.started": "2024-01-02T22:34:52.932541Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PerplexityLogger:\n",
    "    def __init__(self, dataset_name, split, model_name):\n",
    "        self.filename = f\"{dataset_name.replace('/','_')}_{split}_{model_name.replace('/','_')}_perplexity.csv\"\n",
    "        self.file = open(self.filename, 'w')\n",
    "        \n",
    "    def log_batch(self, perplexity, uri, span):\n",
    "        self.file.write(f\"{perplexity},{uri},{span}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6acc7c5-e652-4511-81a4-e830d2d9ed4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T22:34:56.328949Z",
     "iopub.status.busy": "2024-01-02T22:34:56.328467Z",
     "iopub.status.idle": "2024-01-02T22:35:07.767788Z",
     "shell.execute_reply": "2024-01-02T22:35:07.767261Z",
     "shell.execute_reply.started": "2024-01-02T22:34:56.328908Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-llms/.venv/lib/python3.10/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing perplexity on dataset frenchtext/banque-fr-2311:valid for tiiuae/falcon-7b\n",
      "- dataset examples: 8522\n",
      "- batch_size= 8, stride=256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5197805f42434c59afc7f8c153c1c5c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca5ae28832a4f3ba56370e72d78d92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- model torch dtype: torch.bfloat16\n",
      "- model vocabulary: 65024\n",
      "- model sequence length: 2048\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "batch_size = 8\n",
    "stride = 256\n",
    "\n",
    "model_id = list(models)[6]\n",
    "model_name = models[model_id]\n",
    "print(f\"Computing perplexity on dataset {dataset_name}:{split} for {model_name}\")\n",
    "print(f\"- dataset examples: {len(dataset)}\")\n",
    "print(f\"- batch_size= {batch_size}, stride={stride}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)#, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=\"auto\", attn_implementation=\"flash_attention_2\")#, trust_remote_code=True, token=myhftoken) \n",
    "print(f\"- model torch dtype: {model.dtype}\")\n",
    "print(f\"- model vocabulary: {len(tokenizer.vocab)}\")\n",
    "print(f\"- model sequence length: {int(tokenizer.model_max_length)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef201e01-e6ed-4a05-8754-804849a1cbba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = PerplexityLogger(dataset_name, split, model_name)\n",
    "loss_fct = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "losses = []    \n",
    "for idx,encodings_batch in enumerate(get_encodings_batches(tokenizer, dataset, batch_size=batch_size, stride=stride)):\n",
    "    with torch.no_grad():\n",
    "        # predict next token\n",
    "        inputs = encodings_batch[\"input_ids\"].to(model.device)\n",
    "        attention_mask = encodings_batch[\"attention_mask\"].to(model.device)\n",
    "        outputs = model(input_ids=inputs, attention_mask=attention_mask, use_cache=False, output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "        # compute perplexity\n",
    "        # we are doing next-token prediction; shift prediction µscores and input ids by one\n",
    "        shift_logits = outputs.logits[:, :-1, :].permute(0, 2, 1).contiguous()\n",
    "        labels = inputs[:, 1:].contiguous()\n",
    "        labels_to_ignore = attention_mask[:, 1:]\n",
    "        # CrossEntropyLoss: ignore_index=-100\n",
    "        labels = labels*labels_to_ignore -100*(1-labels_to_ignore)\n",
    "        batch_losses = loss_fct(shift_logits, labels).mean(1)\n",
    "        losses.extend(batch_losses)\n",
    "        batch_perplexities = torch.exp(batch_losses).tolist()\n",
    "\n",
    "    for perplexity,uri,span in zip(batch_perplexities, encodings_batch[\"overflow_to_sample_uri\"], encodings_batch[\"overflow_to_sample_offset\"]):\n",
    "        logger.log_batch(perplexity, uri, span)\n",
    "\n",
    "    if idx%10 == 0:\n",
    "        perplexity = torch.exp(torch.stack(losses).mean().float()).item()\n",
    "        print(f\"{(idx+1)*batch_size} encodings processed -> perplexity = {perplexity}\")\n",
    "\n",
    "perplexity = torch.exp(torch.stack(losses).mean().float()).item()\n",
    "print(f\"-> perplexity = {perplexity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d26af8-8e20-4f02-a182-e7ad75b9f6ab",
   "metadata": {},
   "source": [
    "Computing perplexity on dataset frenchtext/banque-fr-2311 for togethercomputer/RedPajama-INCITE-Base-3B-v1\n",
    "- dataset examples: 68166\n",
    "- batch_size= 16, stride=256\n",
    "- model torch dtype: torch.float16\n",
    "- model vocabulary: 50277\n",
    "- model sequence length: 2048\n",
    "- perplexity = 5.301388263702393 (train)\n",
    "- perplexity = 5.480365753173828 (valid) [+3,4%]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91025c3f-96a1-4b07-8c86-1350a178eb51",
   "metadata": {},
   "source": [
    "Computing perplexity on dataset frenchtext/banque-fr-2311 for openlm-research/open_llama_3b_v2\n",
    "- dataset examples: 68166\n",
    "- batch_size= 12, stride=256\n",
    "- model torch dtype: torch.float16\n",
    "- model vocabulary: 32000\n",
    "- model sequence length: 2048\n",
    "- perplexity = 4.064583778381348 (train)\n",
    "- perplexity = 3.9680004119873047 (valid) [-2,3%]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a55cdc7-cffc-4eb3-a3d7-ae588a4a8654",
   "metadata": {},
   "source": [
    "Computing perplexity on dataset frenchtext/banque-fr-2311 for togethercomputer/RedPajama-INCITE-7B-Base\n",
    "- dataset examples: 68166\n",
    "- batch_size= 8, stride=256\n",
    "- model torch dtype: torch.float16\n",
    "- model vocabulary: 50277\n",
    "- model sequence length: 2048\n",
    "- perplexity = 4.955935478210449"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e22d95-6fd3-4c62-bad7-8495c93243ea",
   "metadata": {},
   "source": [
    "Computing perplexity on dataset frenchtext/banque-fr-2311:valid for mistralai/Mistral-7B-v0.1\n",
    "- dataset examples: 8522\n",
    "- batch_size= 4, stride=256\n",
    "- model torch dtype: torch.bfloat16\n",
    "- model vocabulary: 32000\n",
    "- model sequence length: 4096\n",
    "- perplexity = 3.9531056880950928 (valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f419adc-4c00-4a8f-9e72-b8d04150306a",
   "metadata": {},
   "source": [
    "Computing perplexity on dataset frenchtext/banque-fr-2311:valid for 01-ai/Yi-6B\n",
    "- dataset examples: 8522\n",
    "- batch_size= 4, stride=256\n",
    "- model torch dtype: torch.bfloat16\n",
    "- model vocabulary: 64000\n",
    "- model sequence length: 4096\n",
    "- perplexity = 3.990814685821533 (valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d855274a-1c94-4f60-bd80-be9418814eb2",
   "metadata": {},
   "source": [
    "Computing perplexity on dataset frenchtext/banque-fr-2311:valid for tiiuae/falcon-7b\n",
    "- dataset examples: 8522\n",
    "- batch_size= 8, stride=256\n",
    "- model torch dtype: torch.bfloat16\n",
    "- model vocabulary: 65024\n",
    "- model sequence length: 2048\n",
    "- perplexity = 3.8035600185394287 (valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9956a9c2-62f2-4699-98f4-8f7a6306009a",
   "metadata": {},
   "source": [
    "## Unigram-normalized perplexity\n",
    "\n",
    "https://arxiv.org/pdf/2011.13220.pdf\n",
    "\n",
    "Unigram-Normalized Perplexity as a Language Model Performance Measure with Different Vocabulary Sizes\n",
    "\n",
    "*Jihyeon Roh, Sang-Hoon Oh, Soo-Young Lee*\n",
    "\n",
    "Although Perplexity is a widely used performance metric for language models, the values are highly dependent upon the number of words in the corpus and is useful to compare performance of the same corpus only.\n",
    "\n",
    "Perplexity may not be suitable for comparing LMs using different vocabularies because a larger vocabulary size tends to result in lower word probabilities and thus a higher Perplexity.\n",
    "\n",
    "In this paper, we propose a new metric that can be used to evaluate language model performance with different vocabulary sizes. \n",
    "\n",
    "The proposed unigram-normalized Perplexity actually presents the performance improvement of the language models from that of simple unigram model, and is robust on the vocabulary size.\n",
    "\n",
    "To overcome the limitations of the perplexity, we adopt the basic idea of normalizing the word probability with respect to a quantity containing the vocabulary size. \n",
    "\n",
    "We apply a unigram probability that is calculated from the word occurrence as a normalization factor for the perplexity. The unigram probability from the unigram LM is computed as Count(vk) / Count(all words), where Count(vk) is the number of occurrences of word vk in the corpus.\n",
    "\n",
    "Our proposed metric is obtained by normalizing the perplexity with this unigram probability.\n",
    "\n",
    "The proposed “Perplexity normalized with unigram” (PPLu) is defined as\n",
    "PPLu = (Product for all words in sequence of : P(word | language model) / P(word | unigram))^1/length of sequence \n",
    "\n",
    "This metric shows the likelihood improvement of a context-dependent LM from unigram LM without the context information, and enables us to evaluate the effectiveness of an LM.\n",
    "\n",
    "PPLu contains a unigram probability term, which allows PPLu to evaluate LMs more accurately than PPL does. Specifically, even if an LM fails to capture word relationships, it may achieve a good PPL by simply assigning high probabilities to words that frequently appear (e.g., unknown tokens). This case can be corrected with our PPLu, which considers the word frequencies via unigram probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2068465a-c0e0-4ea3-b8b6-cad49777b131",
   "metadata": {},
   "source": [
    "Formula:\n",
    "\n",
    "``` \n",
    "log(PPLu) = 1/length of sequence * Sum for all words in sequence( log(P(word | language model)) - log(P(word | unigram)))\n",
    "          = Log(PPL) - 1/length of sequence * Sum for all words in sequence( log(P(word | unigram) )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1890fab8-8594-4479-a6a9-aa4a88e216c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T22:42:50.841441Z",
     "iopub.status.busy": "2024-01-02T22:42:50.840788Z",
     "iopub.status.idle": "2024-01-02T22:42:51.802240Z",
     "shell.execute_reply": "2024-01-02T22:42:51.801830Z",
     "shell.execute_reply.started": "2024-01-02T22:42:50.841412Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'overflow_to_sample_mapping', 'overflow_to_sample_uri', 'overflow_to_sample_offset'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings_batch = next(get_encodings_batches(tokenizer, dataset, batch_size=batch_size, stride=stride))\n",
    "encodings_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "954820b5-90bb-452d-91b4-110693c798be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T22:57:39.875337Z",
     "iopub.status.busy": "2024-01-02T22:57:39.874089Z",
     "iopub.status.idle": "2024-01-02T22:57:39.882151Z",
     "shell.execute_reply": "2024-01-02T22:57:39.881644Z",
     "shell.execute_reply.started": "2024-01-02T22:57:39.875277Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 2048]),\n",
       " tensor([   14,   382,  2992,  ...,  8409, 34268,  2263]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings_batch[\"input_ids\"].size(),encodings_batch[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e65c0e3-26cc-45eb-b1b2-a4ed8ab98271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T22:43:08.041703Z",
     "iopub.status.busy": "2024-01-02T22:43:08.040813Z",
     "iopub.status.idle": "2024-01-02T22:43:09.750359Z",
     "shell.execute_reply": "2024-01-02T22:43:09.749954Z",
     "shell.execute_reply.started": "2024-01-02T22:43:08.041648Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2048, 65024])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fct = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "with torch.no_grad():\n",
    "    # predict next token\n",
    "    inputs = encodings_batch[\"input_ids\"].to(model.device)\n",
    "    attention_mask = encodings_batch[\"attention_mask\"].to(model.device)\n",
    "    outputs = model(input_ids=inputs, attention_mask=attention_mask, use_cache=False, output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "outputs.logits.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bafc9789-83c0-4fb5-b281-4a40c254aa6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T22:48:16.245556Z",
     "iopub.status.busy": "2024-01-02T22:48:16.244620Z",
     "iopub.status.idle": "2024-01-02T22:48:16.826435Z",
     "shell.execute_reply": "2024-01-02T22:48:16.826018Z",
     "shell.execute_reply.started": "2024-01-02T22:48:16.245515Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5547, 1.7812, 1.6875, 1.6875, 1.6094, 1.4062, 1.4375, 1.6016],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute perplexity\n",
    "# we are doing next-token prediction; shift prediction scores and input ids by one\n",
    "shift_logits = outputs.logits[:, :-1, :].permute(0, 2, 1).contiguous()\n",
    "labels = inputs[:, 1:].contiguous()\n",
    "labels_to_ignore = attention_mask[:, 1:]\n",
    "# CrossEntropyLoss: ignore_index=-100\n",
    "labels = labels*labels_to_ignore -100*(1-labels_to_ignore)\n",
    "batch_losses = loss_fct(shift_logits, labels).mean(1)\n",
    "\n",
    "batch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61fc9b55-d4d9-405f-b54c-18d00671f3dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T22:48:35.814724Z",
     "iopub.status.busy": "2024-01-02T22:48:35.814108Z",
     "iopub.status.idle": "2024-01-02T22:48:35.829527Z",
     "shell.execute_reply": "2024-01-02T22:48:35.829113Z",
     "shell.execute_reply.started": "2024-01-02T22:48:35.814698Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.71875, 5.9375, 5.40625, 5.40625, 5.0, 4.09375, 4.21875, 4.96875]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_perplexities = torch.exp(batch_losses).tolist()\n",
    "\n",
    "batch_perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f145919d-5ef2-4cfe-b8e8-6716440c8ee3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T23:22:09.741510Z",
     "iopub.status.busy": "2024-01-02T23:22:09.740534Z",
     "iopub.status.idle": "2024-01-02T23:22:11.536079Z",
     "shell.execute_reply": "2024-01-02T23:22:11.535586Z",
     "shell.execute_reply.started": "2024-01-02T23:22:09.741466Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute unigram probabilities\n",
    "\n",
    "dataset_batch = next(get_dataset_batches(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b6f1c71-bcb9-46cc-8bfe-8b40b0449ecf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T23:39:16.735297Z",
     "iopub.status.busy": "2024-01-02T23:39:16.734639Z",
     "iopub.status.idle": "2024-01-02T23:39:16.739863Z",
     "shell.execute_reply": "2024-01-02T23:39:16.739084Z",
     "shell.execute_reply.started": "2024-01-02T23:39:16.735272Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>',\n",
       " '>>TITLE<<',\n",
       " '>>ABSTRACT<<',\n",
       " '>>INTRODUCTION<<',\n",
       " '>>SUMMARY<<',\n",
       " '>>COMMENT<<',\n",
       " '>>ANSWER<<',\n",
       " '>>QUESTION<<',\n",
       " '>>DOMAIN<<',\n",
       " '>>PREFIX<<',\n",
       " '>>SUFFIX<<',\n",
       " '>>MIDDLE<<']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fa248897-8b7e-4242-8466-ab9fcf29849c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T23:50:41.571023Z",
     "iopub.status.busy": "2024-01-02T23:50:41.570578Z",
     "iopub.status.idle": "2024-01-02T23:50:41.579433Z",
     "shell.execute_reply": "2024-01-02T23:50:41.576317Z",
     "shell.execute_reply.started": "2024-01-02T23:50:41.570995Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'>>TITLE<<'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_ignore = 0\n",
    "tokenizer.pad_token = tokenizer.decode(token_to_ignore)\n",
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f2224cce-c8ab-49f4-87b3-b83307e84252",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T23:44:20.169616Z",
     "iopub.status.busy": "2024-01-02T23:44:20.169236Z",
     "iopub.status.idle": "2024-01-02T23:44:22.048388Z",
     "shell.execute_reply": "2024-01-02T23:44:22.047961Z",
     "shell.execute_reply.started": "2024-01-02T23:44:20.169601Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encodings = tokenizer(text = dataset_batch[\"Text\"], add_special_tokens=True, padding=\"longest\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "251d28ce-27b1-4c61-bfd9-2c41793509df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T23:44:24.712733Z",
     "iopub.status.busy": "2024-01-02T23:44:24.712305Z",
     "iopub.status.idle": "2024-01-02T23:44:24.719321Z",
     "shell.execute_reply": "2024-01-02T23:44:24.718783Z",
     "shell.execute_reply.started": "2024-01-02T23:44:24.712705Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 288564]),\n",
       " tensor([[   14,   382,  2992,  ...,   193,   195,   193],\n",
       "         [   14, 12869, 18413,  ...,     0,     0,     0],\n",
       "         [   14,  6419,  2454,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [   57,    25,    52,  ...,     0,     0,     0],\n",
       "         [34466, 18587,  8158,  ...,     0,     0,     0],\n",
       "         [   14,  9449, 53037,  ...,     0,     0,     0]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = encodings.input_ids\n",
    "token_ids.size(),token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8a16fe7d-d6f2-45a2-a606-322644a15263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T23:46:19.050971Z",
     "iopub.status.busy": "2024-01-02T23:46:19.050131Z",
     "iopub.status.idle": "2024-01-02T23:46:19.061488Z",
     "shell.execute_reply": "2024-01-02T23:46:19.060950Z",
     "shell.execute_reply.started": "2024-01-02T23:46:19.050938Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2503395)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_count = encodings.attention_mask.sum()\n",
    "tokens_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aefd2ed5-f463-4e69-8afc-0002d89f3434",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T23:44:28.855725Z",
     "iopub.status.busy": "2024-01-02T23:44:28.854212Z",
     "iopub.status.idle": "2024-01-02T23:44:28.861879Z",
     "shell.execute_reply": "2024-01-02T23:44:28.861174Z",
     "shell.execute_reply.started": "2024-01-02T23:44:28.855684Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9234048]), tensor([  14,  382, 2992,  ...,    0,    0,    0]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_token_ids = token_ids.view(-1)\n",
    "flattened_token_ids.size(),flattened_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "35e65d13-edc5-4d9a-9259-d6623dd8e1dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T23:44:31.657322Z",
     "iopub.status.busy": "2024-01-02T23:44:31.656517Z",
     "iopub.status.idle": "2024-01-02T23:44:31.677363Z",
     "shell.execute_reply": "2024-01-02T23:44:31.675413Z",
     "shell.execute_reply.started": "2024-01-02T23:44:31.657289Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.vocab)\n",
    "token_counts = torch.zeros(vocab_size, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8aa4ecda-ded6-4e44-9a79-88b5611b3ca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T23:44:32.789142Z",
     "iopub.status.busy": "2024-01-02T23:44:32.788397Z",
     "iopub.status.idle": "2024-01-02T23:44:32.815579Z",
     "shell.execute_reply": "2024-01-02T23:44:32.813829Z",
     "shell.execute_reply.started": "2024-01-02T23:44:32.789102Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count the occurrences of each token ID in this batch\n",
    "batch_counts = torch.bincount(flattened_token_ids, minlength=vocab_size)\n",
    "\n",
    "# Add the counts from this batch to the total counts\n",
    "token_counts += batch_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f9a542b1-d8a8-43c6-b868-1c99be80c7ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T23:44:34.660948Z",
     "iopub.status.busy": "2024-01-02T23:44:34.660440Z",
     "iopub.status.idle": "2024-01-02T23:44:34.668482Z",
     "shell.execute_reply": "2024-01-02T23:44:34.667839Z",
     "shell.execute_reply.started": "2024-01-02T23:44:34.660914Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6730653,       0,       0,       0,       0,       0,       0,       0,\n",
       "              0,       0,       0,       0,      78,    3592,     161,      22,\n",
       "           5528,     316,   13417,   17977,   13947,     246,     566,   54753,\n",
       "          21514,   51442,    6787,    6689,    7851,    5767,    4073,    2831,\n",
       "           2294,    2014,    1850,    2212,    1734,    6714,    4342,     157,\n",
       "             81,     203,     372,      57,    1704,    1272,    1656,    1644,\n",
       "           1203,    1402,     929,     378,    1150,     524,     175,    1353,\n",
       "            905,     866,    2015,    1588,      67,    2018,    1989,    1237,\n",
       "            578,     825,      48,     133,     143,      92,    1505,      69,\n",
       "           1184,       4,      73,      37,    2013,    1130,    1607,    5055,\n",
       "           4446,    1655,     722,     333,    2166,     201,      70,    3124,\n",
       "           1909,    2127,     282,    1153,     101,    1207,    4233,    1928,\n",
       "           2679,    1544,      12,     242])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3c8cca87-3ea3-4bdf-ab13-68ffafee8448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T23:56:55.541464Z",
     "iopub.status.busy": "2024-01-02T23:56:55.540790Z",
     "iopub.status.idle": "2024-01-02T23:56:55.549469Z",
     "shell.execute_reply": "2024-01-02T23:56:55.547331Z",
     "shell.execute_reply.started": "2024-01-02T23:56:55.541439Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_counts[token_to_ignore] = 0\n",
    "vocab_probs = (token_counts / tokens_count).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fa739dfe-f002-4a12-963e-b4e5acf8f237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T23:57:07.489403Z",
     "iopub.status.busy": "2024-01-02T23:57:07.488034Z",
     "iopub.status.idle": "2024-01-02T23:57:07.495641Z",
     "shell.execute_reply": "2024-01-02T23:57:07.494990Z",
     "shell.execute_reply.started": "2024-01-02T23:57:07.489351Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00],\n",
       "        [0.0000e+00],\n",
       "        [0.0000e+00],\n",
       "        [0.0000e+00],\n",
       "        [0.0000e+00],\n",
       "        [0.0000e+00],\n",
       "        [0.0000e+00],\n",
       "        [0.0000e+00],\n",
       "        [0.0000e+00],\n",
       "        [0.0000e+00],\n",
       "        [0.0000e+00],\n",
       "        [0.0000e+00],\n",
       "        [3.1158e-05],\n",
       "        [1.4349e-03],\n",
       "        [6.4313e-05],\n",
       "        [8.7881e-06],\n",
       "        [2.2082e-03],\n",
       "        [1.2623e-04],\n",
       "        [5.3595e-03],\n",
       "        [7.1810e-03]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_probs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5c1d9504-79c5-4d98-bee7-47be1a2ac940",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T23:57:11.421574Z",
     "iopub.status.busy": "2024-01-02T23:57:11.420510Z",
     "iopub.status.idle": "2024-01-02T23:57:11.427450Z",
     "shell.execute_reply": "2024-01-02T23:57:11.426750Z",
     "shell.execute_reply.started": "2024-01-02T23:57:11.421546Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 100]),\n",
       " tensor([[   14,   382,  2992,  ...,   204, 15244, 60445],\n",
       "         [   14, 12869, 18413,  ...,   193,  2291, 19140],\n",
       "         [   14,  6419,  2454,  ...,  2937,   204,    13],\n",
       "         ...,\n",
       "         [   57,    25,    52,  ...,   204, 50801,   204],\n",
       "         [34466, 18587,  8158,  ...,   195,   193,   195],\n",
       "         [   14,  9449, 53037,  ..., 20643, 28889, 32087]]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = token_ids[:,:100]\n",
    "test_input.size(),test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7ccda629-7b3b-4a04-844b-26c0574eda04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T23:57:51.630471Z",
     "iopub.status.busy": "2024-01-02T23:57:51.630220Z",
     "iopub.status.idle": "2024-01-02T23:57:51.634048Z",
     "shell.execute_reply": "2024-01-02T23:57:51.633662Z",
     "shell.execute_reply.started": "2024-01-02T23:57:51.630460Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 100]),\n",
       " tensor([[6.4313e-05, 8.8040e-04, 7.7095e-05,  ..., 3.6254e-02, 2.7563e-05,\n",
       "          1.5978e-06],\n",
       "         [6.4313e-05, 5.5924e-06, 1.1984e-05,  ..., 8.6842e-02, 1.1676e-03,\n",
       "          4.7456e-04],\n",
       "         [6.4313e-05, 1.2783e-05, 2.5685e-04,  ..., 5.1798e-03, 3.6254e-02,\n",
       "          1.4349e-03],\n",
       "         ...,\n",
       "         [3.4593e-04, 2.0549e-02, 4.5938e-04,  ..., 3.6254e-02, 4.3940e-06,\n",
       "          3.6254e-02],\n",
       "         [2.7962e-06, 5.1929e-06, 3.2356e-05,  ..., 3.6540e-02, 8.6842e-02,\n",
       "          3.6540e-02],\n",
       "         [6.4313e-05, 9.7468e-05, 2.3169e-05,  ..., 4.1384e-04, 3.6470e-04,\n",
       "          3.5951e-04]]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "probs = F.embedding(test_input, vocab_probs).squeeze()\n",
    "probs.size(),probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a46ab85a-24b0-45c0-8748-cb76eb99040d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T23:59:04.174168Z",
     "iopub.status.busy": "2024-01-02T23:59:04.173801Z",
     "iopub.status.idle": "2024-01-02T23:59:04.177799Z",
     "shell.execute_reply": "2024-01-02T23:59:04.177453Z",
     "shell.execute_reply.started": "2024-01-02T23:59:04.174155Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-726.7230, -726.9221, -662.6291, -767.7623, -720.5561, -628.8273,\n",
       "        -644.9472, -684.7527, -708.9458, -712.5073, -633.9623, -659.5041,\n",
       "        -706.5404, -651.2568, -740.7549, -722.7048, -685.3760, -647.0948,\n",
       "        -727.0426, -686.0406, -757.7579, -727.1324, -686.3970, -659.1260,\n",
       "        -629.7627, -737.1560, -671.4485, -735.9675, -663.1301, -716.1690,\n",
       "        -675.1099, -727.1324])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(probs).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67cdb98-d947-4575-a0c5-5d598d3251b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-llms",
   "language": "python",
   "name": "wordslab-llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
