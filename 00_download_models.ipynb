{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e795d02-d492-41f5-bb89-4e7448c4da71",
   "metadata": {},
   "source": [
    "# Most popular open weights LLMs - 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e058ff6-f379-41b0-8646-25b9cf380087",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4925de6e-6681-48b3-8763-134fa1038b30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c2179c2-e0a1-4dc9-aaee-772fdc22333d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T15:17:50.704982Z",
     "iopub.status.busy": "2023-12-23T15:17:50.704466Z",
     "iopub.status.idle": "2023-12-23T15:17:50.712616Z",
     "shell.execute_reply": "2023-12-23T15:17:50.711623Z",
     "shell.execute_reply.started": "2023-12-23T15:17:50.704952Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.36.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2318616-103c-4ffd-881d-ff6d07dc73fd",
   "metadata": {},
   "source": [
    "## Models dictionary\n",
    "\n",
    "### 3B parameters\n",
    "\n",
    "| Date | Name | URL | Params | Context | Train tokens | License |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| 2023/05/04 | redpajama_3b | https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1 | 2.8 B | 2048 | 800 B | Apache 2.0 |\n",
    "| 2023/07/14 | btlm_3b | https://huggingface.co/cerebras/btlm-3b-8k-base | 3 B | 8192 | 627 B | Apache 2.0 |\n",
    "| 2023/07/16 | openllama_3b | https://huggingface.co/openlm-research/open_llama_3b_v2 | 3 B | 2048 | 1 T | Apache 2.0 |\n",
    "| 2023/09/29 | stablelm_3b | https://huggingface.co/stabilityai/stablelm-3b-4e1t | 3 B | 4096 | 1 T | CC BY-SA-4.0 |\n",
    "| 2023/12/13 | phi2_3b | https://huggingface.co/microsoft/phi-2 | 2.7 B | 2048 | 1.4 T | microsoft-research-license |\n",
    "\n",
    "### 7B parameters\n",
    "\n",
    "| Date | Name | URL | Params | Context | Train tokens | License |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| 2023/04/24 | falcon_7b | https://huggingface.co/tiiuae/falcon-7b | 7 B | 2048 | 1.5 T | Apache 2.0 |\n",
    "| 2024/05/04 | redpajama_7b | https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Base | 6.9 B | 2048 | 1 T | Apache 2.0 |\n",
    "| 2023/05/05 | mpt_7b | https://huggingface.co/mosaicml/mpt-7b | 6.7 B | 2048 | 1 T | Apache-2.0 |\n",
    "| 2023/06/30 | mpt_7b_8k| https://huggingface.co/mosaicml/mpt-7b-8k | 6.7 B | 8192 | 1.5 T | Apache-2.0 |\n",
    "| 2023/07/06 | openllama_7b | https://huggingface.co/openlm-research/open_llama_7b_v2 | 7 B | 2048 | 1 T | Apache 2.0 | \n",
    "| 2023/07/26 | llama2_7b_32k | https://huggingface.co/togethercomputer/LLaMA-2-7B-32K | 7 B | 32768 | fine-tuned | llama2 |\n",
    "| 2023/09/20 | mistral_7b | https://huggingface.co/mistralai/Mistral-7B-v0.1 | 7.3 B | 8192 | ?? | Apache 2.0 |\n",
    "| 2023/11/01 | yi_6b | https://huggingface.co/01-ai/Yi-6B | 6 B | 4096 | 3 T | yi-license |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 40B parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f342144-2d6f-4df1-ae83-13182f2625d6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed2ef01b-6443-470a-a8aa-50b9735ed904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T21:00:49.796370Z",
     "iopub.status.busy": "2023-12-23T21:00:49.795022Z",
     "iopub.status.idle": "2023-12-23T21:00:49.801086Z",
     "shell.execute_reply": "2023-12-23T21:00:49.800458Z",
     "shell.execute_reply.started": "2023-12-23T21:00:49.796345Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " models = { \n",
    "    \"redpajama_3b\" : \"togethercomputer/RedPajama-INCITE-Base-3B-v1\", # 5.30 GB\n",
    "    \"btlm_3b\" : \"cerebras/btlm-3b-8k-base\", #  4.93 GB\n",
    "    \"stablelm_3b\" : \"stabilityai/stablelm-3b-4e1t\", # 5.21 GB\n",
    "    \"openllama_3b\" : \"openlm-research/open_llama_3b_v2\", #  6.38 GB\n",
    "    \"phi2_3b\" : \"microsoft/phi-2\", # 5.18 GB\n",
    "    \n",
    "    \"yi_6b\" : \"01-ai/Yi-6B\", # 11.29 GB\n",
    "    \"mistral_7b\" : \"mistralai/Mistral-7B-v0.1\", # 13.49 GB\n",
    "    \"mpt_7b\" : \"mosaicml/mpt-7b\",\n",
    "    \"falcon_7b\" : \"tiiuae/falcon-7b\",\n",
    "    \"redpajama_7b\" : \"togethercomputer/RedPajama-INCITE-7B-Base\",\n",
    "    \"llama2_7b_32k\" : \"togethercomputer/LLaMA-2-7B-32K\",\n",
    "    \"openllama_7b\" : \"openlm-research/open_llama_7b_v2\",\n",
    "    \"mpt_7b_8k\" : \"mosaicml/mpt-7b-8k\",\n",
    "    \"qwen_7b\" : \"Qwen/Qwen-7B\",\n",
    "    \"llama2_7b\" : \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"bloomz_7b\" : \"bigscience/bloomz-7b1-mt\",\n",
    "    \"decilm_7b\" : \"Deci/DeciLM-7B\",\n",
    "    \n",
    "    \"solar_10b\" : \"upstage/SOLAR-10.7B-v1.0\",    \n",
    "    \"llama2_13b\" : \"meta-llama/Llama-2-13b-hf\",\n",
    "    \"openllama_13b\" : \"openlm-research/open_llama_13b\",\n",
    "    \"qwen_14b\" : \"Qwen/Qwen-14B\",\n",
    "    \n",
    "    \"mpt_30b\" : \"mosaicml/mpt-30b\",\n",
    "    \"yi_34b\" : \"TheBloke/Yi-34B-GPTQ\",\n",
    "    \"falcon_40b\" : \"TheBloke/falcon-40b-instruct-GPTQ\",\n",
    "    \"mixtral_8x7B\" : \"heBloke/Mixtral-8x7B-v0.1-GPTQ\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5013cd80-b2c8-4821-a763-adc990e3f8e6",
   "metadata": {},
   "source": [
    "## Models download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deaaa43-17b4-40ff-aa26-76efe13a67e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "If you want to be able to access gated HuggingFace repositories:\n",
    "\n",
    "1. Login to your HuggingFace account, go to https://huggingface.co/settings/tokens, create a READ access token and copy it\n",
    "2. Paste your HuggingFace access token in the local file /workspace/hftoken\n",
    "3. Load it in Python with the the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f18c8a66-c1ff-4eac-9964-4d0a3855453b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T21:11:51.861118Z",
     "iopub.status.busy": "2023-12-23T21:11:51.860212Z",
     "iopub.status.idle": "2023-12-23T21:11:51.875399Z",
     "shell.execute_reply": "2023-12-23T21:11:51.874897Z",
     "shell.execute_reply.started": "2023-12-23T21:11:51.861083Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"/workspace/hftoken\", 'r') as file:\n",
    "    myhftoken = file.read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1aa843-2258-443b-9b83-45b990f25a87",
   "metadata": {},
   "source": [
    "Download all models in HF local cache and measure the model files size on disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b6e717e-5686-4fab-b787-bd0a0ce16dbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T20:46:09.381722Z",
     "iopub.status.busy": "2023-12-23T20:46:09.380949Z",
     "iopub.status.idle": "2023-12-23T20:46:09.388831Z",
     "shell.execute_reply": "2023-12-23T20:46:09.388093Z",
     "shell.execute_reply.started": "2023-12-23T20:46:09.381688Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.utils.hub import cached_file\n",
    "\n",
    "memory_unit_mb = 1024*1024\n",
    "memory_unit_gb = 1024*1024*1024\n",
    "\n",
    "def get_directory_size(directory):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def get_model_path_and_size_on_disk(model):    \n",
    "    model_config_file = cached_file(model.name_or_path, \"config.json\", local_files_only=True)\n",
    "    model_directory = os.path.dirname(model_config_file)    \n",
    "    total_size = get_directory_size(model_directory)\n",
    "    return model_directory,total_size\n",
    "\n",
    "def download_in_local_cache(pretrained_model_id, **kwargs):\n",
    "        print(f\"Loading model {pretrained_model_id} in local cache ...\")\n",
    "        AutoTokenizer.from_pretrained(pretrained_model_id, **kwargs)\n",
    "        model = AutoModelForCausalLM.from_pretrained(pretrained_model_id, device_map=\"meta\", **kwargs)\n",
    "        path,size = get_model_path_and_size_on_disk(model)\n",
    "        print(f\"--> model files size   : {(size/memory_unit_gb):.2f} GB\")\n",
    "        print(f\"--> stored in directory: {path}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053fb4f5-8adf-46c0-b402-2a79a1e3e172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T21:11:55.348183Z",
     "iopub.status.busy": "2023-12-23T21:11:55.347428Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model togethercomputer/RedPajama-INCITE-Base-3B-v1 in local cache ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> model files size   : 5.30 GB\n",
      "--> stored in directory: /models/huggingface/transformers/models--togethercomputer--RedPajama-INCITE-Base-3B-v1/snapshots/094fbdd0c911feb485ce55de1952ab2e75277e1e\n",
      "\n",
      "Loading model cerebras/btlm-3b-8k-base in local cache ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/cerebras/btlm-3b-8k-base:\n",
      "- configuration_btlm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/cerebras/btlm-3b-8k-base:\n",
      "- modeling_btlm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> model files size   : 4.93 GB\n",
      "--> stored in directory: /models/huggingface/transformers/models--cerebras--btlm-3b-8k-base/snapshots/2f325501c4db6464d4fe03c84c3a394197865690\n",
      "\n",
      "Loading model stabilityai/stablelm-3b-4e1t in local cache ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/stabilityai/stablelm-3b-4e1t:\n",
      "- configuration_stablelm_epoch.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/stabilityai/stablelm-3b-4e1t:\n",
      "- modeling_stablelm_epoch.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> model files size   : 5.21 GB\n",
      "--> stored in directory: /models/huggingface/transformers/models--stabilityai--stablelm-3b-4e1t/snapshots/c6554ba60f40a8252d2a43e38e55ee2e3a645813\n",
      "\n",
      "Loading model openlm-research/open_llama_3b_v2 in local cache ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c867fc1e3524806a1df12f55df88044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7222ebb61542e0a2e4720baac03762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/6.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c42627baecf44e383f3fd879163493d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> model files size   : 6.38 GB\n",
      "--> stored in directory: /models/huggingface/transformers/models--openlm-research--open_llama_3b_v2/snapshots/bce5d60d3b0c68318862270ec4e794d83308d80a\n",
      "\n",
      "Loading model microsoft/phi-2 in local cache ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc6a4f464f140c683a918999f4696cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/755 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9046951030c4214b0af3271b56adeaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi.py:   0%|          | 0.00/2.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n",
      "- configuration_phi.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68d1205d8984e4fa2789782414b2c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi.py:   0%|          | 0.00/33.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n",
      "- modeling_phi.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8558ddedc67e41b1b346bc16a0bde098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/24.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89391078fa704a3daa0901b5b5fd4afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5051e1e510654b638cbef85345e19bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282352b20084483ea222ec78a9bed4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/577M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b796cc88b8a64113862e073eb1d3dbb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4975fb89cc4690b3de4707798afb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/69.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> model files size   : 5.18 GB\n",
      "--> stored in directory: /models/huggingface/transformers/models--microsoft--phi-2/snapshots/d3186761bf5c4409f7679359284066c25ab668ee\n",
      "\n",
      "Loading model 01-ai/Yi-6B in local cache ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60bb15c1b10e489288390d0385a3fb49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1371aeca4d1d4da1b55b1514f4bc9efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89c490e41a54368a5ef620758151167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45cebcff55b9405baf6ce8ba8e26c6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db9a998386b49c199d822dad08c931b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7992059f67a4b63b261e92e3e321c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e9bc6feb6b4199b78125e9e916f34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> model files size   : 11.29 GB\n",
      "--> stored in directory: /models/huggingface/transformers/models--01-ai--Yi-6B/snapshots/b881162e08d0fa65011cb53f2c51544e1b623112\n",
      "\n",
      "Loading model mistralai/Mistral-7B-v0.1 in local cache ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b1cb4134d24b32a618ec3a3dc82595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e725ea7e7446b78a3a587942bc02e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54df0f9b9864b19b76851f081d59113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd9d866aa4b4a4ca34d3b51737e5f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c59a456ea014210a5f549fa82d768ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> model files size   : 13.49 GB\n",
      "--> stored in directory: /models/huggingface/transformers/models--mistralai--Mistral-7B-v0.1/snapshots/26bca36bde8333b5d7f72e9ed20ccda6a618af24\n",
      "\n",
      "Loading model mosaicml/mpt-7b in local cache ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88fbb47b813444183dfbaa9dfb77fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33072f56bee0453d986e9ad6121e5bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_mpt.py:   0%|          | 0.00/11.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b:\n",
      "- configuration_mpt.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "/models/huggingface/modules/transformers_modules/mosaicml/mpt-7b/ada218f9a93b5f1c6dce48a4cc9ff01fcba431e7/configuration_mpt.py:97: UserWarning: alibi is turned on, setting `learned_pos_emb` to `False.`\n",
      "  warnings.warn(f'alibi is turned on, setting `learned_pos_emb` to `False.`')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10414c8e2034423fb5b8580d8f7e642a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_mpt.py:   0%|          | 0.00/20.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874a3d31e5754cfd9cf3660faccec9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapt_tokenizer.py:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b:\n",
      "- adapt_tokenizer.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78212bafc3c34578a6c89895b3dbbba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "meta_init_context.py:   0%|          | 0.00/3.96k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b:\n",
      "- meta_init_context.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12dabdfb25a84b33b2f311757e436070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "norm.py:   0%|          | 0.00/3.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b:\n",
      "- norm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3b71a72520423fb61124549c1659e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "attention.py:   0%|          | 0.00/21.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a8d60f66ac4c74bc4945e03867c3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "flash_attn_triton.py:   0%|          | 0.00/28.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b:\n",
      "- flash_attn_triton.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d80ce21bf04ac88464f5b88da1555f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fc.py:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b:\n",
      "- fc.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b:\n",
      "- attention.py\n",
      "- flash_attn_triton.py\n",
      "- fc.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e25025dbdd14f23be268f735e89beeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hf_prefixlm_converter.py:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b:\n",
      "- hf_prefixlm_converter.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7628cac0c24f4b8fce3989958962b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "blocks.py:   0%|          | 0.00/2.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc38fdad7c546628ed10683cc5d67ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ffn.py:   0%|          | 0.00/1.75k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b:\n",
      "- ffn.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b:\n",
      "- blocks.py\n",
      "- ffn.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad00421b71a478eb57b74ae31fb0fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "param_init_fns.py:   0%|          | 0.00/11.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b:\n",
      "- param_init_fns.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc3c0f8bf234a889cfd4663f818fe34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "custom_embedding.py:   0%|          | 0.00/292 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b:\n",
      "- custom_embedding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b:\n",
      "- modeling_mpt.py\n",
      "- adapt_tokenizer.py\n",
      "- meta_init_context.py\n",
      "- norm.py\n",
      "- attention.py\n",
      "- hf_prefixlm_converter.py\n",
      "- blocks.py\n",
      "- param_init_fns.py\n",
      "- custom_embedding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1c83f0684c41e29d9b1c8bdadd07b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/16.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2d612505174f4f8c145b266fb09633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03803a5812b94b71ba2fe1da3695c6b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model_key in models:\n",
    "    download_in_local_cache(models[model_key], trust_remote_code=True, token=myhftoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98a5f38-67b3-4e78-9525-5358f48650c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-llms",
   "language": "python",
   "name": "wordslab-llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
