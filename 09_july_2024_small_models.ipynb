{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d483674f-429c-4679-bca0-eeaf59a184c4",
   "metadata": {},
   "source": [
    "# Small models from july 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15b729d-a1a0-4e09-8c62-116d3e4da7e9",
   "metadata": {},
   "source": [
    "## 1. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aea41d4-0891-4472-9099-887e67993121",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e6839c4-f252-43bf-934e-06138254d7e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T20:41:45.126461Z",
     "iopub.status.busy": "2024-07-30T20:41:45.126114Z",
     "iopub.status.idle": "2024-07-30T20:41:45.128480Z",
     "shell.execute_reply": "2024-07-30T20:41:45.128134Z",
     "shell.execute_reply.started": "2024-07-30T20:41:45.126449Z"
    }
   },
   "outputs": [],
   "source": [
    "from importlib.metadata import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4fd2026-16b5-414c-909d-58df9cad9995",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T20:41:45.136993Z",
     "iopub.status.busy": "2024-07-30T20:41:45.136782Z",
     "iopub.status.idle": "2024-07-30T20:41:45.140767Z",
     "shell.execute_reply": "2024-07-30T20:41:45.140430Z",
     "shell.execute_reply.started": "2024-07-30T20:41:45.136982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5cd0082-9bd8-48d7-a136-671ecbd1a3d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T20:41:45.141364Z",
     "iopub.status.busy": "2024-07-30T20:41:45.141161Z",
     "iopub.status.idle": "2024-07-30T20:41:45.145136Z",
     "shell.execute_reply": "2024-07-30T20:41:45.144750Z",
     "shell.execute_reply.started": "2024-07-30T20:41:45.141353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.43.3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dedc9c78-8559-4aec-b455-32003407281a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T20:41:45.145688Z",
     "iopub.status.busy": "2024-07-30T20:41:45.145587Z",
     "iopub.status.idle": "2024-07-30T20:41:45.149287Z",
     "shell.execute_reply": "2024-07-30T20:41:45.148855Z",
     "shell.execute_reply.started": "2024-07-30T20:41:45.145681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.3.post1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('vllm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "131852f7-39be-483f-b0fe-55e65294c8c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T20:42:41.186615Z",
     "iopub.status.busy": "2024-07-30T20:42:41.186179Z",
     "iopub.status.idle": "2024-07-30T20:42:41.196712Z",
     "shell.execute_reply": "2024-07-30T20:42:41.196359Z",
     "shell.execute_reply.started": "2024-07-30T20:42:41.186599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.9.post1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('vllm-flash-attn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d2f39-aa24-49e9-ab66-8e40d1a742e3",
   "metadata": {},
   "source": [
    "## Mistral Nemo 12b\n",
    "\n",
    "https://mistral.ai/fr/news/mistral-nemo/\n",
    "\n",
    "https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407\n",
    "\n",
    "https://huggingface.co/neuralmagic/Mistral-Nemo-Instruct-2407-FP8\n",
    "\n",
    "**LICENSE :** Apache 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b777ddf-0707-47b9-a1e7-edd82ba83b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"neuralmagic/Mistral-Nemo-Instruct-2407-FP8\"\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0.3, top_p=0.9, max_tokens=256)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "prompts = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "llm = LLM(model=model_id, max_model_len=4096)\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "generated_text = outputs[0].outputs[0].text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf59fbe-27b6-4402-bca6-91979bdf33e8",
   "metadata": {},
   "source": [
    "## Llama 3.1 8b\n",
    "\n",
    "https://llama.meta.com/\n",
    "\n",
    "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct\n",
    "\n",
    "https://huggingface.co/neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8-dynamic\n",
    "\n",
    "**LICENSE :** https://llama.meta.com/llama3_1/license/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f0db3b-262a-4211-a7fa-188e112b681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8-dynamic\"\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0.6, top_p=0.9, max_tokens=256)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "prompts = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "llm = LLM(model=model_id)\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "generated_text = outputs[0].outputs[0].text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6fc4e6-2f76-4b36-9b0e-00b7854415a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T21:56:28.347023Z",
     "iopub.status.busy": "2024-07-30T21:56:28.346440Z",
     "iopub.status.idle": "2024-07-30T21:56:28.350612Z",
     "shell.execute_reply": "2024-07-30T21:56:28.350074Z",
     "shell.execute_reply.started": "2024-07-30T21:56:28.347003Z"
    }
   },
   "source": [
    "## Gemma 2 9b\n",
    "\n",
    "https://ai.google.dev/gemma/docs/model_card_2\n",
    "\n",
    "https://huggingface.co/google/gemma-2-9b-it\n",
    "\n",
    "https://huggingface.co/neuralmagic/gemma-2-9b-it-FP8\n",
    "\n",
    "**LICENSE :** https://ai.google.dev/gemma/terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bfbe97-ccca-4291-9424-6c16aee26f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"neuralmagic/gemma-2-9b-it-FP8\"\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0.6, top_p=0.9, max_tokens=256)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you? Please respond in pirate speak!\"},\n",
    "]\n",
    "\n",
    "prompts = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "llm = LLM(model=model_id)\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "generated_text = outputs[0].outputs[0].text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d006928-0bb3-4f01-9447-f4699992e533",
   "metadata": {},
   "source": [
    "## Phi-3 mini 128k 3.8b\n",
    "\n",
    "https://azure.microsoft.com/en-us/blog/new-models-added-to-the-phi-3-family-available-on-microsoft-azure/\n",
    "\n",
    "https://huggingface.co/microsoft/Phi-3-mini-128k-instruct\n",
    "\n",
    "https://huggingface.co/neuralmagic/Phi-3-mini-128k-instruct-FP8\n",
    "\n",
    "**LICENSE :** MIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d73530-90f1-416e-bac3-6d8ac5d92af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"neuralmagic/Phi-3-mini-128k-instruct-FP8\"\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0.6, top_p=0.9, max_tokens=256)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you? Remember to respond in pirate speak!\"},\n",
    "]\n",
    "\n",
    "prompts = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "llm = LLM(model=model_id)\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "generated_text = outputs[0].outputs[0].text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6e713d-e00f-454c-8dad-488af75fabd2",
   "metadata": {},
   "source": [
    "## Phi-3 medium 128k 14b\n",
    "\n",
    "https://azure.microsoft.com/en-us/blog/new-models-added-to-the-phi-3-family-available-on-microsoft-azure/\n",
    "\n",
    "https://huggingface.co/microsoft/Phi-3-medium-128k-instruct\n",
    "\n",
    "https://huggingface.co/neuralmagic/Phi-3-medium-128k-instruct-FP8\n",
    "\n",
    "**LICENSE :** MIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe79ed72-2cbb-4cfc-9414-e462d8dedc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"neuralmagic/Phi-3-medium-128k-instruct-FP8\"\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0.6, top_p=0.9, max_tokens=256)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you? Remember to respond in pirate speak!\"},\n",
    "]\n",
    "\n",
    "prompts = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "llm = LLM(model=model_id)\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "generated_text = outputs[0].outputs[0].text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab22e39a-2313-442d-b91d-97e4dedf2ad1",
   "metadata": {},
   "source": [
    "# Deepseek coder v2 Lite 16b\n",
    "\n",
    "https://arxiv.org/abs/2406.11931\n",
    "\n",
    "https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct\n",
    "\n",
    "https://huggingface.co/neuralmagic/DeepSeek-Coder-V2-Lite-Instruct-FP8\n",
    "\n",
    "**LICENSE :** https://github.com/deepseek-ai/DeepSeek-Coder-V2/blob/main/LICENSE-MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfca1406-06bd-4561-954a-546f9d03da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"neuralmagic/DeepSeek-Coder-V2-Lite-Instruct-FP8\"\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0.6, top_p=0.9, max_tokens=256)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "prompts = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "llm = LLM(model=model_id, trust_remote_code=True, max_model_len=4096)\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "generated_text = outputs[0].outputs[0].text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5fe7ff-97ec-40b0-b944-2f52792c46a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-llms",
   "language": "python",
   "name": "wordslab-llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
