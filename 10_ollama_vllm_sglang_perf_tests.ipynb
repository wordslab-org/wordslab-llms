{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7249409e-3e87-4e64-875c-624a78033472",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. Install prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51875db1-1156-4474-8e52-de81161a4ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e11987-23f3-44e8-8184-b83679f0ee02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:14:42.975674Z",
     "iopub.status.busy": "2024-09-21T13:14:42.975587Z",
     "iopub.status.idle": "2024-09-21T13:14:42.983783Z",
     "shell.execute_reply": "2024-09-21T13:14:42.983473Z",
     "shell.execute_reply.started": "2024-09-21T13:14:42.975666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad3d9bc-c371-4bf1-8445-70bc48da5986",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:14:52.053603Z",
     "iopub.status.busy": "2024-09-21T13:14:52.053249Z",
     "iopub.status.idle": "2024-09-21T13:14:52.060368Z",
     "shell.execute_reply": "2024-09-21T13:14:52.060090Z",
     "shell.execute_reply.started": "2024-09-21T13:14:52.053580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('triton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee55718c-4310-4aa9-b363-acae522d8197",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "459e66c0-05d6-4651-b62b-e486f5b0a961",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:14:45.123335Z",
     "iopub.status.busy": "2024-09-21T13:14:45.122378Z",
     "iopub.status.idle": "2024-09-21T13:14:45.130853Z",
     "shell.execute_reply": "2024-09-21T13:14:45.130581Z",
     "shell.execute_reply.started": "2024-09-21T13:14:45.123300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.44.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('transformers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc846be-72e4-447e-ab93-094e7e07d7fa",
   "metadata": {},
   "source": [
    "## vLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f72e89a-3941-4ee1-97cf-18c2e15b1842",
   "metadata": {},
   "source": [
    "https://docs.vllm.ai/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d35b0e6-a186-447d-a035-9af71e3358af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "876ca82b-1cd6-4aae-a964-2b047a9fc4a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:14:46.321506Z",
     "iopub.status.busy": "2024-09-21T13:14:46.321142Z",
     "iopub.status.idle": "2024-09-21T13:14:46.329698Z",
     "shell.execute_reply": "2024-09-21T13:14:46.328821Z",
     "shell.execute_reply.started": "2024-09-21T13:14:46.321479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6.1.post2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('vllm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f3783-6061-4f60-b968-e0380e60a99f",
   "metadata": {},
   "source": [
    "## SGLang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6874cffb-8745-418f-9194-0c2f04060567",
   "metadata": {},
   "source": [
    "https://sglang.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56019c95-b5b3-4fe9-8170-2d3873db36cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade \"sglang[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e703628-1345-49f5-b310-b4b93b36c620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:14:50.712384Z",
     "iopub.status.busy": "2024-09-21T13:14:50.711986Z",
     "iopub.status.idle": "2024-09-21T13:14:50.720997Z",
     "shell.execute_reply": "2024-09-21T13:14:50.720538Z",
     "shell.execute_reply.started": "2024-09-21T13:14:50.712356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.1.post2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('sglang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea3fca-704a-4b5e-a8c0-80496ce179f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cb9d3f5-621d-4e1f-b30e-c616ecb2df83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:14:54.202295Z",
     "iopub.status.busy": "2024-09-21T13:14:54.201912Z",
     "iopub.status.idle": "2024-09-21T13:14:54.209965Z",
     "shell.execute_reply": "2024-09-21T13:14:54.209702Z",
     "shell.execute_reply.started": "2024-09-21T13:14:54.202267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.6+cu124torch2.4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('flashinfer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf7128d-8f14-4bde-977d-aec6c1793a69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T10:07:11.161321Z",
     "iopub.status.busy": "2024-09-22T10:07:11.160622Z",
     "iopub.status.idle": "2024-09-22T10:07:11.176874Z",
     "shell.execute_reply": "2024-09-22T10:07:11.176187Z",
     "shell.execute_reply.started": "2024-09-22T10:07:11.161295Z"
    }
   },
   "source": [
    "## ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efede01d-b968-4690-ab82-dc016014738e",
   "metadata": {},
   "source": [
    "https://github.com/ollama/ollama/blob/main/docs/linux.md#manual-install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cac0e71-e0a2-482e-92d5-69a81768e166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T20:25:03.127960Z",
     "iopub.status.busy": "2024-09-21T20:25:03.127560Z",
     "iopub.status.idle": "2024-09-21T20:26:45.368164Z",
     "shell.execute_reply": "2024-09-21T20:26:45.367508Z",
     "shell.execute_reply.started": "2024-09-21T20:25:03.127947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   117  100   117    0     0    566      0 --:--:-- --:--:-- --:--:--   567\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 1583M  100 1583M    0     0  17.1M      0  0:01:32  0:01:32 --:--:-- 16.9M\n"
     ]
    }
   ],
   "source": [
    "!mkdir ollama && curl -L https://ollama.com/download/ollama-linux-amd64.tgz -o ollama-linux-amd64.tgz && tar -C ./ollama -xzf ollama-linux-amd64.tgz && rm ollama-linux-amd64.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c7e6d-8825-46f9-ac49-64b39fc82971",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T20:28:36.847325Z",
     "iopub.status.busy": "2024-09-21T20:28:36.846900Z",
     "iopub.status.idle": "2024-09-21T20:28:36.885093Z",
     "shell.execute_reply": "2024-09-21T20:28:36.884416Z",
     "shell.execute_reply.started": "2024-09-21T20:28:36.847310Z"
    }
   },
   "source": [
    "```bash\n",
    "./ollama/bin/ollama serve &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2783c62-8361-4e45-9fdc-07a9ced35e81",
   "metadata": {},
   "source": [
    "https://github.com/ollama/ollama-python\n",
    "\n",
    "https://github.com/ollama/ollama/tree/main/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b56434-da15-42f4-9974-4f24be59902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48ac7f1f-81db-4643-90d8-2355f26de1c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:15:13.903286Z",
     "iopub.status.busy": "2024-09-21T13:15:13.903058Z",
     "iopub.status.idle": "2024-09-21T13:15:13.909154Z",
     "shell.execute_reply": "2024-09-21T13:15:13.908722Z",
     "shell.execute_reply.started": "2024-09-21T13:15:13.903269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('ollama')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9975774-19fa-4877-9847-dde5548308a8",
   "metadata": {},
   "source": [
    "# 2. Performance testing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750794e4-02f8-4998-b575-7d0a8f3e3c89",
   "metadata": {},
   "source": [
    "## Test models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa413fe-b029-4e5c-ba6e-70f5859f83db",
   "metadata": {},
   "source": [
    "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct\n",
    "\n",
    "https://huggingface.co/collections/neuralmagic/llama-31-quantization-66a3f907f48d07feabb8f300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e93cb29b-8c75-4187-846a-832024247f03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T13:13:16.674751Z",
     "iopub.status.busy": "2024-09-22T13:13:16.674243Z",
     "iopub.status.idle": "2024-09-22T13:13:16.683078Z",
     "shell.execute_reply": "2024-09-22T13:13:16.681838Z",
     "shell.execute_reply.started": "2024-09-22T13:13:16.674723Z"
    }
   },
   "outputs": [],
   "source": [
    "test_models = {                                                                    # OpenLLM leaderboard score\n",
    "    \"llama-3.1\" : \"meta-llama/Meta-Llama-3.1-8B-Instruct\",                         # 100.0 %\n",
    "    \"llama-3.1:w8a16\" : \"neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a16\",  # 99.8 %    \n",
    "    \"llama-3.1:fp8\" : \"neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8\",                # 99.5 % - warning the \"FP8-dynamic\" version is MUCH slower on RTX 4090 !\n",
    "    \"llama-3.1:w8a8\" : \"neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a8\",    # 99.4 %\n",
    "    \"llama-3.1:w4a16\" : \"neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w4a16\"   # 97.1 %\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0c1546-1d5e-4f33-96af-590357639f4d",
   "metadata": {},
   "source": [
    "Note: to create custom quantized model versions -> https://docs.vllm.ai/en/latest/quantization/fp8.html#quantization-process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ded1cee-67b3-4cc8-b111-012411f79dc6",
   "metadata": {},
   "source": [
    "https://ollama.com/library/llama3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bd6727-9d71-4179-8777-67aeeefe6497",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T20:40:36.798116Z",
     "iopub.status.busy": "2024-09-21T20:40:36.797241Z",
     "iopub.status.idle": "2024-09-21T20:40:36.804014Z",
     "shell.execute_reply": "2024-09-21T20:40:36.803150Z",
     "shell.execute_reply.started": "2024-09-21T20:40:36.798087Z"
    }
   },
   "source": [
    "```bash\n",
    "./ollama/bin/ollama pull llama3.1:8b-instruct-fp16\n",
    "./ollama/bin/ollama pull llama3.1:8b-instruct-q8_0\n",
    "./ollama/bin/ollama pull llama3.1:8b-instruct-q4_0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc08f74-bd5a-4601-90ba-e1ec0a2eef3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T13:13:17.522884Z",
     "iopub.status.busy": "2024-09-22T13:13:17.522520Z",
     "iopub.status.idle": "2024-09-22T13:13:17.528296Z",
     "shell.execute_reply": "2024-09-22T13:13:17.527592Z",
     "shell.execute_reply.started": "2024-09-22T13:13:17.522857Z"
    }
   },
   "outputs": [],
   "source": [
    "ollama_test_models = {\n",
    "    \"llama-3.1\" : \"llama3.1:8b-instruct-fp16\",\n",
    "    \"llama-3.1:int8\" : \"llama3.1:8b-instruct-q8_0\",\n",
    "    \"llama-3.1:int4\" : \"llama3.1:8b-instruct-q4_0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de95a90-29e7-4dc4-974b-8b601a86c16a",
   "metadata": {},
   "source": [
    "## Test prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6570564c-6fbb-4eb2-b716-1a161c7d9787",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T13:13:18.239791Z",
     "iopub.status.busy": "2024-09-22T13:13:18.239052Z",
     "iopub.status.idle": "2024-09-22T13:13:18.245256Z",
     "shell.execute_reply": "2024-09-22T13:13:18.244427Z",
     "shell.execute_reply.started": "2024-09-22T13:13:18.239763Z"
    }
   },
   "outputs": [],
   "source": [
    "test_messages = [\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quels sont les avantages du Crédit Mutuel ?\"}\n",
    "],\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quels sont les avantages du Crédit Agricole ?\"}\n",
    "],\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quels sont les avantages de la Société Générale ?\"}\n",
    "],\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quels sont les avantages de la BNP ?\"}\n",
    "]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a427640-100e-49cb-a2fc-f5fa8c18a6e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T13:13:18.576193Z",
     "iopub.status.busy": "2024-09-22T13:13:18.575868Z",
     "iopub.status.idle": "2024-09-22T13:13:19.406186Z",
     "shell.execute_reply": "2024-09-22T13:13:19.405770Z",
     "shell.execute_reply.started": "2024-09-22T13:13:18.576174Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def format_prompt(messages, model):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "267c07a4-c9f1-4d16-8697-d4a1204e2c84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T13:13:19.406887Z",
     "iopub.status.busy": "2024-09-22T13:13:19.406730Z",
     "iopub.status.idle": "2024-09-22T13:13:19.726386Z",
     "shell.execute_reply": "2024-09-22T13:13:19.726015Z",
     "shell.execute_reply.started": "2024-09-22T13:13:19.406862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nTu es un assistant utile et professionnel qui répond toujours en français.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nQuels sont les avantages du Crédit Mutuel ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n',\n",
       " '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nTu es un assistant utile et professionnel qui répond toujours en français.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nQuels sont les avantages du Crédit Agricole ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n',\n",
       " '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nTu es un assistant utile et professionnel qui répond toujours en français.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nQuels sont les avantages de la Société Générale ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n',\n",
       " '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nTu es un assistant utile et professionnel qui répond toujours en français.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nQuels sont les avantages de la BNP ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_prompt(test_messages, test_models[\"llama-3.1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d16d245-b3ef-418e-8d3b-5f494f5e6deb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### vLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f997ac1-6001-493b-b118-61ca0ff29449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T12:24:54.111027Z",
     "iopub.status.busy": "2024-09-22T12:24:54.110568Z",
     "iopub.status.idle": "2024-09-22T12:24:54.113947Z",
     "shell.execute_reply": "2024-09-22T12:24:54.113497Z",
     "shell.execute_reply.started": "2024-09-22T12:24:54.111012Z"
    }
   },
   "outputs": [],
   "source": [
    "# Authenticate VLLM with Huggingface Hub\n",
    "import os\n",
    "\n",
    "with open(\"/workspace/hftoken\", 'r') as file:\n",
    "    myhftoken = file.read().strip()\n",
    "\n",
    "os.environ[\"HF_TOKEN\"]=myhftoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15a8369c-d660-4d64-897d-4d5929200a42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T12:24:54.495920Z",
     "iopub.status.busy": "2024-09-22T12:24:54.495479Z",
     "iopub.status.idle": "2024-09-22T12:24:55.824491Z",
     "shell.execute_reply": "2024-09-22T12:24:55.824041Z",
     "shell.execute_reply.started": "2024-09-22T12:24:54.495909Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "def vllm_load(model):    \n",
    "    llm = LLM(model, gpu_memory_utilization=0.99, max_model_len=8192)\n",
    "    llm._model = model\n",
    "    return llm\n",
    "\n",
    "def vllm_generate(messages, llm):    \n",
    "    print(f\"vLLM performance test:\")\n",
    "    \n",
    "    prompts = format_prompt(messages, llm._model)\n",
    "    sampling_params = SamplingParams(temperature=0.7, top_p=0.8, repetition_penalty=1.05, max_tokens=512)\n",
    "    # warmup\n",
    "    outputs = llm.generate(prompts[0], sampling_params)\n",
    "    print(f\"Generated text: {outputs[0].outputs[0].text!r}\")\n",
    "    \n",
    "    for batch_size in range(1, len(messages) + 1):\n",
    "        start_time = time.time()  # Record the start time\n",
    "        outputs = llm.generate(prompts[0:batch_size], sampling_params)\n",
    "        end_time = time.time()  # Record the end time\n",
    "            \n",
    "        # Print the outputs.\n",
    "        tokenscount = 0\n",
    "        for output in outputs:\n",
    "            generated_text = output.outputs[0].text\n",
    "            tokenscount = tokenscount + len(output.outputs[0].token_ids)\n",
    "\n",
    "        tokens_per_sec = tokenscount/(end_time-start_time)\n",
    "        print(f\"- batch size {batch_size}: {tokens_per_sec:.2f} tokens/sec ({batch_size} x {tokens_per_sec/batch_size:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2267f691-7b8f-44a7-82c6-7e85598c7a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T12:23:59.651640Z",
     "iopub.status.busy": "2024-09-22T12:23:59.651455Z",
     "iopub.status.idle": "2024-09-22T12:24:42.314947Z",
     "shell.execute_reply": "2024-09-22T12:24:42.313020Z",
     "shell.execute_reply.started": "2024-09-22T12:23:59.651627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 14:24:00 llm_engine.py:223] Initializing an LLM engine (v0.6.1.post2) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)\n",
      "WARNING 09-22 14:24:00 utils.py:727] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "INFO 09-22 14:24:01 model_runner.py:997] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...\n",
      "INFO 09-22 14:24:01 weight_utils.py:242] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e474460ce5e1423cadd36a444b5c44e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 14:24:17 model_runner.py:1008] Loading model weights took 14.9888 GB\n",
      "INFO 09-22 14:24:19 gpu_executor.py:122] # GPU blocks: 3610, # CPU blocks: 2048\n",
      "INFO 09-22 14:24:31 model_runner.py:1311] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 09-22 14:24:31 model_runner.py:1315] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 09-22 14:24:42 model_runner.py:1430] Graph capturing finished in 11 secs.\n"
     ]
    }
   ],
   "source": [
    "llm = vllm_load(test_models[\"llama-3.1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d938178-167d-4df8-a5db-43aaa6026140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:15:58.808650Z",
     "iopub.status.busy": "2024-09-21T13:15:58.807243Z",
     "iopub.status.idle": "2024-09-21T13:21:53.704000Z",
     "shell.execute_reply": "2024-09-21T13:21:53.703624Z",
     "shell.execute_reply.started": "2024-09-21T13:15:58.808607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vLLM performance test:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████| 1/1 [00:09<00:00,  9.58s/it, est. speed input: 6.58 toks/s, output: 53.47 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: \"Le Crédit Mutuel est une banque coopérative française qui offre plusieurs avantages à ses membres et clients. Voici quelques-uns des principaux avantages :\\n\\n1. **Intérêts plus élevés sur les épargnes** : Le Crédit Mutuel propose des taux d'intérêt plus élevés sur les comptes d'épargne que de nombreux autres établissements bancaires.\\n2. **Taux d'emprunt compétitifs** : Les prêts personnels, les prêts immobiliers et les prêts pour la mobilité sont proposés avec des taux d'intérêt attractifs.\\n3. **Services personnalisés** : Le Crédit Mutuel offre des services personnalisés et adaptés aux besoins de ses membres et clients, grâce à une approche relationnelle et à une connaissance approfondie de leurs situations financières.\\n4. **Sécurité et confidentialité** : Le Crédit Mutuel s'engage à protéger les données personnelles et financières de ses membres et clients, conformément aux règles de protection des données.\\n5. **Participation aux décisions** : En tant que membre du Crédit Mutuel, vous avez la possibilité de participer aux assemblées générales et de voter sur les décisions stratégiques de l'institution.\\n6. **Services bancaires complets** : Le Crédit Mutuel propose un large éventail de services bancaires, y compris des comptes courants, des comptes d'épargne, des prêts, des cartes de crédit et des assurances.\\n7. **Aide à la gestion financière** : Le Crédit Mutuel propose des outils et des conseils pour aider ses membres et clients à gérer leur budget, à planifier leur avenir financier et à atteindre leurs objectifs économiques.\\n8. **Prévention de la fraude** : Le Crédit Mutuel met en place des mesures de prévention de la fraude pour protéger les comptes et les données de ses membres et clients.\\n9. **Services numériques** : Le Crédit Mutuel propose des applications mobiles et un site internet sécurisé pour gérer ses comptes et effectuer des opérations bancaires en ligne.\\n10. **Eng\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████| 1/1 [00:09<00:00,  9.30s/it, est. speed input: 6.78 toks/s, output: 55.07 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 1: 55.06 tokens/sec (1 x 55.06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 2/2 [00:09<00:00,  4.79s/it, est. speed input: 13.24 toks/s, output: 106.79 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 2: 106.76 tokens/sec (2 x 53.38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 3/3 [00:09<00:00,  3.21s/it, est. speed input: 19.84 toks/s, output: 159.53 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 3: 159.49 tokens/sec (3 x 53.16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 4/4 [00:09<00:00,  2.41s/it, est. speed input: 26.13 toks/s, output: 209.16 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 4: 209.11 tokens/sec (4 x 52.28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 5/5 [00:09<00:00,  1.95s/it, est. speed input: 32.38 toks/s, output: 255.03 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 5: 254.98 tokens/sec (5 x 51.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 6/6 [00:09<00:00,  1.63s/it, est. speed input: 38.78 toks/s, output: 314.30 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 6: 314.21 tokens/sec (6 x 52.37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 7/7 [00:09<00:00,  1.40s/it, est. speed input: 45.17 toks/s, output: 365.40 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 7: 365.28 tokens/sec (7 x 52.18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 8/8 [00:09<00:00,  1.23s/it, est. speed input: 51.42 toks/s, output: 417.88 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 8: 417.78 tokens/sec (8 x 52.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 9/9 [00:09<00:00,  1.10s/it, est. speed input: 57.23 toks/s, output: 453.61 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 9: 453.50 tokens/sec (9 x 50.39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 10/10 [00:09<00:00,  1.00it/s, est. speed input: 63.26 toks/s, output: 513.27 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 10: 513.14 tokens/sec (10 x 51.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 11/11 [00:10<00:00,  1.09it/s, est. speed input: 69.12 toks/s, output: 558.33 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 11: 558.14 tokens/sec (11 x 50.74)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 12/12 [00:10<00:00,  1.19it/s, est. speed input: 74.86 toks/s, output: 607.20 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 12: 607.03 tokens/sec (12 x 50.59)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 13/13 [00:10<00:00,  1.28it/s, est. speed input: 80.73 toks/s, output: 656.08 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 13: 655.89 tokens/sec (13 x 50.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 14/14 [00:10<00:00,  1.36it/s, est. speed input: 86.00 toks/s, output: 690.02 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 14: 689.78 tokens/sec (14 x 49.27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 15/15 [00:10<00:00,  1.47it/s, est. speed input: 92.83 toks/s, output: 748.79 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 15: 748.58 tokens/sec (15 x 49.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 16/16 [00:10<00:00,  1.56it/s, est. speed input: 98.23 toks/s, output: 791.13 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 16: 790.84 tokens/sec (16 x 49.43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 17/17 [00:10<00:00,  1.56it/s, est. speed input: 98.22 toks/s, output: 794.11 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 17: 793.86 tokens/sec (17 x 46.70)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 18/18 [00:11<00:00,  1.64it/s, est. speed input: 103.14 toks/s, output: 837.51 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 18: 837.21 tokens/sec (18 x 46.51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 19/19 [00:11<00:00,  1.73it/s, est. speed input: 108.98 toks/s, output: 872.24 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 19: 871.95 tokens/sec (19 x 45.89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 20/20 [00:11<00:00,  1.79it/s, est. speed input: 112.62 toks/s, output: 906.29 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 20: 905.96 tokens/sec (20 x 45.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 21/21 [00:11<00:00,  1.88it/s, est. speed input: 118.43 toks/s, output: 959.20 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 21: 958.86 tokens/sec (21 x 45.66)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 22/22 [00:11<00:00,  1.96it/s, est. speed input: 123.62 toks/s, output: 1003.89 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 22: 1003.52 tokens/sec (22 x 45.61)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 23/23 [00:11<00:00,  1.97it/s, est. speed input: 124.36 toks/s, output: 1009.31 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 23: 1008.92 tokens/sec (23 x 43.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 24/24 [00:11<00:00,  2.04it/s, est. speed input: 128.40 toks/s, output: 1043.48 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 24: 1043.09 tokens/sec (24 x 43.46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 25/25 [00:11<00:00,  2.12it/s, est. speed input: 133.65 toks/s, output: 1076.93 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 25: 1076.50 tokens/sec (25 x 43.06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 26/26 [00:11<00:00,  2.17it/s, est. speed input: 136.85 toks/s, output: 1102.69 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 26: 1102.26 tokens/sec (26 x 42.39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 27/27 [00:11<00:00,  2.27it/s, est. speed input: 142.88 toks/s, output: 1157.88 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 27: 1157.37 tokens/sec (27 x 42.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 28/28 [00:11<00:00,  2.34it/s, est. speed input: 147.12 toks/s, output: 1189.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 28: 1189.24 tokens/sec (28 x 42.47)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 29/29 [00:12<00:00,  2.40it/s, est. speed input: 151.45 toks/s, output: 1223.51 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 29: 1222.97 tokens/sec (29 x 42.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 30/30 [00:12<00:00,  2.44it/s, est. speed input: 153.90 toks/s, output: 1243.11 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 30: 1242.63 tokens/sec (30 x 41.42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 31/31 [00:12<00:00,  2.53it/s, est. speed input: 159.80 toks/s, output: 1282.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 31: 1282.23 tokens/sec (31 x 41.36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 32/32 [00:12<00:00,  2.56it/s, est. speed input: 161.42 toks/s, output: 1308.09 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 32: 1307.55 tokens/sec (32 x 40.86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vllm_generate(test_messages*8, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84d1f3d-603b-4cf3-be32-ed0312caf5bc",
   "metadata": {},
   "source": [
    "### SGLang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98445cbd-0312-4cf5-8832-53b2da13e83c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T13:13:21.510206Z",
     "iopub.status.busy": "2024-09-22T13:13:21.509719Z",
     "iopub.status.idle": "2024-09-22T13:13:21.520214Z",
     "shell.execute_reply": "2024-09-22T13:13:21.519658Z",
     "shell.execute_reply.started": "2024-09-22T13:13:21.510179Z"
    }
   },
   "outputs": [],
   "source": [
    "import json, time\n",
    "import sglang\n",
    "\n",
    "def sglang_load(model):\n",
    "    runtime = sglang.Runtime(model_path=model)\n",
    "    runtime._model = model\n",
    "    return runtime\n",
    "\n",
    "def sglang_generate(messages, runtime):\n",
    "    print(f\"SGLang performance test:\")\n",
    "    \n",
    "    prompts = format_prompt(messages, runtime._model)\n",
    "    sampling_params = { \"temperature\":0.7, \"top_p\":0.8, \"repetition_penalty\":1.05, \"max_new_tokens\":512 }\n",
    "    # warmup\n",
    "    output = json.loads(runtime.generate(prompt=prompts[0], sampling_params=sampling_params))\n",
    "    print(f\"Generated text: {output['text']!r}\")\n",
    "    \n",
    "    for batch_size in range(1, len(messages) + 1):\n",
    "        start_time = time.time()  # Record the start time\n",
    "        outputs = json.loads(runtime.generate(prompt=prompts[0:batch_size], sampling_params=sampling_params))\n",
    "        end_time = time.time()  # Record the end time\n",
    "            \n",
    "        # Print the outputs.\n",
    "        tokenscount = 0\n",
    "        for output in outputs:\n",
    "            generated_text = output[\"text\"]\n",
    "            tokenscount = tokenscount + output[\"meta_info\"][\"completion_tokens\"]\n",
    "\n",
    "        tokens_per_sec = tokenscount/(end_time-start_time)\n",
    "        print(f\"- batch size {batch_size}: {tokens_per_sec:.2f} tokens/sec ({batch_size} x {tokens_per_sec/batch_size:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128fac7f-aa20-4429-b6b1-31a30fc7ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = sglang_load(test_models[\"llama-3.1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23096e8-950c-48fd-adf7-1bef1b423521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:23:53.873159Z",
     "iopub.status.busy": "2024-09-21T13:23:53.872596Z",
     "iopub.status.idle": "2024-09-21T13:29:57.571364Z",
     "shell.execute_reply": "2024-09-21T13:29:57.570949Z",
     "shell.execute_reply.started": "2024-09-21T13:23:53.873131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGLang performance test:\n",
      "Generated text: \"Le Crédit Mutuel est une banque coopérative française qui offre divers avantages à ses membres et clients. Voici quelques-uns des principaux avantages :\\n\\n1. **Intérêts plus élevés sur les dépôts** : Le Crédit Mutuel propose des taux d'intérêt plus élevés que les banques traditionnelles pour les dépôts, ce qui permet aux clients de gagner plus d'argent sur leurs économies.\\n\\n2. **Taux d'emprunt compétitifs** : Les emprunts du Crédit Mutuel sont souvent moins chers que ceux proposés par les banques traditionnelles, ce qui peut aider les clients à se procurer des prêts à des conditions avantageuses.\\n\\n3. **Services personnalisés** : En tant que banque coopérative, le Crédit Mutuel prend en compte les besoins spécifiques de ses clients et offre des services personnalisés pour répondre à leurs attentes.\\n\\n4. **Transparence et sécurité** : Le Crédit Mutuel est connu pour sa transparence financière et sa sécurité, ce qui rassure les clients qui souhaitent faire confiance à leur banque.\\n\\n5. **Services numériques performants** : Le Crédit Mutuel propose des services en ligne et mobiles pratiques, permettant aux clients de gérer leurs comptes et effectuer des opérations bancaires en toute simplicité.\\n\\n6. **Prise en charge des projets locaux** : Le Crédit Mutuel soutient les projets locaux et les initiatives communautaires, ce qui contribue au développement économique et social des régions où il est présent.\\n\\n7. **Éthique et responsabilité sociale** : Le Crédit Mutuel est engagé dans des pratiques éthiques et responsables, ce qui rassure les clients qui souhaitent faire des affaires avec une banque qui partage leurs valeurs.\\n\\n8. **Diversification des produits et services** : Le Crédit Mutuel propose une gamme large de produits et services bancaires, allant des comptes courants et des épargnes aux prêts et aux assurances.\\n\\n9. **Conseil financier personnalisé** : Les conseillers du Crédit Mutuel offrent un accompagnement personnalisé pour aider les\"\n",
      "- batch size 1: 54.40 tokens/sec (1 x 54.40)\n",
      "- batch size 2: 106.28 tokens/sec (2 x 53.14)\n",
      "- batch size 3: 158.87 tokens/sec (3 x 52.96)\n",
      "- batch size 4: 204.87 tokens/sec (4 x 51.22)\n",
      "- batch size 5: 261.97 tokens/sec (5 x 52.39)\n",
      "- batch size 6: 313.69 tokens/sec (6 x 52.28)\n",
      "- batch size 7: 365.71 tokens/sec (7 x 52.24)\n",
      "- batch size 8: 417.00 tokens/sec (8 x 52.13)\n",
      "- batch size 9: 468.16 tokens/sec (9 x 52.02)\n",
      "- batch size 10: 510.35 tokens/sec (10 x 51.04)\n",
      "- batch size 11: 550.32 tokens/sec (11 x 50.03)\n",
      "- batch size 12: 603.20 tokens/sec (12 x 50.27)\n",
      "- batch size 13: 641.52 tokens/sec (13 x 49.35)\n",
      "- batch size 14: 704.31 tokens/sec (14 x 50.31)\n",
      "- batch size 15: 757.44 tokens/sec (15 x 50.50)\n",
      "- batch size 16: 803.96 tokens/sec (16 x 50.25)\n",
      "- batch size 17: 809.71 tokens/sec (17 x 47.63)\n",
      "- batch size 18: 856.48 tokens/sec (18 x 47.58)\n",
      "- batch size 19: 900.94 tokens/sec (19 x 47.42)\n",
      "- batch size 20: 932.80 tokens/sec (20 x 46.64)\n",
      "- batch size 21: 975.06 tokens/sec (21 x 46.43)\n",
      "- batch size 22: 1020.68 tokens/sec (22 x 46.39)\n",
      "- batch size 23: 1063.49 tokens/sec (23 x 46.24)\n",
      "- batch size 24: 1104.37 tokens/sec (24 x 46.02)\n",
      "- batch size 25: 1146.04 tokens/sec (25 x 45.84)\n",
      "- batch size 26: 1202.71 tokens/sec (26 x 46.26)\n",
      "- batch size 27: 1240.36 tokens/sec (27 x 45.94)\n",
      "- batch size 28: 1290.63 tokens/sec (28 x 46.09)\n",
      "- batch size 29: 1332.88 tokens/sec (29 x 45.96)\n",
      "- batch size 30: 1369.35 tokens/sec (30 x 45.64)\n",
      "- batch size 31: 932.32 tokens/sec (31 x 30.07)\n",
      "- batch size 32: 640.79 tokens/sec (32 x 20.02)\n"
     ]
    }
   ],
   "source": [
    "sglang_generate(test_messages*8, runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65080db2-7b9c-4b53-b31a-f3287412935a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f6239a-2e41-4a0c-8a3a-c7d36d96e063",
   "metadata": {},
   "source": [
    "https://github.com/ollama/ollama-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59930211-acff-404a-b3d1-1d091474cd44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T10:04:19.266501Z",
     "iopub.status.busy": "2024-09-22T10:04:19.265772Z",
     "iopub.status.idle": "2024-09-22T10:04:19.301264Z",
     "shell.execute_reply": "2024-09-22T10:04:19.300884Z",
     "shell.execute_reply.started": "2024-09-22T10:04:19.266474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [{'name': 'llama3.1:8b-instruct-q4_0',\n",
       "   'model': 'llama3.1:8b-instruct-q4_0',\n",
       "   'modified_at': '2024-09-22T11:43:03.484852591+02:00',\n",
       "   'size': 4661230766,\n",
       "   'digest': '42182419e9508c30c4b1fe55015f06b65f4ca4b9e28a744be55008d21998a093',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '8.0B',\n",
       "    'quantization_level': 'Q4_0'}},\n",
       "  {'name': 'llama3.1:8b-instruct-q8_0',\n",
       "   'model': 'llama3.1:8b-instruct-q8_0',\n",
       "   'modified_at': '2024-09-22T11:33:10.006555339+02:00',\n",
       "   'size': 8540789934,\n",
       "   'digest': 'b158ded76fa05be6bce8a682099ce5df8c5571340a04cf63a2923464679db576',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '8.0B',\n",
       "    'quantization_level': 'Q8_0'}},\n",
       "  {'name': 'llama3.1:8b-instruct-fp16',\n",
       "   'model': 'llama3.1:8b-instruct-fp16',\n",
       "   'modified_at': '2024-09-21T22:54:30.926572546+02:00',\n",
       "   'size': 16068910253,\n",
       "   'digest': '4aacac4194543ff7f70dab3f2ebc169c132d5319bb36f7a7e99c4ff525ebcc09',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '8.0B',\n",
       "    'quantization_level': 'F16'}}]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "ollama.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ace51020-dc87-4cbb-a5fb-686ffbc9ccd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T21:06:14.481788Z",
     "iopub.status.busy": "2024-09-21T21:06:14.481058Z",
     "iopub.status.idle": "2024-09-21T21:06:14.501823Z",
     "shell.execute_reply": "2024-09-21T21:06:14.501524Z",
     "shell.execute_reply.started": "2024-09-21T21:06:14.481752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{- if or .System .Tools }}<|start_header_id|>system<|end_header_id|>\n",
      "{{- if .System }}\n",
      "\n",
      "{{ .System }}\n",
      "{{- end }}\n",
      "{{- if .Tools }}\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "\n",
      "When you receive a tool call response, use the output to format an answer to the orginal user question.\n",
      "\n",
      "You are a helpful assistant with tool calling capabilities.\n",
      "{{- end }}<|eot_id|>\n",
      "{{- end }}\n",
      "{{- range $i, $_ := .Messages }}\n",
      "{{- $last := eq (len (slice $.Messages $i)) 1 }}\n",
      "{{- if eq .Role \"user\" }}<|start_header_id|>user<|end_header_id|>\n",
      "{{- if and $.Tools $last }}\n",
      "\n",
      "Given the following functions, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.\n",
      "\n",
      "Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}. Do not use variables.\n",
      "\n",
      "{{ range $.Tools }}\n",
      "{{- . }}\n",
      "{{ end }}\n",
      "Question: {{ .Content }}<|eot_id|>\n",
      "{{- else }}\n",
      "\n",
      "{{ .Content }}<|eot_id|>\n",
      "{{- end }}{{ if $last }}<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{{ end }}\n",
      "{{- else if eq .Role \"assistant\" }}<|start_header_id|>assistant<|end_header_id|>\n",
      "{{- if .ToolCalls }}\n",
      "{{ range .ToolCalls }}\n",
      "{\"name\": \"{{ .Function.Name }}\", \"parameters\": {{ .Function.Arguments }}}{{ end }}\n",
      "{{- else }}\n",
      "\n",
      "{{ .Content }}\n",
      "{{- end }}{{ if not $last }}<|eot_id|>{{ end }}\n",
      "{{- else if eq .Role \"tool\" }}<|start_header_id|>ipython<|end_header_id|>\n",
      "\n",
      "{{ .Content }}<|eot_id|>{{ if $last }}<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{{ end }}\n",
      "{{- end }}\n",
      "{{- end }}\n"
     ]
    }
   ],
   "source": [
    "print(ollama.show(\"llama3.1:8b-instruct-fp16\")['template'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5e8405-b6ed-4ba2-a575-46bddf2f9f8d",
   "metadata": {},
   "source": [
    "https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a9f668b-5d74-4b78-8a86-408328fd9978",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T09:37:45.184355Z",
     "iopub.status.busy": "2024-09-22T09:37:45.183990Z",
     "iopub.status.idle": "2024-09-22T09:37:45.191794Z",
     "shell.execute_reply": "2024-09-22T09:37:45.191214Z",
     "shell.execute_reply.started": "2024-09-22T09:37:45.184331Z"
    }
   },
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "# ollama keeps models 5 min in memory by default, they are reloaded by a query\n",
    "def ollama_load(model):\n",
    "    sampling_params = { \"num_predict\":1 }\n",
    "    ollama.generate(model=model, prompt=\"load\", raw=True, options=sampling_params, stream=False)\n",
    "    return model\n",
    "\n",
    "# ollama API only supports batch size 1\n",
    "def ollama_generate(messages, model):\n",
    "    print(f\"ollama performance test:\")\n",
    "    \n",
    "    prompts = format_prompt(messages, runtime._model)\n",
    "    sampling_params = { \"temperature\":0.7, \"top_p\":0.8, \"repeat_penalty\":1.05, \"num_predict\":512 }\n",
    "    # warmup\n",
    "    output = ollama.generate(model=model, prompt=prompts[0], raw=True, options=sampling_params, stream=False)\n",
    "    print(f\"Generated text: {output['response']!r}\")\n",
    "    \n",
    "    for msg_index in range(len(messages)):\n",
    "        start_time = time.time()  # Record the start time\n",
    "        output = ollama.generate(model=model, prompt=prompts[msg_index], raw=True, options=sampling_params, stream=False)\n",
    "        end_time = time.time()  # Record the end time\n",
    "            \n",
    "        # Print the outputs.\n",
    "        tokenscount = output['eval_count']\n",
    "        tokens_per_sec = tokenscount/(end_time-start_time)\n",
    "        print(f\"- batch size 1: {tokens_per_sec:.2f} tokens/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43eb08e5-8f25-4012-8073-0335d02f653c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T09:37:53.426904Z",
     "iopub.status.busy": "2024-09-22T09:37:53.426458Z",
     "iopub.status.idle": "2024-09-22T09:37:53.741430Z",
     "shell.execute_reply": "2024-09-22T09:37:53.741049Z",
     "shell.execute_reply.started": "2024-09-22T09:37:53.426875Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ollama_load(ollama_test_models[\"llama-3.1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0346b5a-21ae-4f4a-9243-2e4a14ada961",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T09:38:09.282965Z",
     "iopub.status.busy": "2024-09-22T09:38:09.282620Z",
     "iopub.status.idle": "2024-09-22T09:38:59.041822Z",
     "shell.execute_reply": "2024-09-22T09:38:59.041472Z",
     "shell.execute_reply.started": "2024-09-22T09:38:09.282942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ollama performance test:\n",
      "Generated text: \"Le Crédit Mutuel est une banque coopérative française qui offre divers avantages à ses adhérents. Voici quelques-uns des principaux avantages :\\n\\n1. **Intérêts réduits sur les prêts** : Le Crédit Mutuel propose des taux d'intérêt compétitifs pour les prêts personnels, hypothécaires et professionnels.\\n2. **Avantages fiscaux** : Les adhérents du Crédit Mutuel peuvent bénéficier de réductions fiscales sur leurs prêts et épargnes, en fonction de leur situation financière et de leurs impôts.\\n3. **Assistance financière** : Le Crédit Mutuel offre des services d'assistance financière pour aider ses adhérents à gérer leurs finances et à atteindre leurs objectifs économiques.\\n4. **Produits diversifiés** : Le Crédit Mutuel propose une gamme complète de produits bancaires, tels que les comptes courants, les livrets d'épargne, les cartes de crédit, les assurances et les investissements.\\n5. **Services en ligne** : Les adhérents du Crédit Mutuel ont accès à un portail en ligne sécurisé pour gérer leurs comptes, effectuer des virements, payer leurs factures et suivre leur épargne.\\n6. **Soutien à l'épargne** : Le Crédit Mutuel encourage l'épargne de ses adhérents grâce à des produits spécifiques, tels que les livrets d'épargne ou les comptes d'épargne.\\n7. **Protection et assurance** : Le Crédit Mutuel propose des contrats d'assurance pour protéger les biens et les personnes de ses adhérents contre divers risques (incendie, vol, accident, décès).\\n8. **Soutien à l'entrepreneuriat** : Le Crédit Mutuel offre des prêts et des services spécifiques pour les entrepreneurs et les PME.\\n9. **Fidélité et récompenses** : Les adhérents du Crédit Mutuel peuvent bénéficier de récompenses et de primes en fonction de leur comportement bancaire (\"\n",
      "- batch size 1: 51.97 tokens/sec\n",
      "- batch size 1: 52.16 tokens/sec\n",
      "- batch size 1: 52.33 tokens/sec\n",
      "- batch size 1: 52.55 tokens/sec\n"
     ]
    }
   ],
   "source": [
    "ollama_generate(test_messages, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e81e75-2592-413b-b1ac-99f9a7e273e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T10:16:52.786635Z",
     "iopub.status.busy": "2024-09-22T10:16:52.786354Z",
     "iopub.status.idle": "2024-09-22T10:16:52.788783Z",
     "shell.execute_reply": "2024-09-22T10:16:52.788498Z",
     "shell.execute_reply.started": "2024-09-22T10:16:52.786624Z"
    }
   },
   "source": [
    "# 3. Performance tests on RTX 4090"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73e1d8a-ad1c-454b-a7b6-65c35ba8cc3d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## vLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04602b22-efc0-4bd8-bbc1-280ef1be558e",
   "metadata": {},
   "source": [
    "### FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31c545d0-98c8-4ffe-8af4-48285ce273a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T10:18:56.380565Z",
     "iopub.status.busy": "2024-09-22T10:18:56.379872Z",
     "iopub.status.idle": "2024-09-22T10:19:18.485222Z",
     "shell.execute_reply": "2024-09-22T10:19:18.484869Z",
     "shell.execute_reply.started": "2024-09-22T10:18:56.380534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 12:18:56 llm_engine.py:223] Initializing an LLM engine (v0.6.1.post2) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)\n",
      "WARNING 09-22 12:18:57 utils.py:727] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "INFO 09-22 12:18:57 model_runner.py:997] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...\n",
      "INFO 09-22 12:18:58 weight_utils.py:242] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7b6ac65bd14f0fb9f0e270863a6f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 12:19:07 model_runner.py:1008] Loading model weights took 14.9888 GB\n",
      "INFO 09-22 12:19:08 gpu_executor.py:122] # GPU blocks: 3610, # CPU blocks: 2048\n",
      "INFO 09-22 12:19:08 model_runner.py:1311] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 09-22 12:19:08 model_runner.py:1315] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 09-22 12:19:18 model_runner.py:1430] Graph capturing finished in 10 secs.\n"
     ]
    }
   ],
   "source": [
    "llm = vllm_load(test_models[\"llama-3.1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b9b791a-343f-4e3f-acd9-a67fa153f6d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T10:19:41.643872Z",
     "iopub.status.busy": "2024-09-22T10:19:41.643423Z",
     "iopub.status.idle": "2024-09-22T10:29:41.318722Z",
     "shell.execute_reply": "2024-09-22T10:29:41.318342Z",
     "shell.execute_reply.started": "2024-09-22T10:19:41.643840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vLLM performance test:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████| 1/1 [00:09<00:00,  9.62s/it, est. speed input: 6.55 toks/s, output: 53.23 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: \"Le Crédit Mutuel est une banque coopérative française qui offre plusieurs avantages à ses membres et clients. Voici quelques-uns des principaux avantages :\\n\\n1. **Intérêts plus élevés sur les épargnes** : Le Crédit Mutuel propose des taux d'intérêt plus élevés sur les comptes d'épargne que de nombreux autres établissements bancaires.\\n2. **Taux d'emprunt compétitifs** : Les prêts personnels, les prêts immobiliers et les prêts pour la mobilité sont proposés avec des taux d'intérêt attractifs.\\n3. **Services personnalisés** : Le Crédit Mutuel offre des services personnalisés et adaptés aux besoins de ses membres et clients, grâce à une approche relationnelle et à une connaissance approfondie de leurs situations financières.\\n4. **Sécurité et confidentialité** : Le Crédit Mutuel s'engage à protéger les données personnelles et financières de ses membres et clients, conformément aux règles de protection des données.\\n5. **Participation aux décisions** : En tant que membre du Crédit Mutuel, vous avez la possibilité de participer aux assemblées générales et de voter sur les décisions stratégiques de l'institution.\\n6. **Services bancaires complets** : Le Crédit Mutuel propose un large éventail de services bancaires, y compris des comptes courants, des comptes d'épargne, des prêts, des cartes de crédit et des assurances.\\n7. **Aide à la gestion financière** : Le Crédit Mutuel propose des outils et des conseils pour aider ses membres et clients à gérer leur budget, à planifier leur avenir financier et à atteindre leurs objectifs économiques.\\n8. **Prévention de la fraude** : Le Crédit Mutuel met en place des mesures de prévention de la fraude pour protéger les comptes et les données de ses membres et clients.\\n9. **Services numériques** : Le Crédit Mutuel propose des applications mobiles et un site internet sécurisé pour gérer ses comptes et effectuer des opérations bancaires en ligne.\\n10. **Eng\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████| 1/1 [00:09<00:00,  9.29s/it, est. speed input: 6.78 toks/s, output: 55.11 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 1: 55.10 tokens/sec (1 x 55.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 2/2 [00:09<00:00,  4.79s/it, est. speed input: 13.26 toks/s, output: 106.91 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 2: 106.89 tokens/sec (2 x 53.44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 3/3 [00:09<00:00,  3.20s/it, est. speed input: 19.89 toks/s, output: 159.98 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 3: 159.94 tokens/sec (3 x 53.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 4/4 [00:09<00:00,  2.41s/it, est. speed input: 26.12 toks/s, output: 209.04 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 4: 209.00 tokens/sec (4 x 52.25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 5/5 [00:09<00:00,  1.95s/it, est. speed input: 32.36 toks/s, output: 254.88 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 5: 254.81 tokens/sec (5 x 50.96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 6/6 [00:09<00:00,  1.63s/it, est. speed input: 38.83 toks/s, output: 314.72 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 6: 314.63 tokens/sec (6 x 52.44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 7/7 [00:09<00:00,  1.40s/it, est. speed input: 45.15 toks/s, output: 365.32 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 7: 365.23 tokens/sec (7 x 52.18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 8/8 [00:09<00:00,  1.23s/it, est. speed input: 51.20 toks/s, output: 416.13 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 8: 416.02 tokens/sec (8 x 52.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 9/9 [00:09<00:00,  1.10s/it, est. speed input: 57.18 toks/s, output: 453.22 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 9: 453.06 tokens/sec (9 x 50.34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 10/10 [00:09<00:00,  1.01it/s, est. speed input: 63.46 toks/s, output: 514.91 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 10: 514.74 tokens/sec (10 x 51.47)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 11/11 [00:09<00:00,  1.10it/s, est. speed input: 69.57 toks/s, output: 561.93 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 11: 561.78 tokens/sec (11 x 51.07)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 12/12 [00:10<00:00,  1.19it/s, est. speed input: 75.24 toks/s, output: 610.24 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 12: 610.03 tokens/sec (12 x 50.84)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 13/13 [00:10<00:00,  1.28it/s, est. speed input: 80.76 toks/s, output: 656.31 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 13: 656.12 tokens/sec (13 x 50.47)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 14/14 [00:10<00:00,  1.36it/s, est. speed input: 86.09 toks/s, output: 690.78 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 14: 690.56 tokens/sec (14 x 49.33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 15/15 [00:10<00:00,  1.47it/s, est. speed input: 92.65 toks/s, output: 747.39 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 15: 747.14 tokens/sec (15 x 49.81)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 16/16 [00:10<00:00,  1.56it/s, est. speed input: 98.35 toks/s, output: 792.05 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 16: 791.76 tokens/sec (16 x 49.49)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 17/17 [00:10<00:00,  1.55it/s, est. speed input: 97.86 toks/s, output: 791.16 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 17: 790.86 tokens/sec (17 x 46.52)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 18/18 [00:11<00:00,  1.63it/s, est. speed input: 102.61 toks/s, output: 833.17 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 18: 832.88 tokens/sec (18 x 46.27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 19/19 [00:11<00:00,  1.73it/s, est. speed input: 108.87 toks/s, output: 871.30 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 19: 871.01 tokens/sec (19 x 45.84)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 20/20 [00:11<00:00,  1.79it/s, est. speed input: 112.79 toks/s, output: 907.66 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 20: 907.32 tokens/sec (20 x 45.37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 21/21 [00:11<00:00,  1.88it/s, est. speed input: 118.24 toks/s, output: 957.62 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 21: 957.29 tokens/sec (21 x 45.59)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 22/22 [00:11<00:00,  1.96it/s, est. speed input: 123.82 toks/s, output: 1005.52 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 22: 1005.15 tokens/sec (22 x 45.69)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 23/23 [00:11<00:00,  1.96it/s, est. speed input: 123.65 toks/s, output: 1003.52 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 23: 1003.09 tokens/sec (23 x 43.61)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 24/24 [00:11<00:00,  2.03it/s, est. speed input: 127.89 toks/s, output: 1039.36 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 24: 1038.99 tokens/sec (24 x 43.29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 25/25 [00:11<00:00,  2.09it/s, est. speed input: 131.69 toks/s, output: 1061.09 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 25: 1060.58 tokens/sec (25 x 42.42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 26/26 [00:11<00:00,  2.18it/s, est. speed input: 137.70 toks/s, output: 1109.60 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 26: 1109.19 tokens/sec (26 x 42.66)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 27/27 [00:11<00:00,  2.26it/s, est. speed input: 142.36 toks/s, output: 1153.66 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 27: 1153.22 tokens/sec (27 x 42.71)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 28/28 [00:12<00:00,  2.33it/s, est. speed input: 146.82 toks/s, output: 1187.31 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 28: 1186.84 tokens/sec (28 x 42.39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 29/29 [00:12<00:00,  2.40it/s, est. speed input: 151.49 toks/s, output: 1223.90 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 29: 1223.40 tokens/sec (29 x 42.19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 30/30 [00:12<00:00,  2.44it/s, est. speed input: 154.00 toks/s, output: 1243.88 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 30: 1243.38 tokens/sec (30 x 41.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 31/31 [00:12<00:00,  2.53it/s, est. speed input: 159.80 toks/s, output: 1282.70 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 31: 1282.13 tokens/sec (31 x 41.36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 32/32 [00:12<00:00,  2.59it/s, est. speed input: 163.12 toks/s, output: 1321.86 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 32: 1321.37 tokens/sec (32 x 41.29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 33/33 [00:12<00:00,  2.61it/s, est. speed input: 164.50 toks/s, output: 1331.06 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 33: 1330.54 tokens/sec (33 x 40.32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 34/34 [00:12<00:00,  2.68it/s, est. speed input: 169.09 toks/s, output: 1366.55 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 34: 1365.97 tokens/sec (34 x 40.18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 35/35 [00:12<00:00,  2.75it/s, est. speed input: 173.34 toks/s, output: 1405.81 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 35: 1405.09 tokens/sec (35 x 40.15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 36/36 [00:12<00:00,  2.81it/s, est. speed input: 177.34 toks/s, output: 1431.51 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 36: 1430.91 tokens/sec (36 x 39.75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 37/37 [00:12<00:00,  2.85it/s, est. speed input: 179.79 toks/s, output: 1452.48 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 37: 1451.85 tokens/sec (37 x 39.24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 38/38 [00:13<00:00,  2.91it/s, est. speed input: 183.41 toks/s, output: 1478.96 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 38: 1478.29 tokens/sec (38 x 38.90)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 39/39 [00:13<00:00,  2.99it/s, est. speed input: 188.84 toks/s, output: 1533.46 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 39: 1532.73 tokens/sec (39 x 39.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 40/40 [00:13<00:00,  3.03it/s, est. speed input: 190.64 toks/s, output: 1518.94 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 40: 1518.18 tokens/sec (40 x 37.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 41/41 [00:13<00:00,  3.11it/s, est. speed input: 195.87 toks/s, output: 1575.50 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 41: 1574.79 tokens/sec (41 x 38.41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 42/42 [00:13<00:00,  3.16it/s, est. speed input: 199.45 toks/s, output: 1613.63 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 42: 1612.86 tokens/sec (42 x 38.40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 43/43 [00:13<00:00,  3.18it/s, est. speed input: 200.46 toks/s, output: 1625.72 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 43: 1624.96 tokens/sec (43 x 37.79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 44/44 [00:13<00:00,  3.27it/s, est. speed input: 205.80 toks/s, output: 1659.72 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 44: 1658.89 tokens/sec (44 x 37.70)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 45/45 [00:21<00:00,  2.09it/s, est. speed input: 131.66 toks/s, output: 1064.46 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 45: 1064.15 tokens/sec (45 x 23.65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 46/46 [00:21<00:00,  2.10it/s, est. speed input: 132.23 toks/s, output: 1071.14 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 46: 1070.79 tokens/sec (46 x 23.28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 47/47 [00:22<00:00,  2.13it/s, est. speed input: 134.17 toks/s, output: 1087.55 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 47: 1087.21 tokens/sec (47 x 23.13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 48/48 [00:22<00:00,  2.13it/s, est. speed input: 134.46 toks/s, output: 1085.58 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 48: 1085.12 tokens/sec (48 x 22.61)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vllm_generate(test_messages*12, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e12fe53-aff4-4011-a4c4-42c75a1a0e70",
   "metadata": {},
   "source": [
    "### w8a16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afe30855-d044-44cd-8c26-d1fa906d376e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T10:47:04.141090Z",
     "iopub.status.busy": "2024-09-22T10:47:04.140661Z",
     "iopub.status.idle": "2024-09-22T10:47:19.006399Z",
     "shell.execute_reply": "2024-09-22T10:47:19.005934Z",
     "shell.execute_reply.started": "2024-09-22T10:47:04.141076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 12:47:04 llm_engine.py:223] Initializing an LLM engine (v0.6.1.post2) with config: model='neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a16', speculative_config=None, tokenizer='neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a16', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=compressed-tensors, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a16, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)\n",
      "WARNING 09-22 12:47:04 utils.py:727] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "INFO 09-22 12:47:05 model_runner.py:997] Starting to load model neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a16...\n",
      "INFO 09-22 12:47:05 weight_utils.py:242] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50628679523742e29c2ef094a4b4017a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 12:47:08 model_runner.py:1008] Loading model weights took 8.4927 GB\n",
      "INFO 09-22 12:47:09 gpu_executor.py:122] # GPU blocks: 6716, # CPU blocks: 2048\n",
      "INFO 09-22 12:47:09 model_runner.py:1311] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 09-22 12:47:09 model_runner.py:1315] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 09-22 12:47:18 model_runner.py:1430] Graph capturing finished in 9 secs.\n"
     ]
    }
   ],
   "source": [
    "llm = vllm_load(test_models[\"llama-3.1:w8a16\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08425c2e-00b1-4ce6-a386-dfe38fb14545",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T11:02:36.653838Z",
     "iopub.status.busy": "2024-09-22T11:02:36.653443Z",
     "iopub.status.idle": "2024-09-22T11:12:26.033599Z",
     "shell.execute_reply": "2024-09-22T11:12:26.032790Z",
     "shell.execute_reply.started": "2024-09-22T11:02:36.653812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vLLM performance test:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████| 1/1 [00:06<00:00,  6.05s/it, est. speed input: 6.94 toks/s, output: 84.63 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: \"Le Crédit Mutuel est une banque coopérative française qui offre de nombreux avantages à ses adhérents et clients. Voici quelques-uns des principaux avantages :\\n\\n1. **Intérêts plus élevés** : Le Crédit Mutuel propose des taux d'intérêt plus élevés que les banques traditionnelles, notamment pour les comptes courants et les prêts.\\n2. **Services personnalisés** : En tant que banque coopérative, le Crédit Mutuel met l'accent sur la proximité et la personnalisation de ses services. Les clients ont accès à des conseillers financiers compétents qui leur proposent des solutions adaptées à leurs besoins.\\n3. **Transparence et sécurité** : Le Crédit Mutuel est connu pour sa transparence dans les tarifs et les conditions de prêt. Les clients sont également protégés par des garanties de sécurité renforcées.\\n4. **Épargne et placement** : Le Crédit Mutuel propose une gamme de produits d'épargne et de placement attractifs, notamment des comptes d'épargne, des livrets et des fonds communs de placement.\\n5. **Prêts et financements** : Le Crédit Mutuel offre une variété de prêts et de financements pour les particuliers et les entreprises, notamment des prêts immobiliers, des prêts personnels et des financements pour les entrepreneurs.\\n6. **Services bancaires en ligne** : Le Crédit Mutuel propose des services bancaires en ligne performants, permettant aux clients de gérer leurs comptes et d'effectuer des transactions en toute sécurité.\\n7. **Réseau de distributeurs** : Le Crédit Mutuel dispose d'un réseau de distributeurs étendu, ce qui facilite l'accès aux services bancaires pour les clients.\\n8. **Engagement social et environnemental** : Le Crédit Mutuel s'engage à des pratiques sociales et environnementales responsables, ce qui correspond aux valeurs de ses adhérents et clients.\\n9. **Adaptabilité et innovation** : Le Crédit Mutuel est constamment en train d'innover et d'améliorer ses services pour répondre aux besoins évoluant des clients\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████| 1/1 [00:05<00:00,  5.82s/it, est. speed input: 7.21 toks/s, output: 87.92 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 1: 87.89 tokens/sec (1 x 87.89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 2/2 [00:05<00:00,  2.98s/it, est. speed input: 14.25 toks/s, output: 171.63 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 2: 171.58 tokens/sec (2 x 85.79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 3/3 [00:05<00:00,  1.99s/it, est. speed input: 21.48 toks/s, output: 257.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 3: 257.67 tokens/sec (3 x 85.89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 4/4 [00:06<00:00,  1.50s/it, est. speed input: 27.99 toks/s, output: 335.94 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 4: 335.81 tokens/sec (4 x 83.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 5/5 [00:06<00:00,  1.21s/it, est. speed input: 34.65 toks/s, output: 413.27 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 5: 413.13 tokens/sec (5 x 82.63)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 6/6 [00:06<00:00,  1.02s/it, est. speed input: 41.37 toks/s, output: 502.31 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 6: 502.13 tokens/sec (6 x 83.69)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 7/7 [00:06<00:00,  1.14it/s, est. speed input: 48.05 toks/s, output: 563.09 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 7: 562.86 tokens/sec (7 x 80.41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 8/8 [00:06<00:00,  1.29it/s, est. speed input: 54.08 toks/s, output: 658.42 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 8: 658.07 tokens/sec (8 x 82.26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 9/9 [00:06<00:00,  1.44it/s, est. speed input: 60.28 toks/s, output: 734.72 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 9: 734.43 tokens/sec (9 x 81.60)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 10/10 [00:06<00:00,  1.59it/s, est. speed input: 66.78 toks/s, output: 806.88 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 10: 806.50 tokens/sec (10 x 80.65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 11/11 [00:06<00:00,  1.69it/s, est. speed input: 71.30 toks/s, output: 857.11 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 11: 856.78 tokens/sec (11 x 77.89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 12/12 [00:06<00:00,  1.87it/s, est. speed input: 78.49 toks/s, output: 956.26 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 12: 955.85 tokens/sec (12 x 79.65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 13/13 [00:06<00:00,  2.01it/s, est. speed input: 84.51 toks/s, output: 1017.83 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 13: 1017.28 tokens/sec (13 x 78.25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 14/14 [00:06<00:00,  2.15it/s, est. speed input: 90.58 toks/s, output: 1087.73 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 14: 1087.24 tokens/sec (14 x 77.66)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 15/15 [00:06<00:00,  2.29it/s, est. speed input: 96.63 toks/s, output: 1162.61 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 15: 1162.08 tokens/sec (15 x 77.47)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 16/16 [00:06<00:00,  2.46it/s, est. speed input: 103.28 toks/s, output: 1235.94 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 16: 1235.28 tokens/sec (16 x 77.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 17/17 [00:07<00:00,  2.37it/s, est. speed input: 99.74 toks/s, output: 1199.24 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 17: 1198.74 tokens/sec (17 x 70.51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 18/18 [00:07<00:00,  2.48it/s, est. speed input: 104.09 toks/s, output: 1259.25 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 18: 1258.70 tokens/sec (18 x 69.93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 19/19 [00:07<00:00,  2.61it/s, est. speed input: 109.93 toks/s, output: 1317.82 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 19: 1317.21 tokens/sec (19 x 69.33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 20/20 [00:07<00:00,  2.67it/s, est. speed input: 112.21 toks/s, output: 1365.50 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 20: 1364.70 tokens/sec (20 x 68.24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 21/21 [00:07<00:00,  2.86it/s, est. speed input: 119.95 toks/s, output: 1436.85 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 21: 1436.10 tokens/sec (21 x 68.39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 22/22 [00:07<00:00,  2.98it/s, est. speed input: 125.10 toks/s, output: 1498.98 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 22: 1498.23 tokens/sec (22 x 68.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 23/23 [00:07<00:00,  3.09it/s, est. speed input: 130.16 toks/s, output: 1557.75 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 23: 1557.03 tokens/sec (23 x 67.70)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 24/24 [00:07<00:00,  3.21it/s, est. speed input: 134.87 toks/s, output: 1614.59 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 24: 1613.82 tokens/sec (24 x 67.24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 25/25 [00:07<00:00,  3.34it/s, est. speed input: 140.42 toks/s, output: 1693.10 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 25: 1692.18 tokens/sec (25 x 67.69)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 26/26 [00:07<00:00,  3.39it/s, est. speed input: 142.59 toks/s, output: 1714.22 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 26: 1713.37 tokens/sec (26 x 65.90)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 27/27 [00:07<00:00,  3.57it/s, est. speed input: 150.38 toks/s, output: 1784.17 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 27: 1783.18 tokens/sec (27 x 66.04)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 28/28 [00:07<00:00,  3.64it/s, est. speed input: 152.80 toks/s, output: 1857.85 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 28: 1856.88 tokens/sec (28 x 66.32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 29/29 [00:07<00:00,  3.73it/s, est. speed input: 156.48 toks/s, output: 1885.38 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 29: 1884.27 tokens/sec (29 x 64.97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 30/30 [00:07<00:00,  3.85it/s, est. speed input: 161.69 toks/s, output: 1931.98 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 30: 1930.94 tokens/sec (30 x 64.36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 31/31 [00:08<00:00,  3.87it/s, est. speed input: 162.87 toks/s, output: 1967.71 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 31: 1966.60 tokens/sec (31 x 63.44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 32/32 [00:07<00:00,  4.06it/s, est. speed input: 170.60 toks/s, output: 2071.56 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 32: 2070.27 tokens/sec (32 x 64.70)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 33/33 [00:08<00:00,  3.99it/s, est. speed input: 167.64 toks/s, output: 2013.23 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 33: 2012.02 tokens/sec (33 x 60.97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 34/34 [00:08<00:00,  4.06it/s, est. speed input: 170.75 toks/s, output: 2057.06 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 34: 2055.94 tokens/sec (34 x 60.47)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 35/35 [00:08<00:00,  4.08it/s, est. speed input: 171.43 toks/s, output: 2072.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 35: 2071.45 tokens/sec (35 x 59.18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 36/36 [00:08<00:00,  4.22it/s, est. speed input: 177.45 toks/s, output: 2139.55 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 36: 2138.32 tokens/sec (36 x 59.40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 37/37 [00:08<00:00,  4.32it/s, est. speed input: 181.51 toks/s, output: 2183.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 37: 2182.29 tokens/sec (37 x 58.98)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 38/38 [00:08<00:00,  4.40it/s, est. speed input: 184.81 toks/s, output: 2239.70 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 38: 2238.40 tokens/sec (38 x 58.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 39/39 [00:08<00:00,  4.45it/s, est. speed input: 186.98 toks/s, output: 2260.57 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 39: 2259.25 tokens/sec (39 x 57.93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 40/40 [00:08<00:00,  4.62it/s, est. speed input: 193.99 toks/s, output: 2339.56 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 40: 2338.13 tokens/sec (40 x 58.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 41/41 [00:08<00:00,  4.67it/s, est. speed input: 196.33 toks/s, output: 2359.76 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 41: 2358.16 tokens/sec (41 x 57.52)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 42/42 [00:08<00:00,  4.72it/s, est. speed input: 198.40 toks/s, output: 2396.78 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 42: 2395.28 tokens/sec (42 x 57.03)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 43/43 [00:09<00:00,  4.71it/s, est. speed input: 198.19 toks/s, output: 2383.91 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 43: 2382.54 tokens/sec (43 x 55.41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 44/44 [00:09<00:00,  4.88it/s, est. speed input: 204.93 toks/s, output: 2442.57 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 44: 2440.99 tokens/sec (44 x 55.48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 45/45 [00:09<00:00,  4.94it/s, est. speed input: 207.50 toks/s, output: 2503.28 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 45: 2501.75 tokens/sec (45 x 55.59)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 46/46 [00:09<00:00,  4.95it/s, est. speed input: 207.94 toks/s, output: 2512.30 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 46: 2510.82 tokens/sec (46 x 54.58)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 47/47 [00:09<00:00,  5.10it/s, est. speed input: 214.43 toks/s, output: 2596.01 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 47: 2594.32 tokens/sec (47 x 55.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 48/48 [00:09<00:00,  5.20it/s, est. speed input: 218.22 toks/s, output: 2615.13 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 48: 2613.30 tokens/sec (48 x 54.44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 49/49 [00:09<00:00,  5.39it/s, est. speed input: 226.31 toks/s, output: 2720.64 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 49: 2718.71 tokens/sec (49 x 55.48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 50/50 [00:09<00:00,  5.55it/s, est. speed input: 233.29 toks/s, output: 2790.36 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 50: 2788.50 tokens/sec (50 x 55.77)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 51/51 [00:09<00:00,  5.17it/s, est. speed input: 217.31 toks/s, output: 2616.69 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 51: 2615.17 tokens/sec (51 x 51.28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 52/52 [00:09<00:00,  5.32it/s, est. speed input: 223.62 toks/s, output: 2702.69 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 52: 2700.85 tokens/sec (52 x 51.94)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 53/53 [00:09<00:00,  5.41it/s, est. speed input: 227.09 toks/s, output: 2724.34 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 53: 2722.50 tokens/sec (53 x 51.37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 54/54 [00:09<00:00,  5.40it/s, est. speed input: 227.07 toks/s, output: 2739.90 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 54: 2738.10 tokens/sec (54 x 50.71)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 55/55 [00:09<00:00,  5.52it/s, est. speed input: 231.88 toks/s, output: 2794.47 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 55: 2792.75 tokens/sec (55 x 50.78)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 56/56 [00:10<00:00,  5.50it/s, est. speed input: 230.98 toks/s, output: 2791.16 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 56: 2789.30 tokens/sec (56 x 49.81)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 57/57 [00:10<00:00,  5.62it/s, est. speed input: 236.13 toks/s, output: 2836.53 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 57: 2834.65 tokens/sec (57 x 49.73)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 58/58 [00:10<00:00,  5.71it/s, est. speed input: 239.74 toks/s, output: 2868.93 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 58: 2866.93 tokens/sec (58 x 49.43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 59/59 [00:10<00:00,  5.69it/s, est. speed input: 239.28 toks/s, output: 2891.93 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 59: 2890.12 tokens/sec (59 x 48.99)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 60/60 [00:10<00:00,  5.85it/s, est. speed input: 245.72 toks/s, output: 2945.32 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 60: 2943.27 tokens/sec (60 x 49.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 61/61 [00:10<00:00,  5.85it/s, est. speed input: 245.85 toks/s, output: 2951.12 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 61: 2949.07 tokens/sec (61 x 48.35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 62/62 [00:10<00:00,  5.93it/s, est. speed input: 249.18 toks/s, output: 2990.77 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 62: 2988.63 tokens/sec (62 x 48.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 63/63 [00:10<00:00,  5.92it/s, est. speed input: 248.93 toks/s, output: 2987.75 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 63: 2985.80 tokens/sec (63 x 47.39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 64/64 [00:10<00:00,  5.93it/s, est. speed input: 249.17 toks/s, output: 2987.57 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 64: 2985.45 tokens/sec (64 x 46.65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 65/65 [00:13<00:00,  4.89it/s, est. speed input: 205.33 toks/s, output: 2475.45 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 65: 2474.07 tokens/sec (65 x 38.06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 66/66 [00:13<00:00,  4.85it/s, est. speed input: 203.57 toks/s, output: 2432.96 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 66: 2431.67 tokens/sec (66 x 36.84)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 67/67 [00:13<00:00,  4.87it/s, est. speed input: 204.60 toks/s, output: 2458.98 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 67: 2457.61 tokens/sec (67 x 36.68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 68/68 [00:14<00:00,  4.75it/s, est. speed input: 199.54 toks/s, output: 2413.53 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 68: 2412.29 tokens/sec (68 x 35.47)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:   0%|                     | 0/69 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvllm_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_messages\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m, in \u001b[0;36mvllm_generate\u001b[0;34m(messages, llm)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_size \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(messages) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     19\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# Record the start time\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# Record the end time\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Print the outputs.\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/utils.py:1036\u001b[0m, in \u001b[0;36mdeprecate_kwargs.<locals>.wrapper.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1029\u001b[0m             msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1031\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1032\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(msg),\n\u001b[1;32m   1033\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# The inner function takes up one level\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m         )\n\u001b[0;32m-> 1036\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/entrypoints/llm.py:348\u001b[0m, in \u001b[0;36mLLM.generate\u001b[0;34m(self, prompts, sampling_params, prompt_token_ids, use_tqdm, lora_request, prompt_adapter_request, guided_options_request)\u001b[0m\n\u001b[1;32m    339\u001b[0m     sampling_params \u001b[38;5;241m=\u001b[39m SamplingParams()\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_add_requests(\n\u001b[1;32m    342\u001b[0m     inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    343\u001b[0m     params\u001b[38;5;241m=\u001b[39msampling_params,\n\u001b[1;32m    344\u001b[0m     lora_request\u001b[38;5;241m=\u001b[39mlora_request,\n\u001b[1;32m    345\u001b[0m     prompt_adapter_request\u001b[38;5;241m=\u001b[39mprompt_adapter_request,\n\u001b[1;32m    346\u001b[0m     guided_options\u001b[38;5;241m=\u001b[39mguided_options_request)\n\u001b[0;32m--> 348\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMEngine\u001b[38;5;241m.\u001b[39mvalidate_outputs(outputs, RequestOutput)\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/entrypoints/llm.py:715\u001b[0m, in \u001b[0;36mLLM._run_engine\u001b[0;34m(self, use_tqdm)\u001b[0m\n\u001b[1;32m    713\u001b[0m total_out_toks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine\u001b[38;5;241m.\u001b[39mhas_unfinished_requests():\n\u001b[0;32m--> 715\u001b[0m     step_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m step_outputs:\n\u001b[1;32m    717\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mfinished:\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/engine/llm_engine.py:1223\u001b[0m, in \u001b[0;36mLLMEngine.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_async_output_proc:\n\u001b[1;32m   1220\u001b[0m     execute_model_req\u001b[38;5;241m.\u001b[39masync_callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_callbacks[\n\u001b[1;32m   1221\u001b[0m         virtual_engine]\n\u001b[0;32m-> 1223\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;66;03m# We need to do this here so that last step's sampled_token_ids can\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;66;03m# be passed to the next iteration for PP.\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler_config\u001b[38;5;241m.\u001b[39mis_multi_step:\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/executor/gpu_executor.py:130\u001b[0m, in \u001b[0;36mGPUExecutor.execute_model\u001b[0;34m(self, execute_model_req)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_model\u001b[39m(\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m, execute_model_req: ExecuteModelRequest\n\u001b[1;32m    129\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[List[Union[SamplerOutput, PoolerOutput]]]:\n\u001b[0;32m--> 130\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/worker/worker_base.py:327\u001b[0m, in \u001b[0;36mLocalOrDistributedWorkerBase.execute_model\u001b[0;34m(self, execute_model_req)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    323\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config\u001b[38;5;241m.\u001b[39mcollect_model_execute_time):\n\u001b[1;32m    324\u001b[0m         orig_model_execute_time \u001b[38;5;241m=\u001b[39m intermediate_tensors\u001b[38;5;241m.\u001b[39mtensors\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    325\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_execute_time\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 327\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkv_caches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mworker_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvirtual_engine\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintermediate_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintermediate_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m model_execute_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m get_pp_group()\u001b[38;5;241m.\u001b[39mis_last_rank:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# output is IntermediateTensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/worker/model_runner_base.py:112\u001b[0m, in \u001b[0;36mdump_input_when_exception.<locals>._inner.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    114\u001b[0m         timestamp \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/worker/model_runner.py:1589\u001b[0m, in \u001b[0;36mModelRunner.execute_model\u001b[0;34m(self, model_input, kv_caches, intermediate_tensors, num_steps)\u001b[0m\n\u001b[1;32m   1586\u001b[0m     model_input\u001b[38;5;241m.\u001b[39masync_callback()\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;66;03m# Sample the next token.\u001b[39;00m\n\u001b[0;32m-> 1589\u001b[0m output: SamplerOutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1591\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1592\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config\u001b[38;5;241m.\u001b[39mcollect_model_forward_time\n\u001b[1;32m   1595\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1596\u001b[0m     model_forward_end\u001b[38;5;241m.\u001b[39msynchronize()\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py:466\u001b[0m, in \u001b[0;36mLlamaForCausalLM.sample\u001b[0;34m(self, logits, sampling_metadata)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    463\u001b[0m     logits: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    464\u001b[0m     sampling_metadata: SamplingMetadata,\n\u001b[1;32m    465\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[SamplerOutput]:\n\u001b[0;32m--> 466\u001b[0m     next_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m next_tokens\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:278\u001b[0m, in \u001b[0;36mSampler.forward\u001b[0;34m(self, logits, sampling_metadata)\u001b[0m\n\u001b[1;32m    275\u001b[0m logprobs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog_softmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# Sample the next tokens.\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m maybe_deferred_sample_results, maybe_sampled_tokens_tensor \u001b[38;5;241m=\u001b[39m \u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_modify_greedy_probs_inplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_gpu_probs_tensor:\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;66;03m# Since we will defer sampler result Pythonization,\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# preserve GPU-side tensors in support of later\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# deferred pythonization of logprobs\u001b[39;00m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m maybe_sampled_tokens_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:968\u001b[0m, in \u001b[0;36m_sample\u001b[0;34m(probs, logprobs, sampling_metadata, sampling_tensors, include_gpu_probs_tensor, modify_greedy_probs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sample\u001b[39m(\n\u001b[1;32m    949\u001b[0m     probs: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    950\u001b[0m     logprobs: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    954\u001b[0m     modify_greedy_probs: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m    955\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SampleReturnType:\n\u001b[1;32m    956\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;124;03m        probs: (num_query_tokens_in_batch, num_vocab)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;124;03m        sampled_token_ids_tensor: A tensor of sampled token ids.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sample_with_torch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampling_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:855\u001b[0m, in \u001b[0;36m_sample_with_torch\u001b[0;34m(probs, logprobs, sampling_metadata, sampling_tensors, include_gpu_probs_tensor, modify_greedy_probs)\u001b[0m\n\u001b[1;32m    843\u001b[0m maybe_deferred_args \u001b[38;5;241m=\u001b[39m SampleResultArgsType(\n\u001b[1;32m    844\u001b[0m     sampling_metadata\u001b[38;5;241m=\u001b[39msampling_metadata,\n\u001b[1;32m    845\u001b[0m     sample_metadata\u001b[38;5;241m=\u001b[39msample_metadata,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    848\u001b[0m     beam_search_logprobs\u001b[38;5;241m=\u001b[39mbeam_search_logprobs,\n\u001b[1;32m    849\u001b[0m     sample_results_dict\u001b[38;5;241m=\u001b[39msample_results_dict)\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sampling_metadata\u001b[38;5;241m.\u001b[39mskip_sampler_cpu_output:\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# GPU<->CPU sync happens here.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# This also converts the sampler output to a Python object.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;66;03m# Return Pythonized sampler result & sampled token ids\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_pythonized_sample_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaybe_deferred_args\u001b[49m\u001b[43m)\u001b[49m, sampled_token_ids_tensor\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;66;03m# Defer sampler result Pythonization; return deferred\u001b[39;00m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Pythonization args & sampled token ids\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    861\u001b[0m         maybe_deferred_args,\n\u001b[1;32m    862\u001b[0m         sampled_token_ids_tensor,\n\u001b[1;32m    863\u001b[0m     )\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:720\u001b[0m, in \u001b[0;36mget_pythonized_sample_results\u001b[0;34m(sample_result_args)\u001b[0m\n\u001b[1;32m    718\u001b[0m     sample_results \u001b[38;5;241m=\u001b[39m _greedy_sample(seq_groups, greedy_samples)\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sampling_type \u001b[38;5;129;01min\u001b[39;00m (SamplingType\u001b[38;5;241m.\u001b[39mRANDOM, SamplingType\u001b[38;5;241m.\u001b[39mRANDOM_SEED):\n\u001b[0;32m--> 720\u001b[0m     sample_results \u001b[38;5;241m=\u001b[39m \u001b[43m_random_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmultinomial_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[43msampling_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sampling_type \u001b[38;5;241m==\u001b[39m SamplingType\u001b[38;5;241m.\u001b[39mBEAM:\n\u001b[1;32m    723\u001b[0m     sample_results \u001b[38;5;241m=\u001b[39m _beam_search_sample(seq_groups,\n\u001b[1;32m    724\u001b[0m                                          beam_search_logprobs)\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:519\u001b[0m, in \u001b[0;36m_random_sample\u001b[0;34m(selected_seq_groups, random_samples)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run random sampling on a given samples.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;124;03m    seq_group has do_sample=False, tuple contains ([], [])\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;66;03m# Find the maximum best_of value of the prompt phase requests.\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m random_samples \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m sample_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    521\u001b[0m results: SampleResultType \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vllm_generate(test_messages*18, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421d7488-2a64-42b4-8ec0-441447683004",
   "metadata": {},
   "source": [
    "### fp8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd068c8-186b-431f-9067-ae82d15c507a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T11:15:41.261539Z",
     "iopub.status.busy": "2024-09-22T11:15:41.259827Z",
     "iopub.status.idle": "2024-09-22T11:24:26.358892Z",
     "shell.execute_reply": "2024-09-22T11:24:26.358399Z",
     "shell.execute_reply.started": "2024-09-22T11:15:41.261502Z"
    }
   },
   "source": [
    "Note: the \"FP8-dynamic\" version is much slower that the \"FP8\" version.\n",
    "- batch size 16: 61 tokens/sec vs 77 tokens/sec\n",
    "- batch size 32: 42 tokens/sec vs 62 tokens/sec\n",
    "- batch size 48: 03 tokens/sec vs 52 tokens/sec !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5650e783-f639-4c9d-9096-35a6678e91c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T11:39:32.759261Z",
     "iopub.status.busy": "2024-09-22T11:39:32.758586Z",
     "iopub.status.idle": "2024-09-22T11:48:07.880587Z",
     "shell.execute_reply": "2024-09-22T11:48:07.880145Z",
     "shell.execute_reply.started": "2024-09-22T11:39:32.759228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db6daf92370484daf11edee49ca36f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 13:39:33 llm_engine.py:223] Initializing an LLM engine (v0.6.1.post2) with config: model='neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8', speculative_config=None, tokenizer='neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=compressed-tensors, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc0dc720717411da9b7647bcc042579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd11eaca40342f188dbfb1bc83612cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09962e03bbae49af81f0bd548f54f7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/325 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d997f4197e5847dd9ec3438328611585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 09-22 13:39:35 utils.py:727] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "INFO 09-22 13:39:35 model_runner.py:997] Starting to load model neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8...\n",
      "INFO 09-22 13:39:36 weight_utils.py:242] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9163b8f1f63041598e319c582cb695bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d87778d0a544aaae84ede3e66dbbe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7089eeaf99ba47789d6f40347aaf2836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/62.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d27652eebd34392a219e3f6e7f1f9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 13:47:57 model_runner.py:1008] Loading model weights took 8.4889 GB\n",
      "INFO 09-22 13:47:58 gpu_executor.py:122] # GPU blocks: 6856, # CPU blocks: 2048\n",
      "INFO 09-22 13:47:58 model_runner.py:1311] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 09-22 13:47:58 model_runner.py:1315] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 09-22 13:48:07 model_runner.py:1430] Graph capturing finished in 9 secs.\n"
     ]
    }
   ],
   "source": [
    "llm = vllm_load(test_models[\"llama-3.1:fp8\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fdeba4d-443b-4537-9e83-0733c5ccfc3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T11:48:07.881768Z",
     "iopub.status.busy": "2024-09-22T11:48:07.881343Z",
     "iopub.status.idle": "2024-09-22T12:01:23.379397Z",
     "shell.execute_reply": "2024-09-22T12:01:23.378580Z",
     "shell.execute_reply.started": "2024-09-22T11:48:07.881758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vLLM performance test:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████████| 1/1 [00:06<00:00,  6.11s/it, est. speed input: 10.32 toks/s, output: 83.84 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: \"Le Crédit Mutuel est une banque coopérative française qui offre plusieurs avantages à ses membres et clients. Voici quelques-uns des principaux avantages :\\n\\n1. **Intérêts plus élevés sur les épargnes** : Le Crédit Mutuel propose des taux d'intérêt plus élevés sur les comptes d'épargne comparés aux banques traditionnelles.\\n2. **Frais de gestion réduits** : Les frais de gestion pour les comptes courants et les prêts sont souvent moins élevés chez le Crédit Mutuel que dans les banques conventionnelles.\\n3. **Prêts personnalisés** : Le Crédit Mutuel prend en compte la situation personnelle et financière de chaque client pour proposer des prêts adaptés à ses besoins.\\n4. **Soutien à l'entrepreneuriat** : Le Crédit Mutuel propose des solutions financières spécifiques pour les entrepreneurs et les PME, notamment des prêts et des services de financement.\\n5. **Services bancaires complets** : Le Crédit Mutuel propose une gamme complète de services bancaires, y compris les comptes courants, les prêts, les crédits immobiliers, les assurances, les placements et les services de gestion de patrimoine.\\n6. **Transparence et sécurité** : Le Crédit Mutuel est une banque coopérative, ce qui signifie que les décisions sont prises collectivement par les membres et que les informations sont transparentes.\\n7. **Services numériques avancés** : Le Crédit Mutuel propose des outils numériques pour gérer ses finances en ligne, tels que des applications mobiles et des sites web sécurisés.\\n8. **Accès à des services supplémentaires** : Les membres du Crédit Mutuel peuvent accéder à des services supplémentaires, comme des conseils financiers, des formations et des ateliers sur la gestion de l'argent et la maîtrise des finances.\\n9. **Participation à la vie associative** : Les membres du Crédit Mutuel peuvent participer à la vie associative et contribuer à la définition de la politique de la banque.\\n10. **Soutien à la communauté** : Le Crédit Mut\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████████| 1/1 [00:05<00:00,  5.93s/it, est. speed input: 10.62 toks/s, output: 86.31 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 1: 86.27 tokens/sec (1 x 86.27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 2/2 [00:06<00:00,  3.04s/it, est. speed input: 20.88 toks/s, output: 168.32 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 2: 168.27 tokens/sec (2 x 84.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 3/3 [00:06<00:00,  2.03s/it, est. speed input: 31.39 toks/s, output: 252.42 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 3: 252.33 tokens/sec (3 x 84.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 4/4 [00:06<00:00,  1.53s/it, est. speed input: 41.17 toks/s, output: 334.58 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 4: 334.44 tokens/sec (4 x 83.61)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 5/5 [00:06<00:00,  1.24s/it, est. speed input: 51.01 toks/s, output: 411.35 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 5: 411.19 tokens/sec (5 x 82.24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 6/6 [00:06<00:00,  1.03s/it, est. speed input: 61.37 toks/s, output: 497.41 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 6: 497.24 tokens/sec (6 x 82.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 7/7 [00:06<00:00,  1.12it/s, est. speed input: 71.09 toks/s, output: 575.11 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 7: 574.88 tokens/sec (7 x 82.13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 8/8 [00:06<00:00,  1.28it/s, est. speed input: 80.54 toks/s, output: 654.54 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 8: 654.25 tokens/sec (8 x 81.78)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 9/9 [00:06<00:00,  1.43it/s, est. speed input: 90.25 toks/s, output: 729.52 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 9: 729.21 tokens/sec (9 x 81.02)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 10/10 [00:06<00:00,  1.57it/s, est. speed input: 99.38 toks/s, output: 806.05 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 10: 805.72 tokens/sec (10 x 80.57)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 11/11 [00:06<00:00,  1.74it/s, est. speed input: 109.74 toks/s, output: 889.25 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 11: 888.85 tokens/sec (11 x 80.80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 12/12 [00:06<00:00,  1.88it/s, est. speed input: 118.63 toks/s, output: 964.09 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 12: 963.66 tokens/sec (12 x 80.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 13/13 [00:06<00:00,  2.03it/s, est. speed input: 127.69 toks/s, output: 1026.37 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 13: 1025.87 tokens/sec (13 x 78.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 14/14 [00:06<00:00,  2.14it/s, est. speed input: 134.68 toks/s, output: 1086.59 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 14: 1086.05 tokens/sec (14 x 77.57)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 15/15 [00:06<00:00,  2.29it/s, est. speed input: 144.63 toks/s, output: 1172.89 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 15: 1172.37 tokens/sec (15 x 78.16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 16/16 [00:06<00:00,  2.42it/s, est. speed input: 152.37 toks/s, output: 1232.30 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 16: 1231.70 tokens/sec (16 x 76.98)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 17/17 [00:06<00:00,  2.47it/s, est. speed input: 155.67 toks/s, output: 1264.67 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 17: 1264.05 tokens/sec (17 x 74.36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 18/18 [00:06<00:00,  2.61it/s, est. speed input: 164.44 toks/s, output: 1327.22 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 18: 1326.57 tokens/sec (18 x 73.70)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 19/19 [00:06<00:00,  2.74it/s, est. speed input: 173.17 toks/s, output: 1394.73 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 19: 1394.01 tokens/sec (19 x 73.37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 20/20 [00:07<00:00,  2.84it/s, est. speed input: 179.14 toks/s, output: 1443.90 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 20: 1443.12 tokens/sec (20 x 72.16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 21/21 [00:06<00:00,  3.02it/s, est. speed input: 190.27 toks/s, output: 1545.87 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 21: 1545.00 tokens/sec (21 x 73.57)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 22/22 [00:07<00:00,  3.13it/s, est. speed input: 197.52 toks/s, output: 1604.08 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 22: 1603.21 tokens/sec (22 x 72.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 23/23 [00:07<00:00,  3.26it/s, est. speed input: 205.49 toks/s, output: 1667.17 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 23: 1666.15 tokens/sec (23 x 72.44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 24/24 [00:07<00:00,  3.40it/s, est. speed input: 214.05 toks/s, output: 1732.91 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 24: 1731.86 tokens/sec (24 x 72.16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 25/25 [00:07<00:00,  3.23it/s, est. speed input: 203.68 toks/s, output: 1641.56 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 25: 1640.63 tokens/sec (25 x 65.63)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 26/26 [00:07<00:00,  3.36it/s, est. speed input: 212.02 toks/s, output: 1720.50 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 26: 1719.50 tokens/sec (26 x 66.13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 27/27 [00:07<00:00,  3.46it/s, est. speed input: 218.23 toks/s, output: 1758.78 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 27: 1757.78 tokens/sec (27 x 65.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 28/28 [00:07<00:00,  3.57it/s, est. speed input: 225.07 toks/s, output: 1820.45 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 28: 1819.32 tokens/sec (28 x 64.98)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 29/29 [00:07<00:00,  3.64it/s, est. speed input: 229.44 toks/s, output: 1856.89 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 29: 1855.89 tokens/sec (29 x 64.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 30/30 [00:08<00:00,  3.67it/s, est. speed input: 231.08 toks/s, output: 1874.22 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 30: 1873.13 tokens/sec (30 x 62.44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 31/31 [00:08<00:00,  3.80it/s, est. speed input: 239.93 toks/s, output: 1946.91 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 31: 1945.79 tokens/sec (31 x 62.77)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 32/32 [00:08<00:00,  3.88it/s, est. speed input: 244.64 toks/s, output: 1988.15 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 32: 1986.91 tokens/sec (32 x 62.09)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 33/33 [00:08<00:00,  3.89it/s, est. speed input: 244.79 toks/s, output: 1959.25 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 33: 1958.11 tokens/sec (33 x 59.34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 34/34 [00:08<00:00,  3.96it/s, est. speed input: 249.55 toks/s, output: 2020.37 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 34: 2019.27 tokens/sec (34 x 59.39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 35/35 [00:08<00:00,  4.08it/s, est. speed input: 257.34 toks/s, output: 2081.09 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 35: 2079.73 tokens/sec (35 x 59.42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 36/36 [00:08<00:00,  4.17it/s, est. speed input: 262.86 toks/s, output: 2136.26 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 36: 2134.90 tokens/sec (36 x 59.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 37/37 [00:08<00:00,  4.23it/s, est. speed input: 266.38 toks/s, output: 2150.39 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 37: 2149.06 tokens/sec (37 x 58.08)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 38/38 [00:08<00:00,  4.36it/s, est. speed input: 274.64 toks/s, output: 2227.99 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 38: 2226.55 tokens/sec (38 x 58.59)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 39/39 [00:08<00:00,  4.64it/s, est. speed input: 292.55 toks/s, output: 2370.01 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 39: 2368.33 tokens/sec (39 x 60.73)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 40/40 [00:08<00:00,  4.47it/s, est. speed input: 281.69 toks/s, output: 2281.73 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 40: 2280.26 tokens/sec (40 x 57.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 41/41 [00:08<00:00,  4.57it/s, est. speed input: 287.97 toks/s, output: 2330.75 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 41: 2329.16 tokens/sec (41 x 56.81)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 42/42 [00:09<00:00,  4.61it/s, est. speed input: 290.65 toks/s, output: 2353.57 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 42: 2351.93 tokens/sec (42 x 56.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 43/43 [00:09<00:00,  4.64it/s, est. speed input: 292.56 toks/s, output: 2369.20 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 43: 2367.68 tokens/sec (43 x 55.06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 44/44 [00:09<00:00,  4.75it/s, est. speed input: 299.25 toks/s, output: 2423.04 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 44: 2421.30 tokens/sec (44 x 55.03)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 45/45 [00:09<00:00,  4.75it/s, est. speed input: 299.00 toks/s, output: 2421.10 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 45: 2419.48 tokens/sec (45 x 53.77)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 46/46 [00:09<00:00,  4.84it/s, est. speed input: 305.23 toks/s, output: 2474.15 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 46: 2472.53 tokens/sec (46 x 53.75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 47/47 [00:09<00:00,  4.92it/s, est. speed input: 310.48 toks/s, output: 2512.15 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 47: 2510.48 tokens/sec (47 x 53.41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 48/48 [00:09<00:00,  4.90it/s, est. speed input: 309.00 toks/s, output: 2507.15 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 48: 2505.45 tokens/sec (48 x 52.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 49/49 [00:10<00:00,  4.81it/s, est. speed input: 303.06 toks/s, output: 2448.22 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 49: 2446.60 tokens/sec (49 x 49.93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 50/50 [00:10<00:00,  4.81it/s, est. speed input: 302.88 toks/s, output: 2459.86 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 50: 2458.17 tokens/sec (50 x 49.16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 51/51 [00:10<00:00,  4.89it/s, est. speed input: 308.39 toks/s, output: 2497.62 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 51: 2496.01 tokens/sec (51 x 48.94)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 52/52 [00:10<00:00,  5.09it/s, est. speed input: 320.59 toks/s, output: 2598.08 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 52: 2596.31 tokens/sec (52 x 49.93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 53/53 [00:10<00:00,  4.95it/s, est. speed input: 311.58 toks/s, output: 2519.97 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 53: 2518.22 tokens/sec (53 x 47.51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 54/54 [00:10<00:00,  5.08it/s, est. speed input: 319.88 toks/s, output: 2592.56 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 54: 2590.62 tokens/sec (54 x 47.97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 55/55 [00:10<00:00,  5.10it/s, est. speed input: 321.73 toks/s, output: 2603.96 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 55: 2602.18 tokens/sec (55 x 47.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 56/56 [00:28<00:00,  1.99it/s, est. speed input: 125.12 toks/s, output: 1013.03 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 56: 1012.78 tokens/sec (56 x 18.09)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 57/57 [00:29<00:00,  1.96it/s, est. speed input: 123.31 toks/s, output: 997.82 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 57: 997.55 tokens/sec (57 x 17.50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 58/58 [00:30<00:00,  1.90it/s, est. speed input: 119.90 toks/s, output: 971.78 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 58: 971.53 tokens/sec (58 x 16.75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 59/59 [00:31<00:00,  1.90it/s, est. speed input: 119.68 toks/s, output: 970.45 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 59: 970.21 tokens/sec (59 x 16.44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 60/60 [00:31<00:00,  1.90it/s, est. speed input: 119.84 toks/s, output: 972.38 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 60: 972.13 tokens/sec (60 x 16.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 61/61 [00:32<00:00,  1.91it/s, est. speed input: 120.05 toks/s, output: 974.06 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 61: 973.83 tokens/sec (61 x 15.96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 62/62 [00:32<00:00,  1.91it/s, est. speed input: 120.49 toks/s, output: 973.36 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 62: 973.11 tokens/sec (62 x 15.70)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 63/63 [00:32<00:00,  1.94it/s, est. speed input: 122.35 toks/s, output: 989.52 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 63: 989.27 tokens/sec (63 x 15.70)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 64/64 [00:33<00:00,  1.94it/s, est. speed input: 121.93 toks/s, output: 986.78 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 64: 986.53 tokens/sec (64 x 15.41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 65/65 [00:34<00:00,  1.91it/s, est. speed input: 120.07 toks/s, output: 972.32 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 65: 972.07 tokens/sec (65 x 14.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 66/66 [00:34<00:00,  1.92it/s, est. speed input: 120.88 toks/s, output: 978.95 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 66: 978.71 tokens/sec (66 x 14.83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:   0%|                     | 0/67 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvllm_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_messages\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m, in \u001b[0;36mvllm_generate\u001b[0;34m(messages, llm)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_size \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(messages) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     19\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# Record the start time\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# Record the end time\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Print the outputs.\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/utils.py:1036\u001b[0m, in \u001b[0;36mdeprecate_kwargs.<locals>.wrapper.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1029\u001b[0m             msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1031\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1032\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(msg),\n\u001b[1;32m   1033\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# The inner function takes up one level\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m         )\n\u001b[0;32m-> 1036\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/entrypoints/llm.py:348\u001b[0m, in \u001b[0;36mLLM.generate\u001b[0;34m(self, prompts, sampling_params, prompt_token_ids, use_tqdm, lora_request, prompt_adapter_request, guided_options_request)\u001b[0m\n\u001b[1;32m    339\u001b[0m     sampling_params \u001b[38;5;241m=\u001b[39m SamplingParams()\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_add_requests(\n\u001b[1;32m    342\u001b[0m     inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    343\u001b[0m     params\u001b[38;5;241m=\u001b[39msampling_params,\n\u001b[1;32m    344\u001b[0m     lora_request\u001b[38;5;241m=\u001b[39mlora_request,\n\u001b[1;32m    345\u001b[0m     prompt_adapter_request\u001b[38;5;241m=\u001b[39mprompt_adapter_request,\n\u001b[1;32m    346\u001b[0m     guided_options\u001b[38;5;241m=\u001b[39mguided_options_request)\n\u001b[0;32m--> 348\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMEngine\u001b[38;5;241m.\u001b[39mvalidate_outputs(outputs, RequestOutput)\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/entrypoints/llm.py:715\u001b[0m, in \u001b[0;36mLLM._run_engine\u001b[0;34m(self, use_tqdm)\u001b[0m\n\u001b[1;32m    713\u001b[0m total_out_toks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine\u001b[38;5;241m.\u001b[39mhas_unfinished_requests():\n\u001b[0;32m--> 715\u001b[0m     step_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m step_outputs:\n\u001b[1;32m    717\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mfinished:\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/engine/llm_engine.py:1223\u001b[0m, in \u001b[0;36mLLMEngine.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_async_output_proc:\n\u001b[1;32m   1220\u001b[0m     execute_model_req\u001b[38;5;241m.\u001b[39masync_callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_callbacks[\n\u001b[1;32m   1221\u001b[0m         virtual_engine]\n\u001b[0;32m-> 1223\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;66;03m# We need to do this here so that last step's sampled_token_ids can\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;66;03m# be passed to the next iteration for PP.\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler_config\u001b[38;5;241m.\u001b[39mis_multi_step:\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/executor/gpu_executor.py:130\u001b[0m, in \u001b[0;36mGPUExecutor.execute_model\u001b[0;34m(self, execute_model_req)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_model\u001b[39m(\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m, execute_model_req: ExecuteModelRequest\n\u001b[1;32m    129\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[List[Union[SamplerOutput, PoolerOutput]]]:\n\u001b[0;32m--> 130\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/worker/worker_base.py:327\u001b[0m, in \u001b[0;36mLocalOrDistributedWorkerBase.execute_model\u001b[0;34m(self, execute_model_req)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    323\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config\u001b[38;5;241m.\u001b[39mcollect_model_execute_time):\n\u001b[1;32m    324\u001b[0m         orig_model_execute_time \u001b[38;5;241m=\u001b[39m intermediate_tensors\u001b[38;5;241m.\u001b[39mtensors\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    325\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_execute_time\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 327\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkv_caches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mworker_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvirtual_engine\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintermediate_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintermediate_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m model_execute_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m get_pp_group()\u001b[38;5;241m.\u001b[39mis_last_rank:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# output is IntermediateTensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/worker/model_runner_base.py:112\u001b[0m, in \u001b[0;36mdump_input_when_exception.<locals>._inner.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    114\u001b[0m         timestamp \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/worker/model_runner.py:1589\u001b[0m, in \u001b[0;36mModelRunner.execute_model\u001b[0;34m(self, model_input, kv_caches, intermediate_tensors, num_steps)\u001b[0m\n\u001b[1;32m   1586\u001b[0m     model_input\u001b[38;5;241m.\u001b[39masync_callback()\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;66;03m# Sample the next token.\u001b[39;00m\n\u001b[0;32m-> 1589\u001b[0m output: SamplerOutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1591\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1592\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config\u001b[38;5;241m.\u001b[39mcollect_model_forward_time\n\u001b[1;32m   1595\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1596\u001b[0m     model_forward_end\u001b[38;5;241m.\u001b[39msynchronize()\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py:466\u001b[0m, in \u001b[0;36mLlamaForCausalLM.sample\u001b[0;34m(self, logits, sampling_metadata)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    463\u001b[0m     logits: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    464\u001b[0m     sampling_metadata: SamplingMetadata,\n\u001b[1;32m    465\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[SamplerOutput]:\n\u001b[0;32m--> 466\u001b[0m     next_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m next_tokens\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:278\u001b[0m, in \u001b[0;36mSampler.forward\u001b[0;34m(self, logits, sampling_metadata)\u001b[0m\n\u001b[1;32m    275\u001b[0m logprobs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog_softmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# Sample the next tokens.\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m maybe_deferred_sample_results, maybe_sampled_tokens_tensor \u001b[38;5;241m=\u001b[39m \u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_modify_greedy_probs_inplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_gpu_probs_tensor:\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;66;03m# Since we will defer sampler result Pythonization,\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# preserve GPU-side tensors in support of later\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# deferred pythonization of logprobs\u001b[39;00m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m maybe_sampled_tokens_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:968\u001b[0m, in \u001b[0;36m_sample\u001b[0;34m(probs, logprobs, sampling_metadata, sampling_tensors, include_gpu_probs_tensor, modify_greedy_probs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sample\u001b[39m(\n\u001b[1;32m    949\u001b[0m     probs: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    950\u001b[0m     logprobs: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    954\u001b[0m     modify_greedy_probs: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m    955\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SampleReturnType:\n\u001b[1;32m    956\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;124;03m        probs: (num_query_tokens_in_batch, num_vocab)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;124;03m        sampled_token_ids_tensor: A tensor of sampled token ids.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sample_with_torch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampling_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:855\u001b[0m, in \u001b[0;36m_sample_with_torch\u001b[0;34m(probs, logprobs, sampling_metadata, sampling_tensors, include_gpu_probs_tensor, modify_greedy_probs)\u001b[0m\n\u001b[1;32m    843\u001b[0m maybe_deferred_args \u001b[38;5;241m=\u001b[39m SampleResultArgsType(\n\u001b[1;32m    844\u001b[0m     sampling_metadata\u001b[38;5;241m=\u001b[39msampling_metadata,\n\u001b[1;32m    845\u001b[0m     sample_metadata\u001b[38;5;241m=\u001b[39msample_metadata,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    848\u001b[0m     beam_search_logprobs\u001b[38;5;241m=\u001b[39mbeam_search_logprobs,\n\u001b[1;32m    849\u001b[0m     sample_results_dict\u001b[38;5;241m=\u001b[39msample_results_dict)\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sampling_metadata\u001b[38;5;241m.\u001b[39mskip_sampler_cpu_output:\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# GPU<->CPU sync happens here.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# This also converts the sampler output to a Python object.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;66;03m# Return Pythonized sampler result & sampled token ids\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_pythonized_sample_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaybe_deferred_args\u001b[49m\u001b[43m)\u001b[49m, sampled_token_ids_tensor\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;66;03m# Defer sampler result Pythonization; return deferred\u001b[39;00m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Pythonization args & sampled token ids\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    861\u001b[0m         maybe_deferred_args,\n\u001b[1;32m    862\u001b[0m         sampled_token_ids_tensor,\n\u001b[1;32m    863\u001b[0m     )\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:720\u001b[0m, in \u001b[0;36mget_pythonized_sample_results\u001b[0;34m(sample_result_args)\u001b[0m\n\u001b[1;32m    718\u001b[0m     sample_results \u001b[38;5;241m=\u001b[39m _greedy_sample(seq_groups, greedy_samples)\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sampling_type \u001b[38;5;129;01min\u001b[39;00m (SamplingType\u001b[38;5;241m.\u001b[39mRANDOM, SamplingType\u001b[38;5;241m.\u001b[39mRANDOM_SEED):\n\u001b[0;32m--> 720\u001b[0m     sample_results \u001b[38;5;241m=\u001b[39m \u001b[43m_random_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmultinomial_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[43msampling_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sampling_type \u001b[38;5;241m==\u001b[39m SamplingType\u001b[38;5;241m.\u001b[39mBEAM:\n\u001b[1;32m    723\u001b[0m     sample_results \u001b[38;5;241m=\u001b[39m _beam_search_sample(seq_groups,\n\u001b[1;32m    724\u001b[0m                                          beam_search_logprobs)\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:519\u001b[0m, in \u001b[0;36m_random_sample\u001b[0;34m(selected_seq_groups, random_samples)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run random sampling on a given samples.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;124;03m    seq_group has do_sample=False, tuple contains ([], [])\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;66;03m# Find the maximum best_of value of the prompt phase requests.\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m random_samples \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m sample_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    521\u001b[0m results: SampleResultType \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vllm_generate(test_messages*16, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47267753-baff-4dc5-ae32-f421c5b1614a",
   "metadata": {},
   "source": [
    "### w8a8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a3def90-d426-413f-8dd5-08d10454a26f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T12:08:29.729799Z",
     "iopub.status.busy": "2024-09-22T12:08:29.728806Z",
     "iopub.status.idle": "2024-09-22T12:16:57.143620Z",
     "shell.execute_reply": "2024-09-22T12:16:57.143191Z",
     "shell.execute_reply.started": "2024-09-22T12:08:29.729765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46228e5837846cb901f16d194877e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.14k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 14:08:30 llm_engine.py:223] Initializing an LLM engine (v0.6.1.post2) with config: model='neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a8', speculative_config=None, tokenizer='neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a8', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=compressed-tensors, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a8, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f854165b57bf411daceee4d1dd065e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df49cd37bee436d89799ee2262c1a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f096cc73db41f89d2cbf0978d116d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/325 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ecd7d33a574b2b964fa1bafb4b326e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 09-22 14:08:32 utils.py:727] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "INFO 09-22 14:08:33 model_runner.py:997] Starting to load model neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a8...\n",
      "INFO 09-22 14:08:33 weight_utils.py:242] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e1d8cc8cce46949d1d4cac9406c5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bb6048a027476c92410f6ecd1e5965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed24cf2d54e401b97518f7a76ee0307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/43.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8d2aff09e841699de627de89f355c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 14:16:47 model_runner.py:1008] Loading model weights took 8.4939 GB\n",
      "INFO 09-22 14:16:48 gpu_executor.py:122] # GPU blocks: 6759, # CPU blocks: 2048\n",
      "INFO 09-22 14:16:48 model_runner.py:1311] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 09-22 14:16:48 model_runner.py:1315] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 09-22 14:16:57 model_runner.py:1430] Graph capturing finished in 9 secs.\n"
     ]
    }
   ],
   "source": [
    "llm = vllm_load(test_models[\"llama-3.1:w8a8\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cbfd8d3-8269-4646-b9c8-61d7d41e00ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T12:17:09.523309Z",
     "iopub.status.busy": "2024-09-22T12:17:09.522946Z",
     "iopub.status.idle": "2024-09-22T12:23:34.095871Z",
     "shell.execute_reply": "2024-09-22T12:23:34.095274Z",
     "shell.execute_reply.started": "2024-09-22T12:17:09.523262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vLLM performance test:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████| 1/1 [00:06<00:00,  6.90s/it, est. speed input: 6.09 toks/s, output: 74.24 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: \"Le Crédit Mutuel est une banque coopérative française qui offre plusieurs avantages à ses membres et clients. Voici quelques-uns des principaux avantages :\\n\\n1. **Intérêts plus faibles** : Le Crédit Mutuel propose des taux d'intérêt compétitifs pour les prêts, les comptes courants et les épargnes.\\n2. **Accès à des services bancaires complets** : Le Crédit Mutuel offre une gamme complète de services bancaires, y compris des prêts, des comptes courants, des épargnes, des cartes de crédit, des assurances et des investissements.\\n3. **Conseils personnalisés** : Les conseillers du Crédit Mutuel peuvent vous aider à gérer votre patrimoine, à élaborer un plan financier et à atteindre vos objectifs économiques.\\n4. **Transparence et sécurité** : Le Crédit Mutuel est une banque coopérative, ce qui signifie que les décisions sont prises collectivement par les membres et non par des actionnaires. Cela assure une transparence et une sécurité supplémentaires.\\n5. **Services en ligne performants** : Le Crédit Mutuel propose des outils en ligne permettant de gérer son compte, de consulter son historique de transactions et de réaliser des opérations bancaires en toute sécurité.\\n6. **Réseau de guichets et d'agences** : Le Crédit Mutuel dispose d'un réseau de guichets et d'agences réparties sur tout le territoire français, ce qui facilite l'accès aux services bancaires.\\n7. **Participation aux bénéfices** : Les membres du Crédit Mutuel participent aux bénéfices de la banque, ce qui peut entraîner des dividendes et des avantages supplémentaires.\\n8. **Soutien à l'économie locale** : Le Crédit Mutuel soutient l'économie locale en proposant des services bancaires adaptés aux besoins des entreprises et des particuliers locaux.\\n9. **Formation et sensibilisation financière** : Le Crédit Mutuel propose des formations et des ressources pour aider les personnes à mieux comprendre les questions financières et à prendre des décisions éclair\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████| 1/1 [00:06<00:00,  6.63s/it, est. speed input: 6.33 toks/s, output: 77.21 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 1: 77.18 tokens/sec (1 x 77.18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 2/2 [00:06<00:00,  3.39s/it, est. speed input: 12.53 toks/s, output: 149.72 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 2: 149.67 tokens/sec (2 x 74.84)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 3/3 [00:06<00:00,  2.27s/it, est. speed input: 18.83 toks/s, output: 221.19 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 3: 221.12 tokens/sec (3 x 73.71)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 4/4 [00:06<00:00,  1.70s/it, est. speed input: 24.69 toks/s, output: 277.91 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 4: 277.82 tokens/sec (4 x 69.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 5/5 [00:06<00:00,  1.38s/it, est. speed input: 30.48 toks/s, output: 360.57 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 5: 360.46 tokens/sec (5 x 72.09)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 6/6 [00:06<00:00,  1.16s/it, est. speed input: 36.45 toks/s, output: 442.11 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 6: 441.98 tokens/sec (6 x 73.66)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 7/7 [00:06<00:00,  1.00it/s, est. speed input: 42.40 toks/s, output: 494.18 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 7: 493.99 tokens/sec (7 x 70.57)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 8/8 [00:06<00:00,  1.14it/s, est. speed input: 48.02 toks/s, output: 580.86 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 8: 580.67 tokens/sec (8 x 72.58)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 9/9 [00:07<00:00,  1.27it/s, est. speed input: 53.51 toks/s, output: 649.17 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 9: 648.93 tokens/sec (9 x 72.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 10/10 [00:07<00:00,  1.42it/s, est. speed input: 59.71 toks/s, output: 715.61 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 10: 715.38 tokens/sec (10 x 71.54)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 11/11 [00:07<00:00,  1.55it/s, est. speed input: 65.46 toks/s, output: 785.15 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 11: 784.85 tokens/sec (11 x 71.35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 12/12 [00:07<00:00,  1.68it/s, est. speed input: 70.58 toks/s, output: 849.79 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 12: 849.42 tokens/sec (12 x 70.79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 13/13 [00:07<00:00,  1.81it/s, est. speed input: 75.96 toks/s, output: 914.40 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 13: 914.05 tokens/sec (13 x 70.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 14/14 [00:07<00:00,  1.90it/s, est. speed input: 79.95 toks/s, output: 952.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 14: 952.35 tokens/sec (14 x 68.02)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 15/15 [00:07<00:00,  2.05it/s, est. speed input: 86.48 toks/s, output: 1028.98 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 15: 1028.55 tokens/sec (15 x 68.57)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 16/16 [00:07<00:00,  2.17it/s, est. speed input: 91.31 toks/s, output: 1107.42 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 16: 1106.96 tokens/sec (16 x 69.18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 17/17 [00:07<00:00,  2.25it/s, est. speed input: 94.65 toks/s, output: 1123.09 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 17: 1122.60 tokens/sec (17 x 66.04)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 18/18 [00:07<00:00,  2.40it/s, est. speed input: 100.96 toks/s, output: 1194.59 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 18: 1194.09 tokens/sec (18 x 66.34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 19/19 [00:07<00:00,  2.51it/s, est. speed input: 105.88 toks/s, output: 1262.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 19: 1262.16 tokens/sec (19 x 66.43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 20/20 [00:07<00:00,  2.61it/s, est. speed input: 109.41 toks/s, output: 1300.31 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 20: 1299.72 tokens/sec (20 x 64.99)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 21/21 [00:07<00:00,  2.75it/s, est. speed input: 115.49 toks/s, output: 1377.52 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 21: 1376.91 tokens/sec (21 x 65.57)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 22/22 [00:07<00:00,  2.84it/s, est. speed input: 119.28 toks/s, output: 1429.30 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 22: 1428.64 tokens/sec (22 x 64.94)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 23/23 [00:07<00:00,  2.95it/s, est. speed input: 124.36 toks/s, output: 1456.42 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 23: 1455.72 tokens/sec (23 x 63.29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 24/24 [00:07<00:00,  3.09it/s, est. speed input: 129.65 toks/s, output: 1500.97 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 24: 1500.26 tokens/sec (24 x 62.51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 25/25 [00:07<00:00,  3.20it/s, est. speed input: 134.22 toks/s, output: 1593.73 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 25: 1592.90 tokens/sec (25 x 63.72)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 26/26 [00:07<00:00,  3.26it/s, est. speed input: 137.04 toks/s, output: 1645.39 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 26: 1644.59 tokens/sec (26 x 63.25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 27/27 [00:07<00:00,  3.42it/s, est. speed input: 143.74 toks/s, output: 1724.50 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 27: 1723.58 tokens/sec (27 x 63.84)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 28/28 [00:07<00:00,  3.52it/s, est. speed input: 147.78 toks/s, output: 1722.77 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 28: 1721.85 tokens/sec (28 x 61.49)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 29/29 [00:18<00:00,  1.54it/s, est. speed input: 64.72 toks/s, output: 759.85 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 29: 759.69 tokens/sec (29 x 26.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 30/30 [00:31<00:00,  1.06s/it, est. speed input: 39.75 toks/s, output: 467.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 30: 467.67 tokens/sec (30 x 15.59)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 31/31 [00:46<00:00,  1.49s/it, est. speed input: 28.29 toks/s, output: 337.61 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 31: 337.58 tokens/sec (31 x 10.89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 32/32 [00:59<00:00,  1.87s/it, est. speed input: 22.40 toks/s, output: 269.94 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 32: 269.92 tokens/sec (32 x 8.44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:   0%|                     | 0/33 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvllm_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_messages\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m, in \u001b[0;36mvllm_generate\u001b[0;34m(messages, llm)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_size \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(messages) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     19\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# Record the start time\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# Record the end time\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Print the outputs.\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/utils.py:1036\u001b[0m, in \u001b[0;36mdeprecate_kwargs.<locals>.wrapper.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1029\u001b[0m             msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1031\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1032\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(msg),\n\u001b[1;32m   1033\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# The inner function takes up one level\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m         )\n\u001b[0;32m-> 1036\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/entrypoints/llm.py:348\u001b[0m, in \u001b[0;36mLLM.generate\u001b[0;34m(self, prompts, sampling_params, prompt_token_ids, use_tqdm, lora_request, prompt_adapter_request, guided_options_request)\u001b[0m\n\u001b[1;32m    339\u001b[0m     sampling_params \u001b[38;5;241m=\u001b[39m SamplingParams()\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_add_requests(\n\u001b[1;32m    342\u001b[0m     inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    343\u001b[0m     params\u001b[38;5;241m=\u001b[39msampling_params,\n\u001b[1;32m    344\u001b[0m     lora_request\u001b[38;5;241m=\u001b[39mlora_request,\n\u001b[1;32m    345\u001b[0m     prompt_adapter_request\u001b[38;5;241m=\u001b[39mprompt_adapter_request,\n\u001b[1;32m    346\u001b[0m     guided_options\u001b[38;5;241m=\u001b[39mguided_options_request)\n\u001b[0;32m--> 348\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMEngine\u001b[38;5;241m.\u001b[39mvalidate_outputs(outputs, RequestOutput)\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/entrypoints/llm.py:715\u001b[0m, in \u001b[0;36mLLM._run_engine\u001b[0;34m(self, use_tqdm)\u001b[0m\n\u001b[1;32m    713\u001b[0m total_out_toks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine\u001b[38;5;241m.\u001b[39mhas_unfinished_requests():\n\u001b[0;32m--> 715\u001b[0m     step_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m step_outputs:\n\u001b[1;32m    717\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mfinished:\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/engine/llm_engine.py:1223\u001b[0m, in \u001b[0;36mLLMEngine.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_async_output_proc:\n\u001b[1;32m   1220\u001b[0m     execute_model_req\u001b[38;5;241m.\u001b[39masync_callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_callbacks[\n\u001b[1;32m   1221\u001b[0m         virtual_engine]\n\u001b[0;32m-> 1223\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;66;03m# We need to do this here so that last step's sampled_token_ids can\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;66;03m# be passed to the next iteration for PP.\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler_config\u001b[38;5;241m.\u001b[39mis_multi_step:\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/executor/gpu_executor.py:130\u001b[0m, in \u001b[0;36mGPUExecutor.execute_model\u001b[0;34m(self, execute_model_req)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_model\u001b[39m(\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m, execute_model_req: ExecuteModelRequest\n\u001b[1;32m    129\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[List[Union[SamplerOutput, PoolerOutput]]]:\n\u001b[0;32m--> 130\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/worker/worker_base.py:327\u001b[0m, in \u001b[0;36mLocalOrDistributedWorkerBase.execute_model\u001b[0;34m(self, execute_model_req)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    323\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config\u001b[38;5;241m.\u001b[39mcollect_model_execute_time):\n\u001b[1;32m    324\u001b[0m         orig_model_execute_time \u001b[38;5;241m=\u001b[39m intermediate_tensors\u001b[38;5;241m.\u001b[39mtensors\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    325\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_execute_time\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 327\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkv_caches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mworker_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvirtual_engine\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintermediate_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintermediate_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m model_execute_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m get_pp_group()\u001b[38;5;241m.\u001b[39mis_last_rank:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# output is IntermediateTensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/worker/model_runner_base.py:112\u001b[0m, in \u001b[0;36mdump_input_when_exception.<locals>._inner.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    114\u001b[0m         timestamp \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/worker/model_runner.py:1589\u001b[0m, in \u001b[0;36mModelRunner.execute_model\u001b[0;34m(self, model_input, kv_caches, intermediate_tensors, num_steps)\u001b[0m\n\u001b[1;32m   1586\u001b[0m     model_input\u001b[38;5;241m.\u001b[39masync_callback()\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;66;03m# Sample the next token.\u001b[39;00m\n\u001b[0;32m-> 1589\u001b[0m output: SamplerOutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1591\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1592\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config\u001b[38;5;241m.\u001b[39mcollect_model_forward_time\n\u001b[1;32m   1595\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1596\u001b[0m     model_forward_end\u001b[38;5;241m.\u001b[39msynchronize()\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py:466\u001b[0m, in \u001b[0;36mLlamaForCausalLM.sample\u001b[0;34m(self, logits, sampling_metadata)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    463\u001b[0m     logits: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    464\u001b[0m     sampling_metadata: SamplingMetadata,\n\u001b[1;32m    465\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[SamplerOutput]:\n\u001b[0;32m--> 466\u001b[0m     next_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m next_tokens\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:278\u001b[0m, in \u001b[0;36mSampler.forward\u001b[0;34m(self, logits, sampling_metadata)\u001b[0m\n\u001b[1;32m    275\u001b[0m logprobs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog_softmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# Sample the next tokens.\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m maybe_deferred_sample_results, maybe_sampled_tokens_tensor \u001b[38;5;241m=\u001b[39m \u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_modify_greedy_probs_inplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_gpu_probs_tensor:\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;66;03m# Since we will defer sampler result Pythonization,\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# preserve GPU-side tensors in support of later\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# deferred pythonization of logprobs\u001b[39;00m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m maybe_sampled_tokens_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:968\u001b[0m, in \u001b[0;36m_sample\u001b[0;34m(probs, logprobs, sampling_metadata, sampling_tensors, include_gpu_probs_tensor, modify_greedy_probs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sample\u001b[39m(\n\u001b[1;32m    949\u001b[0m     probs: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    950\u001b[0m     logprobs: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    954\u001b[0m     modify_greedy_probs: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m    955\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SampleReturnType:\n\u001b[1;32m    956\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;124;03m        probs: (num_query_tokens_in_batch, num_vocab)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;124;03m        sampled_token_ids_tensor: A tensor of sampled token ids.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sample_with_torch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampling_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:855\u001b[0m, in \u001b[0;36m_sample_with_torch\u001b[0;34m(probs, logprobs, sampling_metadata, sampling_tensors, include_gpu_probs_tensor, modify_greedy_probs)\u001b[0m\n\u001b[1;32m    843\u001b[0m maybe_deferred_args \u001b[38;5;241m=\u001b[39m SampleResultArgsType(\n\u001b[1;32m    844\u001b[0m     sampling_metadata\u001b[38;5;241m=\u001b[39msampling_metadata,\n\u001b[1;32m    845\u001b[0m     sample_metadata\u001b[38;5;241m=\u001b[39msample_metadata,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    848\u001b[0m     beam_search_logprobs\u001b[38;5;241m=\u001b[39mbeam_search_logprobs,\n\u001b[1;32m    849\u001b[0m     sample_results_dict\u001b[38;5;241m=\u001b[39msample_results_dict)\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sampling_metadata\u001b[38;5;241m.\u001b[39mskip_sampler_cpu_output:\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# GPU<->CPU sync happens here.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# This also converts the sampler output to a Python object.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;66;03m# Return Pythonized sampler result & sampled token ids\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_pythonized_sample_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaybe_deferred_args\u001b[49m\u001b[43m)\u001b[49m, sampled_token_ids_tensor\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;66;03m# Defer sampler result Pythonization; return deferred\u001b[39;00m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Pythonization args & sampled token ids\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    861\u001b[0m         maybe_deferred_args,\n\u001b[1;32m    862\u001b[0m         sampled_token_ids_tensor,\n\u001b[1;32m    863\u001b[0m     )\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:720\u001b[0m, in \u001b[0;36mget_pythonized_sample_results\u001b[0;34m(sample_result_args)\u001b[0m\n\u001b[1;32m    718\u001b[0m     sample_results \u001b[38;5;241m=\u001b[39m _greedy_sample(seq_groups, greedy_samples)\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sampling_type \u001b[38;5;129;01min\u001b[39;00m (SamplingType\u001b[38;5;241m.\u001b[39mRANDOM, SamplingType\u001b[38;5;241m.\u001b[39mRANDOM_SEED):\n\u001b[0;32m--> 720\u001b[0m     sample_results \u001b[38;5;241m=\u001b[39m \u001b[43m_random_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmultinomial_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[43msampling_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sampling_type \u001b[38;5;241m==\u001b[39m SamplingType\u001b[38;5;241m.\u001b[39mBEAM:\n\u001b[1;32m    723\u001b[0m     sample_results \u001b[38;5;241m=\u001b[39m _beam_search_sample(seq_groups,\n\u001b[1;32m    724\u001b[0m                                          beam_search_logprobs)\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:519\u001b[0m, in \u001b[0;36m_random_sample\u001b[0;34m(selected_seq_groups, random_samples)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run random sampling on a given samples.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;124;03m    seq_group has do_sample=False, tuple contains ([], [])\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;66;03m# Find the maximum best_of value of the prompt phase requests.\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m random_samples \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m sample_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    521\u001b[0m results: SampleResultType \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vllm_generate(test_messages*18, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d79accf-d5f8-44e9-9338-2434e8c5fa56",
   "metadata": {},
   "source": [
    "### w4a16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "221d45d8-315e-42cf-8adb-69959c7dc12e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T12:25:07.253635Z",
     "iopub.status.busy": "2024-09-22T12:25:07.252675Z",
     "iopub.status.idle": "2024-09-22T12:30:40.390307Z",
     "shell.execute_reply": "2024-09-22T12:30:40.389909Z",
     "shell.execute_reply.started": "2024-09-22T12:25:07.253604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a9ea6700b146bc854b3be1339d3f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.26k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 14:25:08 gptq_marlin.py:108] The model is convertible to gptq_marlin during runtime. Using gptq_marlin kernel.\n",
      "INFO 09-22 14:25:08 llm_engine.py:223] Initializing an LLM engine (v0.6.1.post2) with config: model='neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w4a16', speculative_config=None, tokenizer='neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w4a16', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=gptq_marlin, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w4a16, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b28b7fbab294772ba0aeff26beb8fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a58069105c64b4b81826f55148b6bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75751a767bfb420c9298192a76c2cc15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 09-22 14:25:10 utils.py:727] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "INFO 09-22 14:25:10 model_runner.py:997] Starting to load model neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w4a16...\n",
      "INFO 09-22 14:25:11 weight_utils.py:242] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb0e8c4276f489eb68caec8d5440453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 14:30:25 weight_utils.py:287] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40dad918e004484adea7b1e227fca09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 14:30:26 model_runner.py:1008] Loading model weights took 5.3812 GB\n",
      "INFO 09-22 14:30:28 gpu_executor.py:122] # GPU blocks: 8325, # CPU blocks: 2048\n",
      "INFO 09-22 14:30:30 model_runner.py:1311] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 09-22 14:30:30 model_runner.py:1315] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 09-22 14:30:40 model_runner.py:1430] Graph capturing finished in 10 secs.\n"
     ]
    }
   ],
   "source": [
    "llm = vllm_load(test_models[\"llama-3.1:w4a16\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10f3ba5a-1ff7-4260-ad56-2f2d90edb218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T12:30:45.862281Z",
     "iopub.status.busy": "2024-09-22T12:30:45.861790Z",
     "iopub.status.idle": "2024-09-22T12:39:33.032810Z",
     "shell.execute_reply": "2024-09-22T12:39:33.032392Z",
     "shell.execute_reply.started": "2024-09-22T12:30:45.862253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vLLM performance test:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████████| 1/1 [00:04<00:00,  4.38s/it, est. speed input: 9.58 toks/s, output: 116.78 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: \"Le Crédit Mutuel est une banque mutuelle française qui offre divers avantages à ses clients. Voici quelques-uns des principaux avantages :\\n\\n1. **Intérêts sur les comptes courants** : Le Crédit Mutuel offre des intérêts sur les comptes courants, ce qui permet aux clients de gagner de l'argent sans avoir à investir leurs fonds.\\n2. **Prêt à usage** : Le Crédit Mutuel propose des prêts à usage avec des taux d'intérêt compétitifs, ce qui peut aider les clients à financer leurs besoins ou leurs projets.\\n3. **Assurance de prêt** : Le Crédit Mutuel offre une assurance de prêt qui couvre les risques de défaut de remboursement, ce qui donne aux emprunteurs une sécurité supplémentaire.\\n4. **Services bancaires complets** : Le Crédit Mutuel propose une gamme complète de services bancaires, y compris des cartes de crédit, des chèques, des virements et des paiements en ligne.\\n5. **Sécurité et protection** : Le Crédit Mutuel met en place des mesures de sécurité pour protéger les comptes et les données de ses clients contre les cyberattentats et les autres menaces.\\n6. **Conseils financiers** : Le Crédit Mutuel propose des conseils financiers et des recommandations pour aider ses clients à gérer leur argent et à atteindre leurs objectifs financiers.\\n7. **Réseau de distributeurs** : Le Crédit Mutuel dispose d'un réseau de distributeurs dans tout le pays, ce qui permet aux clients de retirer de l'argent ou de faire des dépôts facilement.\\n8. **Application mobile** : Le Crédit Mutuel propose une application mobile qui permet aux clients de gérer leurs comptes, de vérifier leurs soldes et de réaliser des opérations bancaires en ligne.\\n9. **Participation aux bénéfices** : En tant que banque mutuelle, le Crédit Mutuel redistribue une partie de ses bénéfices aux associés, ce qui peut être considéré comme un avantage pour les clients.\\n10. **Système de récompenses** : Le Crédit Mutuel propose un système de ré\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 1/1 [00:04<00:00,  4.08s/it, est. speed input: 10.30 toks/s, output: 125.62 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 1: 125.55 tokens/sec (1 x 125.55)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 2/2 [00:04<00:00,  2.12s/it, est. speed input: 20.02 toks/s, output: 241.18 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 2: 241.06 tokens/sec (2 x 120.53)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 3/3 [00:04<00:00,  1.40s/it, est. speed input: 30.41 toks/s, output: 355.68 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 3: 355.46 tokens/sec (3 x 118.49)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 4/4 [00:04<00:00,  1.06s/it, est. speed input: 39.45 toks/s, output: 478.56 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 4: 478.33 tokens/sec (4 x 119.58)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 5/5 [00:04<00:00,  1.16it/s, est. speed input: 48.76 toks/s, output: 570.07 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 5: 569.82 tokens/sec (5 x 113.96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 6/6 [00:04<00:00,  1.39it/s, est. speed input: 58.42 toks/s, output: 697.80 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 6: 697.43 tokens/sec (6 x 116.24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 7/7 [00:04<00:00,  1.59it/s, est. speed input: 67.28 toks/s, output: 787.57 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 7: 787.10 tokens/sec (7 x 112.44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 8/8 [00:04<00:00,  1.80it/s, est. speed input: 75.68 toks/s, output: 881.61 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 8: 881.11 tokens/sec (8 x 110.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 9/9 [00:04<00:00,  2.00it/s, est. speed input: 84.02 toks/s, output: 988.23 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 9: 987.65 tokens/sec (9 x 109.74)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 10/10 [00:04<00:00,  2.20it/s, est. speed input: 92.81 toks/s, output: 1067.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 10: 1066.43 tokens/sec (10 x 106.64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 11/11 [00:04<00:00,  2.39it/s, est. speed input: 100.90 toks/s, output: 1190.30 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 11: 1189.65 tokens/sec (11 x 108.15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 12/12 [00:04<00:00,  2.60it/s, est. speed input: 109.12 toks/s, output: 1288.86 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 12: 1288.05 tokens/sec (12 x 107.34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 13/13 [00:04<00:00,  2.78it/s, est. speed input: 116.89 toks/s, output: 1381.02 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 13: 1380.25 tokens/sec (13 x 106.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 14/14 [00:04<00:00,  2.91it/s, est. speed input: 122.61 toks/s, output: 1435.34 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 14: 1434.50 tokens/sec (14 x 102.46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 15/15 [00:04<00:00,  3.15it/s, est. speed input: 132.66 toks/s, output: 1549.33 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 15: 1548.31 tokens/sec (15 x 103.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 16/16 [00:04<00:00,  3.34it/s, est. speed input: 140.13 toks/s, output: 1636.07 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 16: 1634.87 tokens/sec (16 x 102.18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 17/17 [00:05<00:00,  3.16it/s, est. speed input: 132.65 toks/s, output: 1581.27 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 17: 1580.32 tokens/sec (17 x 92.96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 18/18 [00:05<00:00,  3.29it/s, est. speed input: 138.55 toks/s, output: 1630.24 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 18: 1629.18 tokens/sec (18 x 90.51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 19/19 [00:05<00:00,  3.50it/s, est. speed input: 147.55 toks/s, output: 1711.78 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 19: 1710.76 tokens/sec (19 x 90.04)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 20/20 [00:05<00:00,  3.70it/s, est. speed input: 155.47 toks/s, output: 1786.38 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 20: 1785.25 tokens/sec (20 x 89.26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 21/21 [00:05<00:00,  3.77it/s, est. speed input: 158.44 toks/s, output: 1844.72 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 21: 1843.56 tokens/sec (21 x 87.79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 22/22 [00:05<00:00,  3.96it/s, est. speed input: 166.44 toks/s, output: 1955.59 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 22: 1954.32 tokens/sec (22 x 88.83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 23/23 [00:05<00:00,  4.12it/s, est. speed input: 173.21 toks/s, output: 2013.39 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 23: 2011.92 tokens/sec (23 x 87.47)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 24/24 [00:05<00:00,  4.24it/s, est. speed input: 178.23 toks/s, output: 2090.27 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 24: 2088.91 tokens/sec (24 x 87.04)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 25/25 [00:05<00:00,  4.43it/s, est. speed input: 186.27 toks/s, output: 2175.76 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 25: 2174.08 tokens/sec (25 x 86.96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 26/26 [00:05<00:00,  4.47it/s, est. speed input: 188.00 toks/s, output: 2199.89 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 26: 2198.47 tokens/sec (26 x 84.56)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 27/27 [00:05<00:00,  4.69it/s, est. speed input: 197.45 toks/s, output: 2314.77 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 27: 2313.17 tokens/sec (27 x 85.67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 28/28 [00:05<00:00,  4.84it/s, est. speed input: 203.44 toks/s, output: 2359.25 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 28: 2357.53 tokens/sec (28 x 84.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 29/29 [00:05<00:00,  4.91it/s, est. speed input: 206.42 toks/s, output: 2453.69 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 29: 2452.02 tokens/sec (29 x 84.55)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 30/30 [00:06<00:00,  4.96it/s, est. speed input: 208.42 toks/s, output: 2441.66 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 30: 2439.96 tokens/sec (30 x 81.33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 31/31 [00:05<00:00,  5.17it/s, est. speed input: 217.64 toks/s, output: 2538.39 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 31: 2536.60 tokens/sec (31 x 81.83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 32/32 [00:06<00:00,  5.30it/s, est. speed input: 222.50 toks/s, output: 2605.98 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 32: 2604.17 tokens/sec (32 x 81.38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 33/33 [00:06<00:00,  5.14it/s, est. speed input: 215.97 toks/s, output: 2520.17 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 33: 2518.36 tokens/sec (33 x 76.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 34/34 [00:06<00:00,  5.15it/s, est. speed input: 216.40 toks/s, output: 2504.99 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 34: 2503.17 tokens/sec (34 x 73.62)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 35/35 [00:06<00:00,  5.24it/s, est. speed input: 220.19 toks/s, output: 2595.18 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 35: 2593.18 tokens/sec (35 x 74.09)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 36/36 [00:06<00:00,  5.36it/s, est. speed input: 225.03 toks/s, output: 2650.47 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 36: 2648.47 tokens/sec (36 x 73.57)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 37/37 [00:06<00:00,  5.45it/s, est. speed input: 229.04 toks/s, output: 2696.51 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 37: 2694.60 tokens/sec (37 x 72.83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 38/38 [00:06<00:00,  5.50it/s, est. speed input: 231.22 toks/s, output: 2670.48 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 38: 2668.55 tokens/sec (38 x 70.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 39/39 [00:06<00:00,  5.69it/s, est. speed input: 239.27 toks/s, output: 2815.79 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 39: 2813.51 tokens/sec (39 x 72.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 40/40 [00:06<00:00,  5.84it/s, est. speed input: 245.40 toks/s, output: 2855.39 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 40: 2848.50 tokens/sec (40 x 71.21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 41/41 [00:07<00:00,  5.80it/s, est. speed input: 243.61 toks/s, output: 2846.18 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 41: 2843.88 tokens/sec (41 x 69.36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 42/42 [00:07<00:00,  5.96it/s, est. speed input: 250.50 toks/s, output: 2936.79 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 42: 2934.41 tokens/sec (42 x 69.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 43/43 [00:07<00:00,  6.09it/s, est. speed input: 255.91 toks/s, output: 2955.13 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 43: 2952.75 tokens/sec (43 x 68.67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 44/44 [00:07<00:00,  6.00it/s, est. speed input: 251.98 toks/s, output: 2956.01 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 44: 2953.65 tokens/sec (44 x 67.13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 45/45 [00:07<00:00,  6.20it/s, est. speed input: 260.36 toks/s, output: 3044.16 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 45: 3041.90 tokens/sec (45 x 67.60)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 46/46 [00:07<00:00,  6.26it/s, est. speed input: 263.08 toks/s, output: 3097.65 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 46: 3095.31 tokens/sec (46 x 67.29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 47/47 [00:07<00:00,  6.23it/s, est. speed input: 261.82 toks/s, output: 3090.93 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 47: 3036.79 tokens/sec (47 x 64.61)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 48/48 [00:07<00:00,  6.43it/s, est. speed input: 270.23 toks/s, output: 3176.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 48: 3173.57 tokens/sec (48 x 66.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 49/49 [00:08<00:00,  5.85it/s, est. speed input: 245.66 toks/s, output: 2914.78 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 49: 2912.62 tokens/sec (49 x 59.44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 50/50 [00:08<00:00,  5.91it/s, est. speed input: 248.53 toks/s, output: 2905.07 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 50: 2903.08 tokens/sec (50 x 58.06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 51/51 [00:09<00:00,  5.66it/s, est. speed input: 238.12 toks/s, output: 2783.81 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 51: 2781.90 tokens/sec (51 x 54.55)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 52/52 [00:09<00:00,  5.62it/s, est. speed input: 235.93 toks/s, output: 2762.60 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 52: 2760.68 tokens/sec (52 x 53.09)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 53/53 [00:09<00:00,  5.71it/s, est. speed input: 239.64 toks/s, output: 2830.30 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 53: 2828.41 tokens/sec (53 x 53.37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 54/54 [00:09<00:00,  5.73it/s, est. speed input: 240.64 toks/s, output: 2820.32 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 54: 2818.25 tokens/sec (54 x 52.19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 55/55 [00:09<00:00,  5.77it/s, est. speed input: 242.54 toks/s, output: 2883.49 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 55: 2881.63 tokens/sec (55 x 52.39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 56/56 [00:09<00:00,  5.78it/s, est. speed input: 242.64 toks/s, output: 2857.54 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 56: 2855.51 tokens/sec (56 x 50.99)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 57/57 [00:09<00:00,  5.80it/s, est. speed input: 243.43 toks/s, output: 2879.73 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 57: 2877.61 tokens/sec (57 x 50.48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 58/58 [00:09<00:00,  5.91it/s, est. speed input: 248.43 toks/s, output: 2923.29 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 58: 2921.28 tokens/sec (58 x 50.37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 59/59 [00:09<00:00,  5.93it/s, est. speed input: 249.22 toks/s, output: 2939.09 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 59: 2937.12 tokens/sec (59 x 49.78)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 60/60 [00:09<00:00,  6.09it/s, est. speed input: 255.81 toks/s, output: 2973.72 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 60: 2971.65 tokens/sec (60 x 49.53)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 61/61 [00:10<00:00,  5.99it/s, est. speed input: 251.65 toks/s, output: 2963.72 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 61: 2961.58 tokens/sec (61 x 48.55)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 62/62 [00:09<00:00,  6.22it/s, est. speed input: 261.29 toks/s, output: 3035.77 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 62: 3033.71 tokens/sec (62 x 48.93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 63/63 [00:10<00:00,  6.29it/s, est. speed input: 264.39 toks/s, output: 3088.26 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 63: 3085.80 tokens/sec (63 x 48.98)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 64/64 [00:10<00:00,  6.22it/s, est. speed input: 261.25 toks/s, output: 3032.34 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 64: 3030.35 tokens/sec (64 x 47.35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 65/65 [00:11<00:00,  5.62it/s, est. speed input: 236.04 toks/s, output: 2794.32 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 65: 2792.49 tokens/sec (65 x 42.96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 66/66 [00:11<00:00,  5.80it/s, est. speed input: 243.59 toks/s, output: 2826.58 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 66: 2824.80 tokens/sec (66 x 42.80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 67/67 [00:11<00:00,  5.71it/s, est. speed input: 239.81 toks/s, output: 2794.38 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 67: 2792.58 tokens/sec (67 x 41.68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 68/68 [00:11<00:00,  5.79it/s, est. speed input: 243.15 toks/s, output: 2831.61 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 68: 2829.74 tokens/sec (68 x 41.61)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 69/69 [00:11<00:00,  5.84it/s, est. speed input: 245.27 toks/s, output: 2880.51 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 69: 2878.64 tokens/sec (69 x 41.72)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 70/70 [00:11<00:00,  5.84it/s, est. speed input: 245.45 toks/s, output: 2876.64 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 70: 2874.84 tokens/sec (70 x 41.07)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 71/71 [00:11<00:00,  5.99it/s, est. speed input: 251.64 toks/s, output: 2927.52 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 71: 2925.52 tokens/sec (71 x 41.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 72/72 [00:12<00:00,  5.91it/s, est. speed input: 248.35 toks/s, output: 2909.87 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 72: 2907.97 tokens/sec (72 x 40.39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vllm_generate(test_messages*18, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075148e5-22ac-49c9-83ed-223a433d4679",
   "metadata": {},
   "source": [
    "## SGLang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ed22b-8f5b-4730-82d5-57e603dadb64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T12:41:48.206954Z",
     "iopub.status.busy": "2024-09-22T12:41:48.206371Z",
     "iopub.status.idle": "2024-09-22T12:41:48.209325Z",
     "shell.execute_reply": "2024-09-22T12:41:48.208953Z",
     "shell.execute_reply.started": "2024-09-22T12:41:48.206935Z"
    }
   },
   "source": [
    "### fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99bbbb7e-973a-4217-9b5a-2c7b26ccfe07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T12:43:23.629150Z",
     "iopub.status.busy": "2024-09-22T12:43:23.628712Z",
     "iopub.status.idle": "2024-09-22T12:44:29.277842Z",
     "shell.execute_reply": "2024-09-22T12:44:29.276916Z",
     "shell.execute_reply.started": "2024-09-22T12:43:23.629124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 14:43:27 weight_utils.py:242] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb44e40f27454633a8e4ac836dfeacbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runtime = sglang_load(test_models[\"llama-3.1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc24e481-a906-4638-bdaa-4f0c605298b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T12:44:44.457413Z",
     "iopub.status.busy": "2024-09-22T12:44:44.457164Z",
     "iopub.status.idle": "2024-09-22T12:50:49.492084Z",
     "shell.execute_reply": "2024-09-22T12:50:49.491696Z",
     "shell.execute_reply.started": "2024-09-22T12:44:44.457388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGLang performance test:\n",
      "Generated text: \"Le Crédit Mutuel est une banque coopérative française qui offre divers avantages à ses membres, notamment :\\n\\n1. **Intérêts plus élevés sur les épargnes** : Les membres du Crédit Mutuel bénéficient souvent de taux d'intérêt plus élevés que ceux proposés par les banques traditionnelles sur leurs comptes d'épargne.\\n2. **Prêts à des conditions favorables** : Les membres peuvent obtenir des prêts à des taux d'intérêt attractifs et avec des conditions de remboursement flexibles.\\n3. **Sécurité et stabilité** : En tant que banque coopérative, le Crédit Mutuel est contrôlée par ses membres, ce qui garantit une gestion responsable et durable de l'argent.\\n4. **Services personnalisés** : Les conseillers du Crédit Mutuel prennent le temps de comprendre les besoins de chaque membre pour offrir des solutions adaptées à leur situation financière.\\n5. **Économies sur les frais** : Les membres du Crédit Mutuel peuvent bénéficier de réductions sur les frais bancaires, tels que les frais de gestion de compte ou les frais de retrait d'espèces.\\n6. **Accès à des produits financiers diversifiés** : Le Crédit Mutuel propose une gamme complète de produits financiers, notamment des comptes courants, des comptes d'épargne, des prêts immobiliers, des assurances, etc.\\n7. **Transparence et responsabilité** : En tant que banque coopérative, le Crédit Mutuel est transparent dans ses pratiques et ses décisions, et les membres ont la possibilité de participer à la prise de décision au travers de l'assemblée générale annuelle.\\n8. **Soutien à l'économie locale** : Le Crédit Mutuel soutient les entreprises locales et les projets de développement économique dans les régions où il est implanté.\\n9. **Protection contre les risques** : Le Crédit Mutuel propose des produits d'assurance pour protéger les membres contre les risques tels que la perte d'emploi, la maladie, l'accident, etc.\\n10. **Ré\"\n",
      "- batch size 1: 54.77 tokens/sec (1 x 54.77)\n",
      "- batch size 2: 106.73 tokens/sec (2 x 53.37)\n",
      "- batch size 3: 158.59 tokens/sec (3 x 52.86)\n",
      "- batch size 4: 211.71 tokens/sec (4 x 52.93)\n",
      "- batch size 5: 263.86 tokens/sec (5 x 52.77)\n",
      "- batch size 6: 312.78 tokens/sec (6 x 52.13)\n",
      "- batch size 7: 361.04 tokens/sec (7 x 51.58)\n",
      "- batch size 8: 414.94 tokens/sec (8 x 51.87)\n",
      "- batch size 9: 454.06 tokens/sec (9 x 50.45)\n",
      "- batch size 10: 491.39 tokens/sec (10 x 49.14)\n",
      "- batch size 11: 562.16 tokens/sec (11 x 51.11)\n",
      "- batch size 12: 607.31 tokens/sec (12 x 50.61)\n",
      "- batch size 13: 663.95 tokens/sec (13 x 51.07)\n",
      "- batch size 14: 713.50 tokens/sec (14 x 50.96)\n",
      "- batch size 15: 744.90 tokens/sec (15 x 49.66)\n",
      "- batch size 16: 806.56 tokens/sec (16 x 50.41)\n",
      "- batch size 17: 807.56 tokens/sec (17 x 47.50)\n",
      "- batch size 18: 844.80 tokens/sec (18 x 46.93)\n",
      "- batch size 19: 887.98 tokens/sec (19 x 46.74)\n",
      "- batch size 20: 930.40 tokens/sec (20 x 46.52)\n",
      "- batch size 21: 977.37 tokens/sec (21 x 46.54)\n",
      "- batch size 22: 1035.36 tokens/sec (22 x 47.06)\n",
      "- batch size 23: 1067.38 tokens/sec (23 x 46.41)\n",
      "- batch size 24: 1124.12 tokens/sec (24 x 46.84)\n",
      "- batch size 25: 1164.26 tokens/sec (25 x 46.57)\n",
      "- batch size 26: 1202.78 tokens/sec (26 x 46.26)\n",
      "- batch size 27: 1241.82 tokens/sec (27 x 45.99)\n",
      "- batch size 28: 1289.04 tokens/sec (28 x 46.04)\n",
      "- batch size 29: 1302.18 tokens/sec (29 x 44.90)\n",
      "- batch size 30: 1351.25 tokens/sec (30 x 45.04)\n",
      "- batch size 31: 900.91 tokens/sec (31 x 29.06)\n",
      "- batch size 32: 625.98 tokens/sec (32 x 19.56)\n"
     ]
    }
   ],
   "source": [
    "sglang_generate(test_messages*8, runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df115904-3d5e-4b46-a255-06ddca394ba4",
   "metadata": {},
   "source": [
    "### w8a16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8acfda8-889f-40b2-b15a-e6f572caf2de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T12:52:33.141558Z",
     "iopub.status.busy": "2024-09-22T12:52:33.140861Z",
     "iopub.status.idle": "2024-09-22T12:53:26.789057Z",
     "shell.execute_reply": "2024-09-22T12:53:26.786981Z",
     "shell.execute_reply.started": "2024-09-22T12:52:33.141536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 14:52:36 weight_utils.py:242] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79812bcc2564afdbfc6824998b877d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/managers/detokenizer_manager.py\", line 185, in start_detokenizer_process\n",
      "    loop.run_until_complete(manager.handle_loop())\n",
      "  File \"uvloop/loop.pyx\", line 1511, in uvloop.loop.Loop.run_until_complete\n",
      "  File \"uvloop/loop.pyx\", line 1504, in uvloop.loop.Loop.run_until_complete\n",
      "  File \"uvloop/loop.pyx\", line 1377, in uvloop.loop.Loop.run_forever\n",
      "  File \"uvloop/loop.pyx\", line 555, in uvloop.loop.Loop._run\n",
      "Process Process-1:1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/managers/controller_single.py\", line 160, in start_controller_process\n",
      "    controller.loop_for_forward()\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/managers/controller_single.py\", line 99, in loop_for_forward\n",
      "    out_pyobjs = self.tp_server.exposed_step(recv_reqs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py\", line 239, in exposed_step\n",
      "    self.forward_step()\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:W0922 15:01:16.535000 139687192635072 torch/_inductor/compile_worker/subproc_pool.py:126] SubprocPool unclean exit\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py\", line 272, in forward_step\n",
      "    self.forward_decode_batch(self.running_batch)\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py\", line 755, in forward_decode_batch\n",
      "    batch.sampling_info.penalizer_orchestrator.cumulate_output_tokens(\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/sampling/penaltylib/orchestrator.py\", line 85, in cumulate_output_tokens\n",
      "    penalizer.cumulate_output_tokens(output_ids=token_ids)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "runtime = sglang_load(test_models[\"llama-3.1:w8a16\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c0d53fb-d3d8-4b93-adda-161c044a70db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T12:54:32.639808Z",
     "iopub.status.busy": "2024-09-22T12:54:32.639203Z",
     "iopub.status.idle": "2024-09-22T13:01:16.926373Z",
     "shell.execute_reply": "2024-09-22T13:01:16.925725Z",
     "shell.execute_reply.started": "2024-09-22T12:54:32.639779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGLang performance test:\n",
      "Generated text: \"Le Crédit Mutuel est une banque coopérative française qui offre plusieurs avantages à ses adhérents et clients. Voici quelques-uns des principaux avantages :\\n\\n1. **Intérêts attractifs** : Le Crédit Mutuel propose des taux d'intérêt compétitifs pour les prêts, les comptes courants et les épargnes.\\n2. **Services personnalisés** : En tant que banque coopérative, le Crédit Mutuel se concentre sur la relation avec ses adhérents et clients, offrant des services personnalisés et adaptés à leurs besoins.\\n3. **Sécurité et confidentialité** : Comme banque coopérative, le Crédit Mutuel est soumis à des règles de confidentialité et de sécurité strictes pour protéger les données personnelles et financières de ses adhérents et clients.\\n4. **Prêts sans frais de dossier** : Le Crédit Mutuel propose des prêts sans frais de dossier pour certains types de prêts, ce qui peut aider les clients à économiser de l'argent.\\n5. **Cartes de crédit et de débit** : Le Crédit Mutuel offre des cartes de crédit et de débit avec des avantages tels que la réduction des frais de transaction ou des intérêts réduits.\\n6. **Épargne et placement** : Le Crédit Mutuel propose des produits d'épargne et de placement variés, tels que des livrets d'épargne, des comptes d'épargne à terme et des placements diversifiés.\\n7. **Conseils financiers** : Les adhérents et clients du Crédit Mutuel ont accès à des conseils financiers gratuits pour aider à gérer leur budget, planifier leur avenir financier et prendre des décisions éclairées.\\n8. **Réseau de distributeurs** : Le Crédit Mutuel dispose d'un réseau de distributeurs et de guichets automatiques étendu, ce qui facilite l'accès aux services bancaires.\\n9. **Assistance et garantie** : Le Crédit Mutuel propose des services d'assistance et de garantie pour aider à protéger les biens et les projets personnels.\\n\"\n",
      "- batch size 1: 87.07 tokens/sec (1 x 87.07)\n",
      "- batch size 2: 171.62 tokens/sec (2 x 85.81)\n",
      "- batch size 3: 255.17 tokens/sec (3 x 85.06)\n",
      "- batch size 4: 332.75 tokens/sec (4 x 83.19)\n",
      "- batch size 5: 400.14 tokens/sec (5 x 80.03)\n",
      "- batch size 6: 497.19 tokens/sec (6 x 82.86)\n",
      "- batch size 7: 574.74 tokens/sec (7 x 82.11)\n",
      "- batch size 8: 654.19 tokens/sec (8 x 81.77)\n",
      "- batch size 9: 732.26 tokens/sec (9 x 81.36)\n",
      "- batch size 10: 803.03 tokens/sec (10 x 80.30)\n",
      "- batch size 11: 887.36 tokens/sec (11 x 80.67)\n",
      "- batch size 12: 943.27 tokens/sec (12 x 78.61)\n",
      "- batch size 13: 1010.59 tokens/sec (13 x 77.74)\n",
      "- batch size 14: 1102.76 tokens/sec (14 x 78.77)\n",
      "- batch size 15: 1171.05 tokens/sec (15 x 78.07)\n",
      "- batch size 16: 1231.32 tokens/sec (16 x 76.96)\n",
      "- batch size 17: 1229.04 tokens/sec (17 x 72.30)\n",
      "- batch size 18: 1281.63 tokens/sec (18 x 71.20)\n",
      "- batch size 19: 1355.90 tokens/sec (19 x 71.36)\n",
      "- batch size 20: 1426.38 tokens/sec (20 x 71.32)\n",
      "- batch size 21: 1492.51 tokens/sec (21 x 71.07)\n",
      "- batch size 22: 1560.33 tokens/sec (22 x 70.92)\n",
      "- batch size 23: 1632.06 tokens/sec (23 x 70.96)\n",
      "- batch size 24: 1691.40 tokens/sec (24 x 70.48)\n",
      "- batch size 25: 1741.80 tokens/sec (25 x 69.67)\n",
      "- batch size 26: 1782.51 tokens/sec (26 x 68.56)\n",
      "- batch size 27: 1805.51 tokens/sec (27 x 66.87)\n",
      "- batch size 28: 1901.46 tokens/sec (28 x 67.91)\n",
      "- batch size 29: 1858.43 tokens/sec (29 x 64.08)\n",
      "- batch size 30: 1993.94 tokens/sec (30 x 66.46)\n",
      "- batch size 31: 1195.98 tokens/sec (31 x 38.58)\n",
      "- batch size 32: 690.20 tokens/sec (32 x 21.57)\n",
      "- batch size 33: 634.13 tokens/sec (33 x 19.22)\n",
      "- batch size 34: 696.08 tokens/sec (34 x 20.47)\n",
      "- batch size 35: 1026.15 tokens/sec (35 x 29.32)\n",
      "- batch size 36: 1025.83 tokens/sec (36 x 28.50)\n",
      "- batch size 37: 1121.06 tokens/sec (37 x 30.30)\n",
      "- batch size 38: 1107.46 tokens/sec (38 x 29.14)\n",
      "- batch size 39: 1148.71 tokens/sec (39 x 29.45)\n",
      "- batch size 40: 1180.48 tokens/sec (40 x 29.51)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msglang_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_messages\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m, in \u001b[0;36msglang_generate\u001b[0;34m(messages, runtime)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_size \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(messages) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     19\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# Record the start time\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mruntime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_params\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     21\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# Record the end time\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Print the outputs.\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/server.py:630\u001b[0m, in \u001b[0;36mRuntime.generate\u001b[0;34m(self, prompt, sampling_params, return_logprob, logprob_start_len, top_logprobs_num, lora_path)\u001b[0m\n\u001b[1;32m    621\u001b[0m json_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampling_params\u001b[39m\u001b[38;5;124m\"\u001b[39m: sampling_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlora_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: lora_path,\n\u001b[1;32m    628\u001b[0m }\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(lora_path, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lora_path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(prompt)\n\u001b[0;32m--> 630\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/generate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mdumps(response\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/requests/adapters.py:589\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    586\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/urllib3/connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/http/client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sglang_generate(test_messages*10, runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1faa0c-f6d8-4c61-b50a-d125acb0a6b1",
   "metadata": {},
   "source": [
    "### fp8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eedf8f-be67-4e78-ae94-df938e227b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = sglang_load(test_models[\"llama-3.1:fp8\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e802e1-6e87-47b2-9ac1-a1be462fd0ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T13:03:02.785397Z",
     "iopub.status.busy": "2024-09-22T13:03:02.784894Z",
     "iopub.status.idle": "2024-09-22T13:03:02.794302Z",
     "shell.execute_reply": "2024-09-22T13:03:02.793600Z",
     "shell.execute_reply.started": "2024-09-22T13:03:02.785362Z"
    }
   },
   "source": [
    "**INTERNAL ERROR** during FP8 model load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffcae27-f04e-40c3-8455-317b0341717d",
   "metadata": {},
   "source": [
    "### w8a8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af127421-0bc9-468b-839d-820dbdbe242c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T13:04:40.733913Z",
     "iopub.status.busy": "2024-09-22T13:04:40.733454Z",
     "iopub.status.idle": "2024-09-22T13:05:10.099106Z",
     "shell.execute_reply": "2024-09-22T13:05:10.098008Z",
     "shell.execute_reply.started": "2024-09-22T13:04:40.733896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 15:04:44 weight_utils.py:242] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1205690828c543a3ba799f0bafd24cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/managers/detokenizer_manager.py\", line 185, in start_detokenizer_process\n",
      "    loop.run_until_complete(manager.handle_loop())\n",
      "  File \"uvloop/loop.pyx\", line 1511, in uvloop.loop.Loop.run_until_complete\n",
      "  File \"uvloop/loop.pyx\", line 1504, in uvloop.loop.Loop.run_until_complete\n",
      "  File \"uvloop/loop.pyx\", line 1377, in uvloop.loop.Loop.run_forever\n",
      "  File \"uvloop/loop.pyx\", line 555, in uvloop.loop.Loop._run\n",
      "  File \"uvloop/handles/poll.pyx\", line 216, in uvloop.loop.__on_uvpoll_event\n",
      "  File \"uvloop/cbhandles.pyx\", line 83, in uvloop.loop.Handle._run\n",
      "  File \"uvloop/cbhandles.pyx\", line 66, in uvloop.loop.Handle._run\n",
      "  File \"uvloop/loop.pyx\", line 397, in uvloop.loop.Loop._read_from_self\n",
      "  File \"uvloop/loop.pyx\", line 402, in uvloop.loop.Loop._invoke_signals\n",
      "  File \"uvloop/loop.pyx\", line 377, in uvloop.loop.Loop._ceval_process_signals\n",
      "KeyboardInterrupt\n",
      "Process Process-1:1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/managers/controller_single.py\", line 160, in start_controller_process\n",
      "    controller.loop_for_forward()\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/managers/controller_single.py\", line 99, in loop_for_forward\n",
      "    out_pyobjs = self.tp_server.exposed_step(recv_reqs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py\", line 239, in exposed_step\n",
      "    self.forward_step()\n",
      "[rank0]:W0922 15:11:19.557000 139767874275008 torch/_inductor/compile_worker/subproc_pool.py:126] SubprocPool unclean exit\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py\", line 272, in forward_step\n",
      "    self.forward_decode_batch(self.running_batch)\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py\", line 754, in forward_decode_batch\n",
      "    next_token_ids = self.model_runner.sample(logits_output, batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py\", line 563, in sample\n",
      "    next_token_ids = self.sampler(logits, batch.sampling_info)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/layers/sampler.py\", line 48, in forward\n",
      "    uniform_samples = torch.rand(\n",
      "                      ^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "runtime = sglang_load(test_models[\"llama-3.1:w8a8\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89f71362-ce66-4c6c-932d-95c581e38d13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T13:05:15.548918Z",
     "iopub.status.busy": "2024-09-22T13:05:15.548529Z",
     "iopub.status.idle": "2024-09-22T13:11:19.884709Z",
     "shell.execute_reply": "2024-09-22T13:11:19.884184Z",
     "shell.execute_reply.started": "2024-09-22T13:05:15.548886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGLang performance test:\n",
      "Generated text: \"Le Crédit Mutuel est une banque coopérative française qui offre divers avantages à ses adhérents et clients. Voici quelques-uns des principaux avantages :\\n\\n1. **Intérêts attractifs** : Le Crédit Mutuel propose des taux d'intérêt compétitifs pour les prêts, les comptes courants et les épargnes.\\n2. **Service personnalisé** : En tant que banque coopérative, le Crédit Mutuel se concentre sur la relation avec ses clients et adhérents, offrant un service personnalisé et attentif.\\n3. **Produits financiers adaptés** : Le Crédit Mutuel propose une large gamme de produits financiers adaptés aux besoins de ses clients, tels que les prêts immobiliers, les prêts personnels, les comptes courants, les comptes d'épargne, etc.\\n4. **Sécurité et protection** : Le Crédit Mutuel met en place des mesures de sécurité et de protection pour protéger les données et les comptes de ses clients.\\n5. **Transparence et responsabilité** : En tant que banque coopérative, le Crédit Mutuel est soumis à des règles de transparence et de responsabilité, ce qui garantit que les décisions sont prises dans l'intérêt de ses adhérents et clients.\\n6. **Participation à la vie locale** : Le Crédit Mutuel est implanté dans de nombreuses régions de France et participe activement à la vie économique et sociale locale.\\n7. **Accès à des services complémentaires** : Les adhérents du Crédit Mutuel ont souvent accès à des services complémentaires tels que l'assurance, la mutualité ou les services de conseil financier.\\n8. **Épargne collective** : Le Crédit Mutuel propose des produits d'épargne collective qui permettent aux épargnants de participer à la croissance de leur épargne.\\n9. **Prise en charge de projets locaux** : Le Crédit Mutuel soutient souvent des projets locaux tels que la création d'entreprises, la rénovation de bâtiments anciens ou la promotion de l'artisan\"\n",
      "- batch size 1: 75.68 tokens/sec (1 x 75.68)\n",
      "- batch size 2: 147.96 tokens/sec (2 x 73.98)\n",
      "- batch size 3: 218.90 tokens/sec (3 x 72.97)\n",
      "- batch size 4: 284.35 tokens/sec (4 x 71.09)\n",
      "- batch size 5: 337.23 tokens/sec (5 x 67.45)\n",
      "- batch size 6: 415.53 tokens/sec (6 x 69.26)\n",
      "- batch size 7: 492.33 tokens/sec (7 x 70.33)\n",
      "- batch size 8: 552.45 tokens/sec (8 x 69.06)\n",
      "- batch size 9: 620.16 tokens/sec (9 x 68.91)\n",
      "- batch size 10: 701.63 tokens/sec (10 x 70.16)\n",
      "- batch size 11: 776.72 tokens/sec (11 x 70.61)\n",
      "- batch size 12: 822.48 tokens/sec (12 x 68.54)\n",
      "- batch size 13: 890.17 tokens/sec (13 x 68.47)\n",
      "- batch size 14: 954.01 tokens/sec (14 x 68.14)\n",
      "- batch size 15: 1014.44 tokens/sec (15 x 67.63)\n",
      "- batch size 16: 1061.67 tokens/sec (16 x 66.35)\n",
      "- batch size 17: 1151.73 tokens/sec (17 x 67.75)\n",
      "- batch size 18: 500.85 tokens/sec (18 x 27.83)\n",
      "- batch size 19: 528.51 tokens/sec (19 x 27.82)\n",
      "- batch size 20: 553.01 tokens/sec (20 x 27.65)\n",
      "- batch size 21: 341.58 tokens/sec (21 x 16.27)\n",
      "- batch size 22: 363.09 tokens/sec (22 x 16.50)\n",
      "- batch size 23: 255.70 tokens/sec (23 x 11.12)\n",
      "- batch size 24: 265.10 tokens/sec (24 x 11.05)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msglang_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_messages\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m, in \u001b[0;36msglang_generate\u001b[0;34m(messages, runtime)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_size \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(messages) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     19\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# Record the start time\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mruntime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_params\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     21\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# Record the end time\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Print the outputs.\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/server.py:630\u001b[0m, in \u001b[0;36mRuntime.generate\u001b[0;34m(self, prompt, sampling_params, return_logprob, logprob_start_len, top_logprobs_num, lora_path)\u001b[0m\n\u001b[1;32m    621\u001b[0m json_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampling_params\u001b[39m\u001b[38;5;124m\"\u001b[39m: sampling_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlora_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: lora_path,\n\u001b[1;32m    628\u001b[0m }\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(lora_path, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lora_path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(prompt)\n\u001b[0;32m--> 630\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/generate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mdumps(response\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/requests/adapters.py:589\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    586\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/urllib3/connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/http/client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sglang_generate(test_messages*8, runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b358f9d-cea7-4b0d-a099-154d0f81634d",
   "metadata": {},
   "source": [
    "### w4a16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d179a13-50ba-4053-9ba2-cd325322634c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T13:13:29.728496Z",
     "iopub.status.busy": "2024-09-22T13:13:29.728062Z",
     "iopub.status.idle": "2024-09-22T13:13:47.406863Z",
     "shell.execute_reply": "2024-09-22T13:13:47.404366Z",
     "shell.execute_reply.started": "2024-09-22T13:13:29.728457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 15:13:32 gptq_marlin.py:108] The model is convertible to gptq_marlin during runtime. Using gptq_marlin kernel.\n",
      "INFO 09-22 15:13:33 weight_utils.py:242] Using model weights format ['*.safetensors']\n",
      "INFO 09-22 15:13:33 weight_utils.py:287] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed6707b65214716bbaeeabc42a14268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/managers/detokenizer_manager.py\", line 185, in start_detokenizer_process\n",
      "    loop.run_until_complete(manager.handle_loop())\n",
      "  File \"uvloop/loop.pyx\", line 1511, in uvloop.loop.Loop.run_until_complete\n",
      "  File \"uvloop/loop.pyx\", line 1504, in uvloop.loop.Loop.run_until_complete\n",
      "  File \"uvloop/loop.pyx\", line 1377, in uvloop.loop.Loop.run_forever\n",
      "  File \"uvloop/loop.pyx\", line 555, in uvloop.loop.Loop._run\n",
      "  File \"uvloop/handles/poll.pyx\", line 216, in uvloop.loop.__on_uvpoll_event\n",
      "  File \"uvloop/cbhandles.pyx\", line 83, in uvloop.loop.Handle._run\n",
      "  File \"uvloop/cbhandles.pyx\", line 66, in uvloop.loop.Handle._run\n",
      "  File \"uvloop/loop.pyx\", line 397, in uvloop.loop.Loop._read_from_self\n",
      "  File \"uvloop/loop.pyx\", line 402, in uvloop.loop.Loop._invoke_signals\n",
      "  File \"uvloop/loop.pyx\", line 377, in uvloop.loop.Loop._ceval_process_signals\n",
      "KeyboardInterrupt\n",
      "Process Process-1:1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/managers/controller_single.py\", line 160, in start_controller_process\n",
      "    controller.loop_for_forward()\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/managers/controller_single.py\", line 99, in loop_for_forward\n",
      "    out_pyobjs = self.tp_server.exposed_step(recv_reqs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py\", line 239, in exposed_step\n",
      "    self.forward_step()\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py\", line 272, in forward_step\n",
      "    self.forward_decode_batch(self.running_batch)\n",
      "[rank0]:W0922 15:19:24.767000 139820202403520 torch/_inductor/compile_worker/subproc_pool.py:126] SubprocPool unclean exit\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py\", line 755, in forward_decode_batch\n",
      "    batch.sampling_info.penalizer_orchestrator.cumulate_output_tokens(\n",
      "  File \"/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/sampling/penaltylib/orchestrator.py\", line 85, in cumulate_output_tokens\n",
      "    penalizer.cumulate_output_tokens(output_ids=token_ids)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "runtime = sglang_load(test_models[\"llama-3.1:w4a16\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f403f899-f66e-4162-9ed6-aea5f2603f4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T13:13:47.411475Z",
     "iopub.status.busy": "2024-09-22T13:13:47.411035Z",
     "iopub.status.idle": "2024-09-22T13:19:25.151758Z",
     "shell.execute_reply": "2024-09-22T13:19:25.151197Z",
     "shell.execute_reply.started": "2024-09-22T13:13:47.411425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGLang performance test:\n",
      "Generated text: \"Le Crédit Mutuel est une banque mutuelle française qui offre divers services financiers à ses clients. Voici quelques-uns des principaux avantages du Crédit Mutuel :\\n\\n1. **Sécurité et stabilité** : Le Crédit Mutuel est une banque mutuelle, ce qui signifie qu'il est géré par ses membres (clients) et non par des actionnaires. Cela garantit sa stabilité et sa sécurité.\\n2. **Services personnalisés** : Le Crédit Mutuel propose des services personnalisés adaptés aux besoins de ses clients, qu'ils soient particuliers ou professionnels.\\n3. **Offres de produits variées** : La banque propose une gamme de produits et services, notamment des comptes courants, des épargnes, des crédits, des assurances et des services d'investissement.\\n4. **Prêt rapide et à bon taux d'intérêt** : Le Crédit Mutuel offre des prêts à des taux d'intérêt compétitifs et avec des conditions de remboursement flexibles.\\n5. **Assistance et conseil** : Les clients du Crédit Mutuel bénéficient d'une assistance et d'un conseil personnalisés pour aider à prendre des décisions éclairées concernant leurs finances.\\n6. **Systèmes de paiement sécurisés** : La banque propose des systèmes de paiement sécurisés pour protéger les transactions de ses clients.\\n7. **Presences dans tout le territoire** : Le Crédit Mutuel a une présence importante sur tout le territoire français, avec des agences et des distributeurs répartis dans toutes les régions.\\n8. **Systèmes de gestion de patrimoine** : La banque propose des systèmes de gestion de patrimoine pour aider les clients à gérer leurs actifs et à atteindre leurs objectifs financiers.\\n9. **Partenariats et collaborations** : Le Crédit Mutuel collabore avec d'autres entreprises et institutions pour offrir des solutions complètes et innovantes à ses clients.\\n10. **Transparence et responsabilité** : La banque est soumise à des règles de transparence et de responsabilité pour garantir que ses opérations sont transparentes et éthiques.\\n\\nCes avantages peuvent var\"\n",
      "- batch size 1: 119.47 tokens/sec (1 x 119.47)\n",
      "- batch size 2: 235.54 tokens/sec (2 x 117.77)\n",
      "- batch size 3: 343.20 tokens/sec (3 x 114.40)\n",
      "- batch size 4: 453.09 tokens/sec (4 x 113.27)\n",
      "- batch size 5: 559.35 tokens/sec (5 x 111.87)\n",
      "- batch size 6: 647.88 tokens/sec (6 x 107.98)\n",
      "- batch size 7: 809.98 tokens/sec (7 x 115.71)\n",
      "- batch size 8: 867.72 tokens/sec (8 x 108.46)\n",
      "- batch size 9: 1016.88 tokens/sec (9 x 112.99)\n",
      "- batch size 10: 1087.76 tokens/sec (10 x 108.78)\n",
      "- batch size 11: 1210.91 tokens/sec (11 x 110.08)\n",
      "- batch size 12: 1337.60 tokens/sec (12 x 111.47)\n",
      "- batch size 13: 1368.37 tokens/sec (13 x 105.26)\n",
      "- batch size 14: 1464.22 tokens/sec (14 x 104.59)\n",
      "- batch size 15: 1509.03 tokens/sec (15 x 100.60)\n",
      "- batch size 16: 1666.01 tokens/sec (16 x 104.13)\n",
      "- batch size 17: 1598.10 tokens/sec (17 x 94.01)\n",
      "- batch size 18: 1681.20 tokens/sec (18 x 93.40)\n",
      "- batch size 19: 1802.29 tokens/sec (19 x 94.86)\n",
      "- batch size 20: 1883.87 tokens/sec (20 x 94.19)\n",
      "- batch size 21: 1965.75 tokens/sec (21 x 93.61)\n",
      "- batch size 22: 2043.66 tokens/sec (22 x 92.89)\n",
      "- batch size 23: 2134.67 tokens/sec (23 x 92.81)\n",
      "- batch size 24: 2202.02 tokens/sec (24 x 91.75)\n",
      "- batch size 25: 2273.44 tokens/sec (25 x 90.94)\n",
      "- batch size 26: 2276.49 tokens/sec (26 x 87.56)\n",
      "- batch size 27: 2372.31 tokens/sec (27 x 87.86)\n",
      "- batch size 28: 2475.12 tokens/sec (28 x 88.40)\n",
      "- batch size 29: 2508.51 tokens/sec (29 x 86.50)\n",
      "- batch size 30: 2634.24 tokens/sec (30 x 87.81)\n",
      "- batch size 31: 2657.33 tokens/sec (31 x 85.72)\n",
      "- batch size 32: 2824.99 tokens/sec (32 x 88.28)\n",
      "- batch size 33: 2633.52 tokens/sec (33 x 79.80)\n",
      "- batch size 34: 2824.58 tokens/sec (34 x 83.08)\n",
      "- batch size 35: 1164.60 tokens/sec (35 x 33.27)\n",
      "- batch size 36: 1231.65 tokens/sec (36 x 34.21)\n",
      "- batch size 37: 1319.47 tokens/sec (37 x 35.66)\n",
      "- batch size 38: 1367.97 tokens/sec (38 x 36.00)\n",
      "- batch size 39: 1353.92 tokens/sec (39 x 34.72)\n",
      "- batch size 40: 1383.40 tokens/sec (40 x 34.58)\n",
      "- batch size 41: 1380.85 tokens/sec (41 x 33.68)\n",
      "- batch size 42: 1408.69 tokens/sec (42 x 33.54)\n",
      "- batch size 43: 1215.52 tokens/sec (43 x 28.27)\n",
      "- batch size 44: 934.38 tokens/sec (44 x 21.24)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msglang_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_messages\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m, in \u001b[0;36msglang_generate\u001b[0;34m(messages, runtime)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_size \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(messages) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     19\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# Record the start time\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mruntime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_params\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     21\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# Record the end time\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Print the outputs.\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/sglang/srt/server.py:630\u001b[0m, in \u001b[0;36mRuntime.generate\u001b[0;34m(self, prompt, sampling_params, return_logprob, logprob_start_len, top_logprobs_num, lora_path)\u001b[0m\n\u001b[1;32m    621\u001b[0m json_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampling_params\u001b[39m\u001b[38;5;124m\"\u001b[39m: sampling_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlora_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: lora_path,\n\u001b[1;32m    628\u001b[0m }\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(lora_path, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lora_path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(prompt)\n\u001b[0;32m--> 630\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/generate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mdumps(response\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/requests/adapters.py:589\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    586\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/urllib3/connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/http/client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/wordslab-notebooks/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sglang_generate(test_messages*18, runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d17ba0a-c518-4149-9689-dcfb52efa81c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-llms",
   "language": "python",
   "name": "wordslab-llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
