{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7249409e-3e87-4e64-875c-624a78033472",
   "metadata": {},
   "source": [
    "## Install prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24e11987-23f3-44e8-8184-b83679f0ee02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T21:30:05.806413Z",
     "iopub.status.busy": "2024-09-20T21:30:05.806024Z",
     "iopub.status.idle": "2024-09-20T21:30:05.816874Z",
     "shell.execute_reply": "2024-09-20T21:30:05.816083Z",
     "shell.execute_reply.started": "2024-09-20T21:30:05.806383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "version('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee55718c-4310-4aa9-b363-acae522d8197",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f72e89a-3941-4ee1-97cf-18c2e15b1842",
   "metadata": {},
   "source": [
    "https://docs.vllm.ai/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "459e66c0-05d6-4651-b62b-e486f5b0a961",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T19:18:21.579202Z",
     "iopub.status.busy": "2024-09-20T19:18:21.578852Z",
     "iopub.status.idle": "2024-09-20T19:18:21.586959Z",
     "shell.execute_reply": "2024-09-20T19:18:21.586649Z",
     "shell.execute_reply.started": "2024-09-20T19:18:21.579175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.44.2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d35b0e6-a186-447d-a035-9af71e3358af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "876ca82b-1cd6-4aae-a964-2b047a9fc4a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T18:38:51.786662Z",
     "iopub.status.busy": "2024-09-20T18:38:51.786290Z",
     "iopub.status.idle": "2024-09-20T18:38:51.794793Z",
     "shell.execute_reply": "2024-09-20T18:38:51.794417Z",
     "shell.execute_reply.started": "2024-09-20T18:38:51.786630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6.1.post2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('vllm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6874cffb-8745-418f-9194-0c2f04060567",
   "metadata": {},
   "source": [
    "https://sglang.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56019c95-b5b3-4fe9-8170-2d3873db36cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade \"sglang[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea3fca-704a-4b5e-a8c0-80496ce179f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e703628-1345-49f5-b310-b4b93b36c620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T18:44:48.981904Z",
     "iopub.status.busy": "2024-09-20T18:44:48.981514Z",
     "iopub.status.idle": "2024-09-20T18:44:48.993669Z",
     "shell.execute_reply": "2024-09-20T18:44:48.993228Z",
     "shell.execute_reply.started": "2024-09-20T18:44:48.981875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.1.post2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('sglang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cb9d3f5-621d-4e1f-b30e-c616ecb2df83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T21:30:11.967166Z",
     "iopub.status.busy": "2024-09-20T21:30:11.966769Z",
     "iopub.status.idle": "2024-09-20T21:30:11.975092Z",
     "shell.execute_reply": "2024-09-20T21:30:11.974357Z",
     "shell.execute_reply.started": "2024-09-20T21:30:11.967143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.6+cu124torch2.4'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('flashinfer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2783c62-8361-4e45-9fdc-07a9ced35e81",
   "metadata": {},
   "source": [
    "https://github.com/ollama/ollama-python\n",
    "\n",
    "https://github.com/ollama/ollama/tree/main/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b56434-da15-42f4-9974-4f24be59902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48ac7f1f-81db-4643-90d8-2355f26de1c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T19:08:15.201708Z",
     "iopub.status.busy": "2024-09-20T19:08:15.200981Z",
     "iopub.status.idle": "2024-09-20T19:08:15.210161Z",
     "shell.execute_reply": "2024-09-20T19:08:15.209607Z",
     "shell.execute_reply.started": "2024-09-20T19:08:15.201674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('ollama')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de95a90-29e7-4dc4-974b-8b601a86c16a",
   "metadata": {},
   "source": [
    "## Test installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6570564c-6fbb-4eb2-b716-1a161c7d9787",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T12:59:39.836919Z",
     "iopub.status.busy": "2024-09-21T12:59:39.836745Z",
     "iopub.status.idle": "2024-09-21T12:59:39.840157Z",
     "shell.execute_reply": "2024-09-21T12:59:39.839831Z",
     "shell.execute_reply.started": "2024-09-21T12:59:39.836910Z"
    }
   },
   "outputs": [],
   "source": [
    "test_messages = [\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quels sont les avantages du Crédit Mutuel ?\"}\n",
    "],\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quels sont les avantages du Crédit Agricole ?\"}\n",
    "],\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quels sont les avantages de la Société Générale ?\"}\n",
    "],\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quels sont les avantages de la BNP ?\"}\n",
    "]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e93cb29b-8c75-4187-846a-832024247f03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T12:59:39.840837Z",
     "iopub.status.busy": "2024-09-21T12:59:39.840650Z",
     "iopub.status.idle": "2024-09-21T12:59:39.859079Z",
     "shell.execute_reply": "2024-09-21T12:59:39.858698Z",
     "shell.execute_reply.started": "2024-09-21T12:59:39.840825Z"
    }
   },
   "outputs": [],
   "source": [
    "test_models = {\n",
    "    \"llama-3.1\" : \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a427640-100e-49cb-a2fc-f5fa8c18a6e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T12:59:39.859606Z",
     "iopub.status.busy": "2024-09-21T12:59:39.859500Z",
     "iopub.status.idle": "2024-09-21T12:59:40.681709Z",
     "shell.execute_reply": "2024-09-21T12:59:40.681184Z",
     "shell.execute_reply.started": "2024-09-21T12:59:39.859598Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def format_prompt(messages, model):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "267c07a4-c9f1-4d16-8697-d4a1204e2c84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T12:59:40.682536Z",
     "iopub.status.busy": "2024-09-21T12:59:40.682204Z",
     "iopub.status.idle": "2024-09-21T12:59:41.038255Z",
     "shell.execute_reply": "2024-09-21T12:59:41.037821Z",
     "shell.execute_reply.started": "2024-09-21T12:59:40.682526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nTu es un assistant utile et professionnel qui répond toujours en français.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nQuels sont les avantages du Crédit Mutuel ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n',\n",
       " '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nTu es un assistant utile et professionnel qui répond toujours en français.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nQuels sont les avantages du Crédit Agricole ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n',\n",
       " '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nTu es un assistant utile et professionnel qui répond toujours en français.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nQuels sont les avantages de la Société Générale ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n',\n",
       " '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nTu es un assistant utile et professionnel qui répond toujours en français.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nQuels sont les avantages de la BNP ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_prompt(test_messages, test_models[\"llama-3.1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d16d245-b3ef-418e-8d3b-5f494f5e6deb",
   "metadata": {},
   "source": [
    "### vLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f997ac1-6001-493b-b118-61ca0ff29449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T12:59:42.010177Z",
     "iopub.status.busy": "2024-09-21T12:59:42.009749Z",
     "iopub.status.idle": "2024-09-21T12:59:42.024929Z",
     "shell.execute_reply": "2024-09-21T12:59:42.024603Z",
     "shell.execute_reply.started": "2024-09-21T12:59:42.010147Z"
    }
   },
   "outputs": [],
   "source": [
    "# Authenticate VLLM with Huggingface Hub\n",
    "import os\n",
    "\n",
    "with open(\"/workspace/hftoken\", 'r') as file:\n",
    "    myhftoken = file.read().strip()\n",
    "\n",
    "os.environ[\"HF_TOKEN\"]=myhftoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15a8369c-d660-4d64-897d-4d5929200a42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T12:59:44.988332Z",
     "iopub.status.busy": "2024-09-21T12:59:44.987550Z",
     "iopub.status.idle": "2024-09-21T12:59:46.208740Z",
     "shell.execute_reply": "2024-09-21T12:59:46.208262Z",
     "shell.execute_reply.started": "2024-09-21T12:59:44.988301Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "def vllm_load(model):    \n",
    "    llm = LLM(model, gpu_memory_utilization=0.99, max_model_len=8192)\n",
    "    llm._model = model\n",
    "    return llm\n",
    "\n",
    "def vllm_generate(messages, llm):    \n",
    "    print(f\"vLLM performance test:\")\n",
    "    \n",
    "    prompts = format_prompt(messages, llm._model)\n",
    "    sampling_params = SamplingParams(temperature=0.7, top_p=0.8, repetition_penalty=1.05, max_tokens=512)\n",
    "    # warmup\n",
    "    outputs = llm.generate(prompts[0], sampling_params)\n",
    "    print(f\"Generated text: {outputs[0].outputs[0].text!r}\")\n",
    "    \n",
    "    for batch_size in range(1, len(messages) + 1):\n",
    "        start_time = time.time()  # Record the start time\n",
    "        outputs = llm.generate(prompts[0:batch_size], sampling_params)\n",
    "        end_time = time.time()  # Record the end time\n",
    "            \n",
    "        # Print the outputs.\n",
    "        tokenscount = 0\n",
    "        for output in outputs:\n",
    "            generated_text = output.outputs[0].text\n",
    "            tokenscount = tokenscount + len(output.outputs[0].token_ids)\n",
    "\n",
    "        tokens_per_sec = tokenscount/(end_time-start_time)\n",
    "        print(f\"- batch size {batch_size}: {tokens_per_sec:.2f} tokens/sec ({batch_size} x {tokens_per_sec/batch_size:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2267f691-7b8f-44a7-82c6-7e85598c7a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T12:59:48.277632Z",
     "iopub.status.busy": "2024-09-21T12:59:48.276955Z",
     "iopub.status.idle": "2024-09-21T13:00:05.296796Z",
     "shell.execute_reply": "2024-09-21T13:00:05.296499Z",
     "shell.execute_reply.started": "2024-09-21T12:59:48.277602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-21 14:59:48 llm_engine.py:184] Initializing an LLM engine (v0.5.5) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, enable_prefix_caching=False)\n",
      "WARNING 09-21 14:59:49 utils.py:721] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "INFO 09-21 14:59:49 model_runner.py:879] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...\n",
      "INFO 09-21 14:59:49 weight_utils.py:236] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0a3060c18942eab3f959c967f30c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-21 14:59:52 model_runner.py:890] Loading model weights took 14.9888 GB\n",
      "INFO 09-21 14:59:53 gpu_executor.py:121] # GPU blocks: 3610, # CPU blocks: 2048\n",
      "INFO 09-21 14:59:54 model_runner.py:1181] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 09-21 14:59:54 model_runner.py:1185] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 09-21 15:00:05 model_runner.py:1300] Graph capturing finished in 11 secs.\n"
     ]
    }
   ],
   "source": [
    "llm = vllm_load(test_models[\"llama-3.1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d938178-167d-4df8-a5db-43aaa6026140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:00:05.297440Z",
     "iopub.status.busy": "2024-09-21T13:00:05.297342Z",
     "iopub.status.idle": "2024-09-21T13:06:03.663292Z",
     "shell.execute_reply": "2024-09-21T13:06:03.662779Z",
     "shell.execute_reply.started": "2024-09-21T13:00:05.297432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vLLM performance test:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████| 1/1 [00:09<00:00,  9.43s/it, est. speed input: 6.68 toks/s, output: 54.32 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: \"Le Crédit Mutuel est une banque coopérative française qui offre plusieurs avantages à ses membres et clients. Voici quelques-uns des principaux avantages :\\n\\n1. **Intérêts plus élevés sur les épargnes** : Le Crédit Mutuel propose des taux d'intérêt plus élevés sur les comptes d'épargne que de nombreux autres établissements bancaires.\\n2. **Taux d'emprunt compétitifs** : Les prêts personnels, les prêts immobiliers et les prêts pour la mobilité sont proposés avec des taux d'intérêt attractifs.\\n3. **Services personnalisés** : Le Crédit Mutuel offre des services personnalisés et adaptés aux besoins de ses membres et clients, grâce à une approche relationnelle et à une connaissance approfondie de leurs situations financières.\\n4. **Sécurité et confidentialité** : Le Crédit Mutuel s'engage à protéger les données personnelles et financières de ses membres et clients, conformément aux règles de protection des données.\\n5. **Participation aux décisions** : En tant que membre du Crédit Mutuel, vous avez la possibilité de participer aux assemblées générales et de voter sur les décisions stratégiques de l'institution.\\n6. **Services bancaires complets** : Le Crédit Mutuel propose un large éventail de services bancaires, y compris des comptes courants, des comptes d'épargne, des prêts, des cartes de crédit et des assurances.\\n7. **Aide à la gestion financière** : Le Crédit Mutuel propose des outils et des conseils pour aider ses membres et clients à gérer leur budget, à planifier leur avenir financier et à atteindre leurs objectifs économiques.\\n8. **Prévention de la fraude** : Le Crédit Mutuel met en place des mesures de prévention de la fraude pour protéger les comptes et les données de ses membres et clients.\\n9. **Services numériques** : Le Crédit Mutuel propose des applications mobiles et un site internet sécurisé pour gérer ses comptes et effectuer des opérations bancaires en ligne.\\n10. **Eng\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████| 1/1 [00:09<00:00,  9.29s/it, est. speed input: 6.78 toks/s, output: 55.13 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 1: 55.11 tokens/sec (1 x 55.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 2/2 [00:09<00:00,  4.80s/it, est. speed input: 13.24 toks/s, output: 106.76 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 2: 106.74 tokens/sec (2 x 53.37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 3/3 [00:09<00:00,  3.20s/it, est. speed input: 19.90 toks/s, output: 160.03 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 3: 159.98 tokens/sec (3 x 53.33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 4/4 [00:09<00:00,  2.42s/it, est. speed input: 26.08 toks/s, output: 211.15 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 4: 211.10 tokens/sec (4 x 52.77)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 5/5 [00:09<00:00,  1.95s/it, est. speed input: 32.33 toks/s, output: 262.77 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 5: 262.71 tokens/sec (5 x 52.54)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 6/6 [00:09<00:00,  1.63s/it, est. speed input: 38.80 toks/s, output: 314.48 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 6: 314.39 tokens/sec (6 x 52.40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 7/7 [00:09<00:00,  1.40s/it, est. speed input: 45.23 toks/s, output: 365.90 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 7: 365.80 tokens/sec (7 x 52.26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 8/8 [00:09<00:00,  1.23s/it, est. speed input: 51.25 toks/s, output: 416.53 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 8: 416.44 tokens/sec (8 x 52.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 9/9 [00:09<00:00,  1.11s/it, est. speed input: 56.98 toks/s, output: 463.06 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 9: 462.94 tokens/sec (9 x 51.44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 10/10 [00:10<00:00,  1.00s/it, est. speed input: 63.07 toks/s, output: 505.20 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 10: 505.04 tokens/sec (10 x 50.50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 11/11 [00:10<00:00,  1.09it/s, est. speed input: 69.00 toks/s, output: 559.12 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 11: 558.94 tokens/sec (11 x 50.81)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 12/12 [00:10<00:00,  1.19it/s, est. speed input: 74.67 toks/s, output: 606.83 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 12: 606.66 tokens/sec (12 x 50.56)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 13/13 [00:10<00:00,  1.28it/s, est. speed input: 80.69 toks/s, output: 647.62 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 13: 647.42 tokens/sec (13 x 49.80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 14/14 [00:10<00:00,  1.37it/s, est. speed input: 86.45 toks/s, output: 696.47 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 14: 696.27 tokens/sec (14 x 49.73)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 15/15 [00:10<00:00,  1.46it/s, est. speed input: 92.41 toks/s, output: 736.12 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 15: 735.89 tokens/sec (15 x 49.06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 16/16 [00:10<00:00,  1.53it/s, est. speed input: 96.50 toks/s, output: 784.27 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 16: 784.04 tokens/sec (16 x 49.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 17/17 [00:10<00:00,  1.56it/s, est. speed input: 98.10 toks/s, output: 787.19 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 17: 786.94 tokens/sec (17 x 46.29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 18/18 [00:11<00:00,  1.62it/s, est. speed input: 102.19 toks/s, output: 825.41 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 18: 825.16 tokens/sec (18 x 45.84)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 19/19 [00:11<00:00,  1.70it/s, est. speed input: 106.98 toks/s, output: 859.23 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 19: 858.96 tokens/sec (19 x 45.21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 20/20 [00:11<00:00,  1.77it/s, est. speed input: 111.41 toks/s, output: 902.62 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 20: 902.31 tokens/sec (20 x 45.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 21/21 [00:11<00:00,  1.84it/s, est. speed input: 116.22 toks/s, output: 936.93 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 21: 936.60 tokens/sec (21 x 44.60)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 22/22 [00:11<00:00,  1.92it/s, est. speed input: 121.24 toks/s, output: 982.60 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 22: 982.27 tokens/sec (22 x 44.65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 23/23 [00:11<00:00,  1.93it/s, est. speed input: 121.52 toks/s, output: 980.62 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 23: 980.30 tokens/sec (23 x 42.62)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 24/24 [00:12<00:00,  1.98it/s, est. speed input: 124.75 toks/s, output: 1002.42 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 24: 1002.09 tokens/sec (24 x 41.75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 25/25 [00:12<00:00,  2.07it/s, est. speed input: 130.63 toks/s, output: 1054.14 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 25: 1053.77 tokens/sec (25 x 42.15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 26/26 [00:12<00:00,  2.15it/s, est. speed input: 135.23 toks/s, output: 1091.22 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 26: 1090.81 tokens/sec (26 x 41.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 27/27 [00:12<00:00,  2.21it/s, est. speed input: 139.65 toks/s, output: 1133.60 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 27: 1133.13 tokens/sec (27 x 41.97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 28/28 [00:12<00:00,  2.31it/s, est. speed input: 145.68 toks/s, output: 1179.29 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 28: 1178.82 tokens/sec (28 x 42.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 29/29 [00:12<00:00,  2.33it/s, est. speed input: 146.56 toks/s, output: 1183.64 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 29: 1183.22 tokens/sec (29 x 40.80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 30/30 [00:12<00:00,  2.41it/s, est. speed input: 151.92 toks/s, output: 1222.63 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 30: 1222.15 tokens/sec (30 x 40.74)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 31/31 [00:12<00:00,  2.47it/s, est. speed input: 155.98 toks/s, output: 1259.03 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 31: 1258.56 tokens/sec (31 x 40.60)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 32/32 [00:12<00:00,  2.52it/s, est. speed input: 158.80 toks/s, output: 1288.18 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 32: 1287.65 tokens/sec (32 x 40.24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vllm_generate(test_messages*8, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84d1f3d-603b-4cf3-be32-ed0312caf5bc",
   "metadata": {},
   "source": [
    "### SGLang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98445cbd-0312-4cf5-8832-53b2da13e83c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T12:45:37.022854Z",
     "iopub.status.busy": "2024-09-21T12:45:37.022682Z",
     "iopub.status.idle": "2024-09-21T12:45:37.026918Z",
     "shell.execute_reply": "2024-09-21T12:45:37.026278Z",
     "shell.execute_reply.started": "2024-09-21T12:45:37.022845Z"
    }
   },
   "outputs": [],
   "source": [
    "import json, time\n",
    "import sglang\n",
    "\n",
    "def sglang_load(model):\n",
    "    runtime = sglang.Runtime(model_path=model)\n",
    "    runtime._model = model\n",
    "    return runtime\n",
    "\n",
    "def sglang_generate(messages, runtime):\n",
    "    print(f\"SGLang performance test:\")\n",
    "    \n",
    "    prompts = format_prompt(messages, runtime._model)\n",
    "    sampling_params = { \"temperature\":0.7, \"top_p\":0.8, \"repetition_penalty\":1.05, \"max_new_tokens\":512 }\n",
    "    # warmup\n",
    "    output = json.loads(runtime.generate(prompt=prompts[0], sampling_params=sampling_params))\n",
    "    print(f\"Generated text: {output['text']!r}\")\n",
    "    \n",
    "    for batch_size in range(1, len(messages) + 1):\n",
    "        start_time = time.time()  # Record the start time\n",
    "        outputs = json.loads(runtime.generate(prompt=prompts[0:batch_size], sampling_params=sampling_params))\n",
    "        end_time = time.time()  # Record the end time\n",
    "            \n",
    "        # Print the outputs.\n",
    "        tokenscount = 0\n",
    "        for output in outputs:\n",
    "            generated_text = output[\"text\"]\n",
    "            tokenscount = tokenscount + output[\"meta_info\"][\"completion_tokens\"]\n",
    "\n",
    "        tokens_per_sec = tokenscount/(end_time-start_time)\n",
    "        print(f\"- batch size {batch_size}: {tokens_per_sec:.2f} tokens/sec ({batch_size} x {tokens_per_sec/batch_size:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "128fac7f-aa20-4429-b6b1-31a30fc7ff83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T12:36:00.268452Z",
     "iopub.status.busy": "2024-09-21T12:36:00.267298Z",
     "iopub.status.idle": "2024-09-21T12:36:14.600995Z",
     "shell.execute_reply": "2024-09-21T12:36:14.600463Z",
     "shell.execute_reply.started": "2024-09-21T12:36:00.268402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-21 14:36:03 weight_utils.py:236] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:W0921 14:36:03.593000 140239112718016 torch/_inductor/compile_worker/subproc_pool.py:126] SubprocPool unclean exit\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/torch/_inductor/compile_worker/__main__.py\", line 45, in <module>\n",
      "    main()\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/torch/_inductor/compile_worker/__main__.py\", line 38, in main\n",
      "    pre_fork_setup()\n",
      "  File \"/root/miniconda3/envs/wordslab-notebooks/lib/python3.11/site-packages/torch/_inductor/async_compile.py\", line 62, in pre_fork_setup\n",
      "    from triton.compiler.compiler import triton_key\n",
      "ImportError: cannot import name 'triton_key' from 'triton.compiler.compiler' (/workspace/wordslab-llms/.venv/lib/python3.11/site-packages/triton/compiler/compiler.py)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8a8946e5b74f55bc8bf0c54673b02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runtime = sglang_load(test_models[\"llama-3.1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c23096e8-950c-48fd-adf7-1bef1b423521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T12:52:52.389315Z",
     "iopub.status.busy": "2024-09-21T12:52:52.389155Z",
     "iopub.status.idle": "2024-09-21T12:59:17.271931Z",
     "shell.execute_reply": "2024-09-21T12:59:17.271509Z",
     "shell.execute_reply.started": "2024-09-21T12:52:52.389300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGLang performance test:\n",
      "Generated text: \"Le Crédit Mutuel est une banque coopérative française qui offre divers avantages à ses membres, notamment :\\n\\n1. **Intérêts plus élevés sur les épargnes** : Le Crédit Mutuel propose des taux d'intérêt attractifs sur les comptes d'épargne, ce qui permet aux membres de gagner plus sur leurs économies.\\n2. **Prêts à des conditions avantageuses** : Les prêts accordés par le Crédit Mutuel sont souvent moins chers que ceux proposés par les banques traditionnelles, avec des taux d'intérêt compétitifs et des conditions de remboursement flexibles.\\n3. **Services personnalisés** : Le Crédit Mutuel offre des services personnalisés à ses membres, notamment en termes de conseil financier et de suivi de leur situation financière.\\n4. **Participation aux décisions** : En tant que membre du Crédit Mutuel, vous avez la possibilité de participer aux décisions stratégiques de l'organisation et de voter pour les dirigeants.\\n5. **Soutien à l'économie locale** : Le Crédit Mutuel soutient l'économie locale en finançant des projets de développement économique dans les territoires où il est présent.\\n6. **Protection contre les risques** : Le Crédit Mutuel propose des assurances et des garanties pour protéger ses membres contre les risques tels que les accidents, les maladies ou les pertes d'emploi.\\n7. **Comptes courants et cartes de paiement** : Le Crédit Mutuel propose des comptes courants et des cartes de paiement avec des conditions de rémunération intéressantes.\\n8. **Accès à des services numériques** : Le Crédit Mutuel propose des applications mobiles et un site internet sécurisé pour gérer vos comptes et effectuer des opérations bancaires en ligne.\\n9. **Système de réseaux** : Le Crédit Mutuel dispose d'un réseau de points de vente et de guichets automatiques pour permettre aux membres de gérer leurs comptes et effectuer des opérations bancaires en personne.\\n10. **Solidarité et responsabilité sociale** : Le Crédit Mutuel est une entreprise sol\"\n",
      "- batch size 1: 54.66 tokens/sec (1 x 54.66)\n",
      "- batch size 2: 107.32 tokens/sec (2 x 53.66)\n",
      "- batch size 3: 159.94 tokens/sec (3 x 53.31)\n",
      "- batch size 4: 212.60 tokens/sec (4 x 53.15)\n",
      "- batch size 5: 261.29 tokens/sec (5 x 52.26)\n",
      "- batch size 6: 310.14 tokens/sec (6 x 51.69)\n",
      "- batch size 7: 361.39 tokens/sec (7 x 51.63)\n",
      "- batch size 8: 414.71 tokens/sec (8 x 51.84)\n",
      "- batch size 9: 456.46 tokens/sec (9 x 50.72)\n",
      "- batch size 10: 507.11 tokens/sec (10 x 50.71)\n",
      "- batch size 11: 559.93 tokens/sec (11 x 50.90)\n",
      "- batch size 12: 613.54 tokens/sec (12 x 51.13)\n",
      "- batch size 13: 656.63 tokens/sec (13 x 50.51)\n",
      "- batch size 14: 703.96 tokens/sec (14 x 50.28)\n",
      "- batch size 15: 754.65 tokens/sec (15 x 50.31)\n",
      "- batch size 16: 804.48 tokens/sec (16 x 50.28)\n",
      "- batch size 17: 803.36 tokens/sec (17 x 47.26)\n",
      "- batch size 18: 838.78 tokens/sec (18 x 46.60)\n",
      "- batch size 19: 884.27 tokens/sec (19 x 46.54)\n",
      "- batch size 20: 931.08 tokens/sec (20 x 46.55)\n",
      "- batch size 21: 970.44 tokens/sec (21 x 46.21)\n",
      "- batch size 22: 1029.03 tokens/sec (22 x 46.77)\n",
      "- batch size 23: 1076.23 tokens/sec (23 x 46.79)\n",
      "- batch size 24: 1123.73 tokens/sec (24 x 46.82)\n",
      "- batch size 25: 1160.04 tokens/sec (25 x 46.40)\n",
      "- batch size 26: 1201.45 tokens/sec (26 x 46.21)\n",
      "- batch size 27: 848.42 tokens/sec (27 x 31.42)\n",
      "- batch size 28: 634.09 tokens/sec (28 x 22.65)\n",
      "- batch size 29: 867.79 tokens/sec (29 x 29.92)\n",
      "- batch size 30: 878.66 tokens/sec (30 x 29.29)\n",
      "- batch size 31: 918.74 tokens/sec (31 x 29.64)\n",
      "- batch size 32: 940.34 tokens/sec (32 x 29.39)\n"
     ]
    }
   ],
   "source": [
    "sglang_generate(test_messages*8, runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f668b-5d74-4b78-8a86-408328fd9978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41dd047a-5a98-485d-a451-55e7482b6999",
   "metadata": {},
   "source": [
    "https://docs.vllm.ai/en/latest/quantization/fp8.html#quantization-process"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-llms",
   "language": "python",
   "name": "wordslab-llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
