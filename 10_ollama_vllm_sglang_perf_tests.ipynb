{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7249409e-3e87-4e64-875c-624a78033472",
   "metadata": {},
   "source": [
    "## Install prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e11987-23f3-44e8-8184-b83679f0ee02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:14:42.975674Z",
     "iopub.status.busy": "2024-09-21T13:14:42.975587Z",
     "iopub.status.idle": "2024-09-21T13:14:42.983783Z",
     "shell.execute_reply": "2024-09-21T13:14:42.983473Z",
     "shell.execute_reply.started": "2024-09-21T13:14:42.975666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "version('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee55718c-4310-4aa9-b363-acae522d8197",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f72e89a-3941-4ee1-97cf-18c2e15b1842",
   "metadata": {},
   "source": [
    "https://docs.vllm.ai/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "459e66c0-05d6-4651-b62b-e486f5b0a961",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:14:45.123335Z",
     "iopub.status.busy": "2024-09-21T13:14:45.122378Z",
     "iopub.status.idle": "2024-09-21T13:14:45.130853Z",
     "shell.execute_reply": "2024-09-21T13:14:45.130581Z",
     "shell.execute_reply.started": "2024-09-21T13:14:45.123300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.44.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d35b0e6-a186-447d-a035-9af71e3358af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "876ca82b-1cd6-4aae-a964-2b047a9fc4a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:14:46.321506Z",
     "iopub.status.busy": "2024-09-21T13:14:46.321142Z",
     "iopub.status.idle": "2024-09-21T13:14:46.329698Z",
     "shell.execute_reply": "2024-09-21T13:14:46.328821Z",
     "shell.execute_reply.started": "2024-09-21T13:14:46.321479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6.1.post2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('vllm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6874cffb-8745-418f-9194-0c2f04060567",
   "metadata": {},
   "source": [
    "https://sglang.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56019c95-b5b3-4fe9-8170-2d3873db36cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade \"sglang[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea3fca-704a-4b5e-a8c0-80496ce179f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e703628-1345-49f5-b310-b4b93b36c620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:14:50.712384Z",
     "iopub.status.busy": "2024-09-21T13:14:50.711986Z",
     "iopub.status.idle": "2024-09-21T13:14:50.720997Z",
     "shell.execute_reply": "2024-09-21T13:14:50.720538Z",
     "shell.execute_reply.started": "2024-09-21T13:14:50.712356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.1.post2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('sglang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad3d9bc-c371-4bf1-8445-70bc48da5986",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:14:52.053603Z",
     "iopub.status.busy": "2024-09-21T13:14:52.053249Z",
     "iopub.status.idle": "2024-09-21T13:14:52.060368Z",
     "shell.execute_reply": "2024-09-21T13:14:52.060090Z",
     "shell.execute_reply.started": "2024-09-21T13:14:52.053580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('triton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cb9d3f5-621d-4e1f-b30e-c616ecb2df83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:14:54.202295Z",
     "iopub.status.busy": "2024-09-21T13:14:54.201912Z",
     "iopub.status.idle": "2024-09-21T13:14:54.209965Z",
     "shell.execute_reply": "2024-09-21T13:14:54.209702Z",
     "shell.execute_reply.started": "2024-09-21T13:14:54.202267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.6+cu124torch2.4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('flashinfer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2783c62-8361-4e45-9fdc-07a9ced35e81",
   "metadata": {},
   "source": [
    "https://github.com/ollama/ollama-python\n",
    "\n",
    "https://github.com/ollama/ollama/tree/main/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b56434-da15-42f4-9974-4f24be59902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48ac7f1f-81db-4643-90d8-2355f26de1c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:15:13.903286Z",
     "iopub.status.busy": "2024-09-21T13:15:13.903058Z",
     "iopub.status.idle": "2024-09-21T13:15:13.909154Z",
     "shell.execute_reply": "2024-09-21T13:15:13.908722Z",
     "shell.execute_reply.started": "2024-09-21T13:15:13.903269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('ollama')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de95a90-29e7-4dc4-974b-8b601a86c16a",
   "metadata": {},
   "source": [
    "### Format prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6570564c-6fbb-4eb2-b716-1a161c7d9787",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:23:20.268360Z",
     "iopub.status.busy": "2024-09-21T13:23:20.267806Z",
     "iopub.status.idle": "2024-09-21T13:23:20.283003Z",
     "shell.execute_reply": "2024-09-21T13:23:20.282486Z",
     "shell.execute_reply.started": "2024-09-21T13:23:20.268306Z"
    }
   },
   "outputs": [],
   "source": [
    "test_messages = [\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quels sont les avantages du Crédit Mutuel ?\"}\n",
    "],\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quels sont les avantages du Crédit Agricole ?\"}\n",
    "],\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quels sont les avantages de la Société Générale ?\"}\n",
    "],\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quels sont les avantages de la BNP ?\"}\n",
    "]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e93cb29b-8c75-4187-846a-832024247f03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:23:20.678285Z",
     "iopub.status.busy": "2024-09-21T13:23:20.677943Z",
     "iopub.status.idle": "2024-09-21T13:23:20.683032Z",
     "shell.execute_reply": "2024-09-21T13:23:20.682477Z",
     "shell.execute_reply.started": "2024-09-21T13:23:20.678262Z"
    }
   },
   "outputs": [],
   "source": [
    "test_models = {                                                                    # OpenLLM leaderboard score\n",
    "    \"llama-3.1\" : \"meta-llama/Meta-Llama-3.1-8B-Instruct\",                         # 100.0 %\n",
    "    \"llama-3.1:w8a16\" : \"neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a16\",  # 99.8 %    \n",
    "    \"llama-3.1:fp8\" : \"neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8-dynamic\",        # 99.7 %\n",
    "    \"llama-3.1:w8a8\" : \"neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a8\",    # 99.4 %\n",
    "    \"llama-3.1:w4a16\" : \"neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w4a16\"   # 97.1 %\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a427640-100e-49cb-a2fc-f5fa8c18a6e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:23:22.189349Z",
     "iopub.status.busy": "2024-09-21T13:23:22.188943Z",
     "iopub.status.idle": "2024-09-21T13:23:23.029322Z",
     "shell.execute_reply": "2024-09-21T13:23:23.028841Z",
     "shell.execute_reply.started": "2024-09-21T13:23:22.189322Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def format_prompt(messages, model):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "267c07a4-c9f1-4d16-8697-d4a1204e2c84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:23:23.030064Z",
     "iopub.status.busy": "2024-09-21T13:23:23.029884Z",
     "iopub.status.idle": "2024-09-21T13:23:23.358944Z",
     "shell.execute_reply": "2024-09-21T13:23:23.358307Z",
     "shell.execute_reply.started": "2024-09-21T13:23:23.030054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nTu es un assistant utile et professionnel qui répond toujours en français.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nQuels sont les avantages du Crédit Mutuel ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n',\n",
       " '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nTu es un assistant utile et professionnel qui répond toujours en français.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nQuels sont les avantages du Crédit Agricole ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n',\n",
       " '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nTu es un assistant utile et professionnel qui répond toujours en français.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nQuels sont les avantages de la Société Générale ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n',\n",
       " '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nTu es un assistant utile et professionnel qui répond toujours en français.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nQuels sont les avantages de la BNP ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_prompt(test_messages, test_models[\"llama-3.1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d16d245-b3ef-418e-8d3b-5f494f5e6deb",
   "metadata": {},
   "source": [
    "### vLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f997ac1-6001-493b-b118-61ca0ff29449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:15:32.117210Z",
     "iopub.status.busy": "2024-09-21T13:15:32.116663Z",
     "iopub.status.idle": "2024-09-21T13:15:32.123110Z",
     "shell.execute_reply": "2024-09-21T13:15:32.122797Z",
     "shell.execute_reply.started": "2024-09-21T13:15:32.117183Z"
    }
   },
   "outputs": [],
   "source": [
    "# Authenticate VLLM with Huggingface Hub\n",
    "import os\n",
    "\n",
    "with open(\"/workspace/hftoken\", 'r') as file:\n",
    "    myhftoken = file.read().strip()\n",
    "\n",
    "os.environ[\"HF_TOKEN\"]=myhftoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15a8369c-d660-4d64-897d-4d5929200a42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:15:32.459431Z",
     "iopub.status.busy": "2024-09-21T13:15:32.459248Z",
     "iopub.status.idle": "2024-09-21T13:15:33.501003Z",
     "shell.execute_reply": "2024-09-21T13:15:33.500430Z",
     "shell.execute_reply.started": "2024-09-21T13:15:32.459421Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "def vllm_load(model):    \n",
    "    llm = LLM(model, gpu_memory_utilization=0.99, max_model_len=8192)\n",
    "    llm._model = model\n",
    "    return llm\n",
    "\n",
    "def vllm_generate(messages, llm):    \n",
    "    print(f\"vLLM performance test:\")\n",
    "    \n",
    "    prompts = format_prompt(messages, llm._model)\n",
    "    sampling_params = SamplingParams(temperature=0.7, top_p=0.8, repetition_penalty=1.05, max_tokens=512)\n",
    "    # warmup\n",
    "    outputs = llm.generate(prompts[0], sampling_params)\n",
    "    print(f\"Generated text: {outputs[0].outputs[0].text!r}\")\n",
    "    \n",
    "    for batch_size in range(1, len(messages) + 1):\n",
    "        start_time = time.time()  # Record the start time\n",
    "        outputs = llm.generate(prompts[0:batch_size], sampling_params)\n",
    "        end_time = time.time()  # Record the end time\n",
    "            \n",
    "        # Print the outputs.\n",
    "        tokenscount = 0\n",
    "        for output in outputs:\n",
    "            generated_text = output.outputs[0].text\n",
    "            tokenscount = tokenscount + len(output.outputs[0].token_ids)\n",
    "\n",
    "        tokens_per_sec = tokenscount/(end_time-start_time)\n",
    "        print(f\"- batch size {batch_size}: {tokens_per_sec:.2f} tokens/sec ({batch_size} x {tokens_per_sec/batch_size:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2267f691-7b8f-44a7-82c6-7e85598c7a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:15:37.330530Z",
     "iopub.status.busy": "2024-09-21T13:15:37.329877Z",
     "iopub.status.idle": "2024-09-21T13:15:52.509569Z",
     "shell.execute_reply": "2024-09-21T13:15:52.509096Z",
     "shell.execute_reply.started": "2024-09-21T13:15:37.330503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-21 15:15:37 llm_engine.py:223] Initializing an LLM engine (v0.6.1.post2) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)\n",
      "WARNING 09-21 15:15:38 utils.py:727] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "INFO 09-21 15:15:38 model_runner.py:997] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...\n",
      "INFO 09-21 15:15:38 weight_utils.py:242] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb3328c31d34b1a8665b0f69a252b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-21 15:15:41 model_runner.py:1008] Loading model weights took 14.9888 GB\n",
      "INFO 09-21 15:15:42 gpu_executor.py:122] # GPU blocks: 3610, # CPU blocks: 2048\n",
      "INFO 09-21 15:15:42 model_runner.py:1311] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 09-21 15:15:42 model_runner.py:1315] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 09-21 15:15:52 model_runner.py:1430] Graph capturing finished in 10 secs.\n"
     ]
    }
   ],
   "source": [
    "llm = vllm_load(test_models[\"llama-3.1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d938178-167d-4df8-a5db-43aaa6026140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:15:58.808650Z",
     "iopub.status.busy": "2024-09-21T13:15:58.807243Z",
     "iopub.status.idle": "2024-09-21T13:21:53.704000Z",
     "shell.execute_reply": "2024-09-21T13:21:53.703624Z",
     "shell.execute_reply.started": "2024-09-21T13:15:58.808607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vLLM performance test:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████| 1/1 [00:09<00:00,  9.58s/it, est. speed input: 6.58 toks/s, output: 53.47 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: \"Le Crédit Mutuel est une banque coopérative française qui offre plusieurs avantages à ses membres et clients. Voici quelques-uns des principaux avantages :\\n\\n1. **Intérêts plus élevés sur les épargnes** : Le Crédit Mutuel propose des taux d'intérêt plus élevés sur les comptes d'épargne que de nombreux autres établissements bancaires.\\n2. **Taux d'emprunt compétitifs** : Les prêts personnels, les prêts immobiliers et les prêts pour la mobilité sont proposés avec des taux d'intérêt attractifs.\\n3. **Services personnalisés** : Le Crédit Mutuel offre des services personnalisés et adaptés aux besoins de ses membres et clients, grâce à une approche relationnelle et à une connaissance approfondie de leurs situations financières.\\n4. **Sécurité et confidentialité** : Le Crédit Mutuel s'engage à protéger les données personnelles et financières de ses membres et clients, conformément aux règles de protection des données.\\n5. **Participation aux décisions** : En tant que membre du Crédit Mutuel, vous avez la possibilité de participer aux assemblées générales et de voter sur les décisions stratégiques de l'institution.\\n6. **Services bancaires complets** : Le Crédit Mutuel propose un large éventail de services bancaires, y compris des comptes courants, des comptes d'épargne, des prêts, des cartes de crédit et des assurances.\\n7. **Aide à la gestion financière** : Le Crédit Mutuel propose des outils et des conseils pour aider ses membres et clients à gérer leur budget, à planifier leur avenir financier et à atteindre leurs objectifs économiques.\\n8. **Prévention de la fraude** : Le Crédit Mutuel met en place des mesures de prévention de la fraude pour protéger les comptes et les données de ses membres et clients.\\n9. **Services numériques** : Le Crédit Mutuel propose des applications mobiles et un site internet sécurisé pour gérer ses comptes et effectuer des opérations bancaires en ligne.\\n10. **Eng\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████| 1/1 [00:09<00:00,  9.30s/it, est. speed input: 6.78 toks/s, output: 55.07 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 1: 55.06 tokens/sec (1 x 55.06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 2/2 [00:09<00:00,  4.79s/it, est. speed input: 13.24 toks/s, output: 106.79 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 2: 106.76 tokens/sec (2 x 53.38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 3/3 [00:09<00:00,  3.21s/it, est. speed input: 19.84 toks/s, output: 159.53 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 3: 159.49 tokens/sec (3 x 53.16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 4/4 [00:09<00:00,  2.41s/it, est. speed input: 26.13 toks/s, output: 209.16 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 4: 209.11 tokens/sec (4 x 52.28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 5/5 [00:09<00:00,  1.95s/it, est. speed input: 32.38 toks/s, output: 255.03 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 5: 254.98 tokens/sec (5 x 51.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 6/6 [00:09<00:00,  1.63s/it, est. speed input: 38.78 toks/s, output: 314.30 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 6: 314.21 tokens/sec (6 x 52.37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 7/7 [00:09<00:00,  1.40s/it, est. speed input: 45.17 toks/s, output: 365.40 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 7: 365.28 tokens/sec (7 x 52.18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 8/8 [00:09<00:00,  1.23s/it, est. speed input: 51.42 toks/s, output: 417.88 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 8: 417.78 tokens/sec (8 x 52.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 9/9 [00:09<00:00,  1.10s/it, est. speed input: 57.23 toks/s, output: 453.61 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 9: 453.50 tokens/sec (9 x 50.39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 10/10 [00:09<00:00,  1.00it/s, est. speed input: 63.26 toks/s, output: 513.27 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 10: 513.14 tokens/sec (10 x 51.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 11/11 [00:10<00:00,  1.09it/s, est. speed input: 69.12 toks/s, output: 558.33 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 11: 558.14 tokens/sec (11 x 50.74)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 12/12 [00:10<00:00,  1.19it/s, est. speed input: 74.86 toks/s, output: 607.20 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 12: 607.03 tokens/sec (12 x 50.59)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 13/13 [00:10<00:00,  1.28it/s, est. speed input: 80.73 toks/s, output: 656.08 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 13: 655.89 tokens/sec (13 x 50.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 14/14 [00:10<00:00,  1.36it/s, est. speed input: 86.00 toks/s, output: 690.02 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 14: 689.78 tokens/sec (14 x 49.27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 15/15 [00:10<00:00,  1.47it/s, est. speed input: 92.83 toks/s, output: 748.79 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 15: 748.58 tokens/sec (15 x 49.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 16/16 [00:10<00:00,  1.56it/s, est. speed input: 98.23 toks/s, output: 791.13 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 16: 790.84 tokens/sec (16 x 49.43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████| 17/17 [00:10<00:00,  1.56it/s, est. speed input: 98.22 toks/s, output: 794.11 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 17: 793.86 tokens/sec (17 x 46.70)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 18/18 [00:11<00:00,  1.64it/s, est. speed input: 103.14 toks/s, output: 837.51 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 18: 837.21 tokens/sec (18 x 46.51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 19/19 [00:11<00:00,  1.73it/s, est. speed input: 108.98 toks/s, output: 872.24 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 19: 871.95 tokens/sec (19 x 45.89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 20/20 [00:11<00:00,  1.79it/s, est. speed input: 112.62 toks/s, output: 906.29 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 20: 905.96 tokens/sec (20 x 45.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████| 21/21 [00:11<00:00,  1.88it/s, est. speed input: 118.43 toks/s, output: 959.20 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 21: 958.86 tokens/sec (21 x 45.66)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 22/22 [00:11<00:00,  1.96it/s, est. speed input: 123.62 toks/s, output: 1003.89 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 22: 1003.52 tokens/sec (22 x 45.61)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 23/23 [00:11<00:00,  1.97it/s, est. speed input: 124.36 toks/s, output: 1009.31 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 23: 1008.92 tokens/sec (23 x 43.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 24/24 [00:11<00:00,  2.04it/s, est. speed input: 128.40 toks/s, output: 1043.48 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 24: 1043.09 tokens/sec (24 x 43.46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 25/25 [00:11<00:00,  2.12it/s, est. speed input: 133.65 toks/s, output: 1076.93 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 25: 1076.50 tokens/sec (25 x 43.06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 26/26 [00:11<00:00,  2.17it/s, est. speed input: 136.85 toks/s, output: 1102.69 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 26: 1102.26 tokens/sec (26 x 42.39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 27/27 [00:11<00:00,  2.27it/s, est. speed input: 142.88 toks/s, output: 1157.88 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 27: 1157.37 tokens/sec (27 x 42.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 28/28 [00:11<00:00,  2.34it/s, est. speed input: 147.12 toks/s, output: 1189.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 28: 1189.24 tokens/sec (28 x 42.47)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 29/29 [00:12<00:00,  2.40it/s, est. speed input: 151.45 toks/s, output: 1223.51 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 29: 1222.97 tokens/sec (29 x 42.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 30/30 [00:12<00:00,  2.44it/s, est. speed input: 153.90 toks/s, output: 1243.11 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 30: 1242.63 tokens/sec (30 x 41.42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 31/31 [00:12<00:00,  2.53it/s, est. speed input: 159.80 toks/s, output: 1282.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 31: 1282.23 tokens/sec (31 x 41.36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 32/32 [00:12<00:00,  2.56it/s, est. speed input: 161.42 toks/s, output: 1308.09 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- batch size 32: 1307.55 tokens/sec (32 x 40.86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vllm_generate(test_messages*8, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84d1f3d-603b-4cf3-be32-ed0312caf5bc",
   "metadata": {},
   "source": [
    "### SGLang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98445cbd-0312-4cf5-8832-53b2da13e83c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:23:31.653744Z",
     "iopub.status.busy": "2024-09-21T13:23:31.653203Z",
     "iopub.status.idle": "2024-09-21T13:23:31.665077Z",
     "shell.execute_reply": "2024-09-21T13:23:31.664669Z",
     "shell.execute_reply.started": "2024-09-21T13:23:31.653713Z"
    }
   },
   "outputs": [],
   "source": [
    "import json, time\n",
    "import sglang\n",
    "\n",
    "def sglang_load(model):\n",
    "    runtime = sglang.Runtime(model_path=model)\n",
    "    runtime._model = model\n",
    "    return runtime\n",
    "\n",
    "def sglang_generate(messages, runtime):\n",
    "    print(f\"SGLang performance test:\")\n",
    "    \n",
    "    prompts = format_prompt(messages, runtime._model)\n",
    "    sampling_params = { \"temperature\":0.7, \"top_p\":0.8, \"repetition_penalty\":1.05, \"max_new_tokens\":512 }\n",
    "    # warmup\n",
    "    output = json.loads(runtime.generate(prompt=prompts[0], sampling_params=sampling_params))\n",
    "    print(f\"Generated text: {output['text']!r}\")\n",
    "    \n",
    "    for batch_size in range(1, len(messages) + 1):\n",
    "        start_time = time.time()  # Record the start time\n",
    "        outputs = json.loads(runtime.generate(prompt=prompts[0:batch_size], sampling_params=sampling_params))\n",
    "        end_time = time.time()  # Record the end time\n",
    "            \n",
    "        # Print the outputs.\n",
    "        tokenscount = 0\n",
    "        for output in outputs:\n",
    "            generated_text = output[\"text\"]\n",
    "            tokenscount = tokenscount + output[\"meta_info\"][\"completion_tokens\"]\n",
    "\n",
    "        tokens_per_sec = tokenscount/(end_time-start_time)\n",
    "        print(f\"- batch size {batch_size}: {tokens_per_sec:.2f} tokens/sec ({batch_size} x {tokens_per_sec/batch_size:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128fac7f-aa20-4429-b6b1-31a30fc7ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = sglang_load(test_models[\"llama-3.1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23096e8-950c-48fd-adf7-1bef1b423521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T13:23:53.873159Z",
     "iopub.status.busy": "2024-09-21T13:23:53.872596Z",
     "iopub.status.idle": "2024-09-21T13:29:57.571364Z",
     "shell.execute_reply": "2024-09-21T13:29:57.570949Z",
     "shell.execute_reply.started": "2024-09-21T13:23:53.873131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGLang performance test:\n",
      "Generated text: \"Le Crédit Mutuel est une banque coopérative française qui offre divers avantages à ses membres et clients. Voici quelques-uns des principaux avantages :\\n\\n1. **Intérêts plus élevés sur les dépôts** : Le Crédit Mutuel propose des taux d'intérêt plus élevés que les banques traditionnelles pour les dépôts, ce qui permet aux clients de gagner plus d'argent sur leurs économies.\\n\\n2. **Taux d'emprunt compétitifs** : Les emprunts du Crédit Mutuel sont souvent moins chers que ceux proposés par les banques traditionnelles, ce qui peut aider les clients à se procurer des prêts à des conditions avantageuses.\\n\\n3. **Services personnalisés** : En tant que banque coopérative, le Crédit Mutuel prend en compte les besoins spécifiques de ses clients et offre des services personnalisés pour répondre à leurs attentes.\\n\\n4. **Transparence et sécurité** : Le Crédit Mutuel est connu pour sa transparence financière et sa sécurité, ce qui rassure les clients qui souhaitent faire confiance à leur banque.\\n\\n5. **Services numériques performants** : Le Crédit Mutuel propose des services en ligne et mobiles pratiques, permettant aux clients de gérer leurs comptes et effectuer des opérations bancaires en toute simplicité.\\n\\n6. **Prise en charge des projets locaux** : Le Crédit Mutuel soutient les projets locaux et les initiatives communautaires, ce qui contribue au développement économique et social des régions où il est présent.\\n\\n7. **Éthique et responsabilité sociale** : Le Crédit Mutuel est engagé dans des pratiques éthiques et responsables, ce qui rassure les clients qui souhaitent faire des affaires avec une banque qui partage leurs valeurs.\\n\\n8. **Diversification des produits et services** : Le Crédit Mutuel propose une gamme large de produits et services bancaires, allant des comptes courants et des épargnes aux prêts et aux assurances.\\n\\n9. **Conseil financier personnalisé** : Les conseillers du Crédit Mutuel offrent un accompagnement personnalisé pour aider les\"\n",
      "- batch size 1: 54.40 tokens/sec (1 x 54.40)\n",
      "- batch size 2: 106.28 tokens/sec (2 x 53.14)\n",
      "- batch size 3: 158.87 tokens/sec (3 x 52.96)\n",
      "- batch size 4: 204.87 tokens/sec (4 x 51.22)\n",
      "- batch size 5: 261.97 tokens/sec (5 x 52.39)\n",
      "- batch size 6: 313.69 tokens/sec (6 x 52.28)\n",
      "- batch size 7: 365.71 tokens/sec (7 x 52.24)\n",
      "- batch size 8: 417.00 tokens/sec (8 x 52.13)\n",
      "- batch size 9: 468.16 tokens/sec (9 x 52.02)\n",
      "- batch size 10: 510.35 tokens/sec (10 x 51.04)\n",
      "- batch size 11: 550.32 tokens/sec (11 x 50.03)\n",
      "- batch size 12: 603.20 tokens/sec (12 x 50.27)\n",
      "- batch size 13: 641.52 tokens/sec (13 x 49.35)\n",
      "- batch size 14: 704.31 tokens/sec (14 x 50.31)\n",
      "- batch size 15: 757.44 tokens/sec (15 x 50.50)\n",
      "- batch size 16: 803.96 tokens/sec (16 x 50.25)\n",
      "- batch size 17: 809.71 tokens/sec (17 x 47.63)\n",
      "- batch size 18: 856.48 tokens/sec (18 x 47.58)\n",
      "- batch size 19: 900.94 tokens/sec (19 x 47.42)\n",
      "- batch size 20: 932.80 tokens/sec (20 x 46.64)\n",
      "- batch size 21: 975.06 tokens/sec (21 x 46.43)\n",
      "- batch size 22: 1020.68 tokens/sec (22 x 46.39)\n",
      "- batch size 23: 1063.49 tokens/sec (23 x 46.24)\n",
      "- batch size 24: 1104.37 tokens/sec (24 x 46.02)\n",
      "- batch size 25: 1146.04 tokens/sec (25 x 45.84)\n",
      "- batch size 26: 1202.71 tokens/sec (26 x 46.26)\n",
      "- batch size 27: 1240.36 tokens/sec (27 x 45.94)\n",
      "- batch size 28: 1290.63 tokens/sec (28 x 46.09)\n",
      "- batch size 29: 1332.88 tokens/sec (29 x 45.96)\n",
      "- batch size 30: 1369.35 tokens/sec (30 x 45.64)\n",
      "- batch size 31: 932.32 tokens/sec (31 x 30.07)\n",
      "- batch size 32: 640.79 tokens/sec (32 x 20.02)\n"
     ]
    }
   ],
   "source": [
    "sglang_generate(test_messages*8, runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65080db2-7b9c-4b53-b31a-f3287412935a",
   "metadata": {},
   "source": [
    "### Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805868d1-ea35-49dd-a449-20be4833469e",
   "metadata": {},
   "source": [
    "https://github.com/ollama/ollama/blob/main/docs/linux.md#manual-install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cac0e71-e0a2-482e-92d5-69a81768e166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T20:25:03.127960Z",
     "iopub.status.busy": "2024-09-21T20:25:03.127560Z",
     "iopub.status.idle": "2024-09-21T20:26:45.368164Z",
     "shell.execute_reply": "2024-09-21T20:26:45.367508Z",
     "shell.execute_reply.started": "2024-09-21T20:25:03.127947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   117  100   117    0     0    566      0 --:--:-- --:--:-- --:--:--   567\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 1583M  100 1583M    0     0  17.1M      0  0:01:32  0:01:32 --:--:-- 16.9M\n"
     ]
    }
   ],
   "source": [
    "!mkdir ollama && curl -L https://ollama.com/download/ollama-linux-amd64.tgz -o ollama-linux-amd64.tgz && tar -C ./ollama -xzf ollama-linux-amd64.tgz && rm ollama-linux-amd64.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b945949-a146-45d1-97a0-7d8ceddae56c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T20:28:36.847325Z",
     "iopub.status.busy": "2024-09-21T20:28:36.846900Z",
     "iopub.status.idle": "2024-09-21T20:28:36.885093Z",
     "shell.execute_reply": "2024-09-21T20:28:36.884416Z",
     "shell.execute_reply.started": "2024-09-21T20:28:36.847310Z"
    }
   },
   "source": [
    "```bash\n",
    "./ollama/bin/ollama serve &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f6239a-2e41-4a0c-8a3a-c7d36d96e063",
   "metadata": {},
   "source": [
    "https://github.com/ollama/ollama-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "379dd5df-93a0-48d7-91e8-23d49a37cb00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T20:31:49.830929Z",
     "iopub.status.busy": "2024-09-21T20:31:49.830794Z",
     "iopub.status.idle": "2024-09-21T20:31:49.835434Z",
     "shell.execute_reply": "2024-09-21T20:31:49.834577Z",
     "shell.execute_reply.started": "2024-09-21T20:31:49.830922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': []}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "ollama.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59df8a3-ed0b-4965-9aea-c2da99595cb2",
   "metadata": {},
   "source": [
    "https://ollama.com/library/llama3.1:8b-instruct-fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2bc08f74-bd5a-4601-90ba-e1ec0a2eef3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T09:31:56.246287Z",
     "iopub.status.busy": "2024-09-22T09:31:56.245540Z",
     "iopub.status.idle": "2024-09-22T09:31:56.252551Z",
     "shell.execute_reply": "2024-09-22T09:31:56.251423Z",
     "shell.execute_reply.started": "2024-09-22T09:31:56.246261Z"
    }
   },
   "outputs": [],
   "source": [
    "ollama_test_models = {\n",
    "    \"llama-3.1\" : \"llama3.1:8b-instruct-fp16\",\n",
    "    \"llama-3.1:int8\" : \"llama3.1:8b-instruct-q8_0\",\n",
    "    \"llama-3.1:int4\" : \"llama3.1:8b-instruct-q4_0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e30fa2-f318-4bc3-8814-938de80ce756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T20:40:36.798116Z",
     "iopub.status.busy": "2024-09-21T20:40:36.797241Z",
     "iopub.status.idle": "2024-09-21T20:40:36.804014Z",
     "shell.execute_reply": "2024-09-21T20:40:36.803150Z",
     "shell.execute_reply.started": "2024-09-21T20:40:36.798087Z"
    }
   },
   "source": [
    "```bash\n",
    "./ollama/bin/ollama pull llama3.1:8b-instruct-fp16\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59930211-acff-404a-b3d1-1d091474cd44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T20:57:45.617937Z",
     "iopub.status.busy": "2024-09-21T20:57:45.617402Z",
     "iopub.status.idle": "2024-09-21T20:57:45.643455Z",
     "shell.execute_reply": "2024-09-21T20:57:45.643032Z",
     "shell.execute_reply.started": "2024-09-21T20:57:45.617903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [{'name': 'llama3.1:8b-instruct-fp16',\n",
       "   'model': 'llama3.1:8b-instruct-fp16',\n",
       "   'modified_at': '2024-09-21T22:54:30.926572546+02:00',\n",
       "   'size': 16068910253,\n",
       "   'digest': '4aacac4194543ff7f70dab3f2ebc169c132d5319bb36f7a7e99c4ff525ebcc09',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '8.0B',\n",
       "    'quantization_level': 'F16'}}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ace51020-dc87-4cbb-a5fb-686ffbc9ccd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T21:06:14.481788Z",
     "iopub.status.busy": "2024-09-21T21:06:14.481058Z",
     "iopub.status.idle": "2024-09-21T21:06:14.501823Z",
     "shell.execute_reply": "2024-09-21T21:06:14.501524Z",
     "shell.execute_reply.started": "2024-09-21T21:06:14.481752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{- if or .System .Tools }}<|start_header_id|>system<|end_header_id|>\n",
      "{{- if .System }}\n",
      "\n",
      "{{ .System }}\n",
      "{{- end }}\n",
      "{{- if .Tools }}\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "\n",
      "When you receive a tool call response, use the output to format an answer to the orginal user question.\n",
      "\n",
      "You are a helpful assistant with tool calling capabilities.\n",
      "{{- end }}<|eot_id|>\n",
      "{{- end }}\n",
      "{{- range $i, $_ := .Messages }}\n",
      "{{- $last := eq (len (slice $.Messages $i)) 1 }}\n",
      "{{- if eq .Role \"user\" }}<|start_header_id|>user<|end_header_id|>\n",
      "{{- if and $.Tools $last }}\n",
      "\n",
      "Given the following functions, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.\n",
      "\n",
      "Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}. Do not use variables.\n",
      "\n",
      "{{ range $.Tools }}\n",
      "{{- . }}\n",
      "{{ end }}\n",
      "Question: {{ .Content }}<|eot_id|>\n",
      "{{- else }}\n",
      "\n",
      "{{ .Content }}<|eot_id|>\n",
      "{{- end }}{{ if $last }}<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{{ end }}\n",
      "{{- else if eq .Role \"assistant\" }}<|start_header_id|>assistant<|end_header_id|>\n",
      "{{- if .ToolCalls }}\n",
      "{{ range .ToolCalls }}\n",
      "{\"name\": \"{{ .Function.Name }}\", \"parameters\": {{ .Function.Arguments }}}{{ end }}\n",
      "{{- else }}\n",
      "\n",
      "{{ .Content }}\n",
      "{{- end }}{{ if not $last }}<|eot_id|>{{ end }}\n",
      "{{- else if eq .Role \"tool\" }}<|start_header_id|>ipython<|end_header_id|>\n",
      "\n",
      "{{ .Content }}<|eot_id|>{{ if $last }}<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{{ end }}\n",
      "{{- end }}\n",
      "{{- end }}\n"
     ]
    }
   ],
   "source": [
    "print(ollama.show(\"llama3.1:8b-instruct-fp16\")['template'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5e8405-b6ed-4ba2-a575-46bddf2f9f8d",
   "metadata": {},
   "source": [
    "https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a9f668b-5d74-4b78-8a86-408328fd9978",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T09:37:45.184355Z",
     "iopub.status.busy": "2024-09-22T09:37:45.183990Z",
     "iopub.status.idle": "2024-09-22T09:37:45.191794Z",
     "shell.execute_reply": "2024-09-22T09:37:45.191214Z",
     "shell.execute_reply.started": "2024-09-22T09:37:45.184331Z"
    }
   },
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "# ollama keeps models 5 min in memory by default, they are reloaded by a query\n",
    "def ollama_load(model):\n",
    "    sampling_params = { \"num_predict\":1 }\n",
    "    ollama.generate(model=model, prompt=\"load\", raw=True, options=sampling_params, stream=False)\n",
    "    return model\n",
    "\n",
    "# ollama API only supports batch size 1\n",
    "def ollama_generate(messages, model):\n",
    "    print(f\"ollama performance test:\")\n",
    "    \n",
    "    prompts = format_prompt(messages, runtime._model)\n",
    "    sampling_params = { \"temperature\":0.7, \"top_p\":0.8, \"repeat_penalty\":1.05, \"num_predict\":512 }\n",
    "    # warmup\n",
    "    output = ollama.generate(model=model, prompt=prompts[0], raw=True, options=sampling_params, stream=False)\n",
    "    print(f\"Generated text: {output['response']!r}\")\n",
    "    \n",
    "    for msg_index in range(len(messages)):\n",
    "        start_time = time.time()  # Record the start time\n",
    "        output = ollama.generate(model=model, prompt=prompts[msg_index], raw=True, options=sampling_params, stream=False)\n",
    "        end_time = time.time()  # Record the end time\n",
    "            \n",
    "        # Print the outputs.\n",
    "        tokenscount = output['eval_count']\n",
    "        tokens_per_sec = tokenscount/(end_time-start_time)\n",
    "        print(f\"- batch size 1: {tokens_per_sec:.2f} tokens/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43eb08e5-8f25-4012-8073-0335d02f653c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T09:37:53.426904Z",
     "iopub.status.busy": "2024-09-22T09:37:53.426458Z",
     "iopub.status.idle": "2024-09-22T09:37:53.741430Z",
     "shell.execute_reply": "2024-09-22T09:37:53.741049Z",
     "shell.execute_reply.started": "2024-09-22T09:37:53.426875Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ollama_load(ollama_test_models[\"llama-3.1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0346b5a-21ae-4f4a-9243-2e4a14ada961",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T09:38:09.282965Z",
     "iopub.status.busy": "2024-09-22T09:38:09.282620Z",
     "iopub.status.idle": "2024-09-22T09:38:59.041822Z",
     "shell.execute_reply": "2024-09-22T09:38:59.041472Z",
     "shell.execute_reply.started": "2024-09-22T09:38:09.282942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ollama performance test:\n",
      "Generated text: \"Le Crédit Mutuel est une banque coopérative française qui offre divers avantages à ses adhérents. Voici quelques-uns des principaux avantages :\\n\\n1. **Intérêts réduits sur les prêts** : Le Crédit Mutuel propose des taux d'intérêt compétitifs pour les prêts personnels, hypothécaires et professionnels.\\n2. **Avantages fiscaux** : Les adhérents du Crédit Mutuel peuvent bénéficier de réductions fiscales sur leurs prêts et épargnes, en fonction de leur situation financière et de leurs impôts.\\n3. **Assistance financière** : Le Crédit Mutuel offre des services d'assistance financière pour aider ses adhérents à gérer leurs finances et à atteindre leurs objectifs économiques.\\n4. **Produits diversifiés** : Le Crédit Mutuel propose une gamme complète de produits bancaires, tels que les comptes courants, les livrets d'épargne, les cartes de crédit, les assurances et les investissements.\\n5. **Services en ligne** : Les adhérents du Crédit Mutuel ont accès à un portail en ligne sécurisé pour gérer leurs comptes, effectuer des virements, payer leurs factures et suivre leur épargne.\\n6. **Soutien à l'épargne** : Le Crédit Mutuel encourage l'épargne de ses adhérents grâce à des produits spécifiques, tels que les livrets d'épargne ou les comptes d'épargne.\\n7. **Protection et assurance** : Le Crédit Mutuel propose des contrats d'assurance pour protéger les biens et les personnes de ses adhérents contre divers risques (incendie, vol, accident, décès).\\n8. **Soutien à l'entrepreneuriat** : Le Crédit Mutuel offre des prêts et des services spécifiques pour les entrepreneurs et les PME.\\n9. **Fidélité et récompenses** : Les adhérents du Crédit Mutuel peuvent bénéficier de récompenses et de primes en fonction de leur comportement bancaire (\"\n",
      "- batch size 1: 51.97 tokens/sec\n",
      "- batch size 1: 52.16 tokens/sec\n",
      "- batch size 1: 52.33 tokens/sec\n",
      "- batch size 1: 52.55 tokens/sec\n"
     ]
    }
   ],
   "source": [
    "ollama_generate(test_messages, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dd047a-5a98-485d-a451-55e7482b6999",
   "metadata": {},
   "source": [
    "https://docs.vllm.ai/en/latest/quantization/fp8.html#quantization-process"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-llms",
   "language": "python",
   "name": "wordslab-llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
